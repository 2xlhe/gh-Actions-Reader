{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from actions import ActionsWorkflow, ActionsJobs, ActionsArtifacts\n",
    "import LogExtractor as extractor\n",
    "\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Table, TableStyle, Spacer, ListFlowable, ListItem, Spacer, Image\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import tempfile\n",
    "import os\n",
    "import kaleido\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_distribution_pie_chat_plt(error_df):\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.pie(\n",
    "        error_passed_info['FAILED'].values,\n",
    "        labels=error_passed_info['FAILED'].index.to_list(),\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=90,\n",
    "        colors=['firebrick', 'lightgreen', 'lightskyblue'],\n",
    "    )\n",
    "    plt.legend(title=\"Error Types\", loc=\"upper right\", bbox_to_anchor=(1.3, 1))\n",
    "    plt.title('Failure Distribution')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_distribution_pie_chart(error_df):\n",
    "    # Filter for FAILED status\n",
    "    failed_df = error_df[error_df['status'] == 'FAILED']\n",
    "\n",
    "    # Group by category and count the number of FAILED statuses\n",
    "    failed_counts = failed_df.groupby('category').size().reset_index(name='count')\n",
    "\n",
    "    # Create the pie chart\n",
    "    fig = px.pie(\n",
    "        failed_counts, \n",
    "        names=\"category\",  # Use 'category' for pie slice labels\n",
    "        values=\"count\",    # Use 'count' for pie slice sizes\n",
    "        title=\"Distribuição de falhas por categoria\",\n",
    "        color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "    #   width=400,  # Set the width of the plot (in pixels)\n",
    "    #  height=400,  # Set the height of the plot (in pixels)\n",
    "        margin=dict(l=20, r=20, t=40, b=20)  # Adjust margins if needed\n",
    "    )\n",
    "\n",
    "    # Make the pie chart circle bigger by adjusting the marker size\n",
    "    fig.update_traces(\n",
    "        marker=dict(line=dict(color='white', width=2)),  # Optional: Add a white border\n",
    "        textposition='inside',  # Display text inside the slices\n",
    "        textinfo='percent+label'  # Show percentage and label\n",
    "    )\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".png\", delete=False) as tmpfile:\n",
    "        fig.write_image(tmpfile.name, format=\"png\", width=800, height=400)\n",
    "        return tmpfile.name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category_errors_bar(error_df):\n",
    "    # Calculate the frequency of errors per category\n",
    "    error_freq_df = error_df.groupby(['category', 'error']).size().reset_index(name='frequency')\n",
    "\n",
    "    # Create the bar plot\n",
    "    fig = px.bar(\n",
    "        error_freq_df, \n",
    "        x=\"category\", \n",
    "        y=\"frequency\", \n",
    "        color=\"error\",  # Use a discrete color sequence\n",
    "        color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "        title=\"Frequência de tipos de erros por categoria\",\n",
    "        labels={'frequency': 'Frequency of Errors', 'category': 'Category'},\n",
    "    )\n",
    "\n",
    "    # Adjust layout to control bar width\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Category\",\n",
    "        yaxis_title=\"Frequency of Errors\",\n",
    "        barmode='stack',  \n",
    "        bargroupgap=0.1,  \n",
    "        width=600,\n",
    "        margin=dict(l=20, r=20, t=40, b=20)  \n",
    "    )\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".png\", delete=False) as tmpfile:\n",
    "        fig.write_image(tmpfile.name, format=\"png\", width=800, height=400)\n",
    "        return tmpfile.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categories_failures_passed_rate(status_freq_df):\n",
    "    # Calcular totais e percentuais\n",
    "    status_freq_df['Total'] = status_freq_df['PASSED'] + status_freq_df['FAILED']\n",
    "    status_freq_df['PASSED_pct'] = (status_freq_df['PASSED'] / status_freq_df['Total']) * 100\n",
    "    status_freq_df['FAILED_pct'] = (status_freq_df['FAILED'] / status_freq_df['Total']) * 100\n",
    "\n",
    "    # Transformar dados para formato longo\n",
    "    status_freq_long = status_freq_df.melt(\n",
    "        id_vars=['category'], \n",
    "        value_vars=['PASSED_pct', 'FAILED_pct'], \n",
    "        var_name='Status', \n",
    "        value_name='Percentage'\n",
    "    )\n",
    "\n",
    "    # Criar coluna com valores reais correspondentes\n",
    "    status_freq_long['Real Value'] = status_freq_long.apply(\n",
    "        lambda row: status_freq_df.loc[status_freq_df['category'] == row['category'], row['Status'].replace('_pct', '')].values[0], \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Criar gráfico\n",
    "    fig = px.bar(\n",
    "        status_freq_long, \n",
    "        x=\"category\", \n",
    "        y=\"Percentage\", \n",
    "        color=\"Status\", \n",
    "        barmode='stack', \n",
    "        title=\"Proporção de testes Aprovados/Falho\",\n",
    "        labels={'Percentage': 'Percentage'},\n",
    "        text=status_freq_long[\"Real Value\"]  # Exibir valores reais nas barras\n",
    "    )\n",
    "\n",
    "    # Ajustar layout para exibir os valores dentro das barras\n",
    "    fig.update_traces(texttemplate='%{text}', textposition='inside')\n",
    "    fig.update_yaxes(title='Percentage')\n",
    "    fig.update_xaxes(title='Category')\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".png\", delete=False) as tmpfile:\n",
    "        fig.write_image(tmpfile.name, format=\"png\", width=800, height=400)\n",
    "        return tmpfile.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_all_graphs():\n",
    "    return {\n",
    "        'category_errors_bar': plot_category_errors_bar(error_df),\n",
    "        'error_distribution_pie': error_distribution_pie_chart(error_distribution_df),\n",
    "        'failures_passed_rate': categories_failures_passed_rate(status_freq_df),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_pdf(df, df_errors):\n",
    "    # A4 size dimensions\n",
    "    width, height = A4\n",
    "\n",
    "    # Set 10% margin\n",
    "    margin = 0.1 * width\n",
    "\n",
    "    # Create PDF with margins\n",
    "    doc = SimpleDocTemplate(\"report_v0.pdf\", pagesize=A4,\n",
    "                            leftMargin=margin, rightMargin=margin, topMargin=0.1*height, bottomMargin=0.1*height)\n",
    "\n",
    "    # Styles\n",
    "    styles = getSampleStyleSheet()\n",
    "    heading_style = styles['Heading1']\n",
    "    normal_style = styles['Normal']\n",
    "    normal_style.alignment = 0  # 0 for left alignment\n",
    "\n",
    "    bold_style = ParagraphStyle(\n",
    "        name=\"Bold\",\n",
    "        parent=normal_style,\n",
    "        fontName=\"Helvetica-Bold\",\n",
    "        fontSize=12\n",
    "    )\n",
    "\n",
    "    # Create the story (content) for the PDF\n",
    "    story = []\n",
    "\n",
    "    # Add title with fields\n",
    "    story.extend(create_title(heading_style,normal_style))\n",
    "\n",
    "    # Add each section to the story\n",
    "    story.extend(create_execution_summary(df, normal_style, bold_style))\n",
    "    story.extend(create_detailed_results(df, normal_style, bold_style, width, margin))\n",
    "    story.extend(create_errors_summary(df_errors, normal_style, bold_style, width, margin))\n",
    "    story.extend(create_graphs(normal_style, bold_style, width, margin))\n",
    "    # Build PDF\n",
    "    doc.build(story)\n",
    "\n",
    "def create_title(heading_style, normal_style):\n",
    "    # Initialize the story list\n",
    "    story = []\n",
    "\n",
    "    # Get current date and time\n",
    "    agora = datetime.now()\n",
    "    horario_dia = agora.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "    # Create the title\n",
    "    title_text = \"Sumário de Resultados dos Testes\"\n",
    "    title_paragraph = Paragraph(f\"<b>{title_text}</b>\", heading_style)\n",
    "\n",
    "\n",
    "    # Add title and date to the story as separate elements\n",
    "    story.append(title_paragraph)\n",
    "\n",
    "    # Create the formatted text for the execution date, system version, and environment\n",
    "    execution_paragraph = Paragraph(f\"Data da Execução: {horario_dia}\", normal_style)\n",
    "    version_paragraph = Paragraph(\"Versão do Sistema: \", normal_style)\n",
    "    environment_paragraph = Paragraph(\"Ambiente: \", normal_style)\n",
    "\n",
    "    # Add other paragraphs to the story\n",
    "    story.append(execution_paragraph)\n",
    "    story.append(Spacer(1, 6))  # Spacer between execution and version\n",
    "    story.append(version_paragraph)\n",
    "    story.append(Spacer(1, 6))  # Spacer between version and environment\n",
    "    story.append(environment_paragraph)\n",
    "\n",
    "    story.append(Spacer(1, 18))  # Add space at the end\n",
    "\n",
    "    # Return the complete story\n",
    "    return story\n",
    "\n",
    "def create_execution_summary(df, normal_style, bold_style):\n",
    "    story = []\n",
    "    story.append(Paragraph(\"Resumo Geral\", bold_style))\n",
    "    story.append(Spacer(1, 6))\n",
    "\n",
    "    fail_success_rate = (df['num_failed'].sum() / df['num_passed'].sum() * 100).round(2)\n",
    "\n",
    "    # Criando a lista de resumo corretamente\n",
    "    summary_data = {\n",
    "        'Total de Testes:': df['total_runs'].sum(),\n",
    "        'Testes Bem-Sucedidos:': df['num_passed'].sum(),\n",
    "        'Testes com Falha:': df['num_failed'].sum(),\n",
    "        'Taxa de Sucessos/Falha:': f\"{fail_success_rate}%\",  # Round to 2 decimal places\n",
    "        'Tempo Mínimo de Execução:': f\"{df['min_test_time'].min():.2f} s\",\n",
    "        'Tempo Médio de Execução:': f\"{df['avg_test_time'].mean():.2f} s\",\n",
    "        'Duração Total dos Testes:': f\"{df['total_duration'].sum():.2f} s\"\n",
    "    }\n",
    "\n",
    "    # Criando a lista com bullet points\n",
    "    bullet_points = [\n",
    "        ListItem(Paragraph(f\"<b>{key}</b> {value}\", normal_style), leftIndent=20, spaceAfter=6)\n",
    "        for key, value in summary_data.items()\n",
    "    ]\n",
    "\n",
    "    # Criando o ListFlowable\n",
    "    list_flowable = ListFlowable(bullet_points, bulletType='bullet', leftIndent=20)\n",
    "\n",
    "    # Adicionando ao relatório\n",
    "    story.append(list_flowable)\n",
    "    story.append(Spacer(1, 24))\n",
    "\n",
    "    return story\n",
    "\n",
    "def create_detailed_results(df, normal_style, bold_style, width, margin):\n",
    "    story = []\n",
    "    story.append(Paragraph(\"Detalhamento dos Testes\", bold_style))\n",
    "    story.append(Spacer(1, 12))\n",
    "    df_renamed = df.copy()  # Create a copy of the DataFrame\n",
    "    df_renamed.columns = [\n",
    "        'Categoria de Teste', \n",
    "        'Testes Bem-Sucedidos', \n",
    "        'Falhas', \n",
    "        'Execuções', \n",
    "        'Tempo Mínimo de Execução', \n",
    "        'Tempo Médio', \n",
    "        'Duração Total'\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Dropping the specified columns\n",
    "    df_renamed = df_renamed.drop(columns=['Tempo Mínimo de Execução'])\n",
    "\n",
    "    df_renamed['Tempo Médio'] = df_renamed['Tempo Médio'].astype(str) + ' sec'\n",
    "    df_renamed['Duração Total'] = df_renamed['Duração Total'].astype(str) + ' sec'\n",
    "\n",
    "    # Prepare the detailed data for the table\n",
    "    detailed_tests_data = [[Paragraph(str(value), normal_style) for value in df_renamed.columns.tolist()]]  # Add header\n",
    "    detailed_tests_data.extend(\n",
    "        [[Paragraph(str(value), normal_style) for value in row] for row in df_renamed.values.tolist()]\n",
    "    )\n",
    "\n",
    "    # Calculate available width after applying margins\n",
    "    available_width = width - 2 * margin  # Subtracting left and right margins\n",
    "\n",
    "    # Define column proportions\n",
    "    proportions = [0.3, 0.15, 0.15, 0.15, 0.2, 0.15]  # Example proportions\n",
    "\n",
    "    total_proportion = sum(proportions)\n",
    "    if total_proportion > 1:\n",
    "        proportions = [p / total_proportion for p in proportions]  # Scale proportions to fit within 1\n",
    "\n",
    "    # Calculate column widths based on the available width\n",
    "    col_widths = [available_width * p for p in proportions]\n",
    "\n",
    "    # Create the table\n",
    "    detailed_table = Table(detailed_tests_data, colWidths=col_widths)\n",
    "    detailed_table.setStyle(TableStyle([('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "                                        ('GRID', (0, 0), (-1, -1), 0.5, colors.black)]))\n",
    "    story.append(detailed_table)\n",
    "    story.append(Spacer(1, 24))\n",
    "\n",
    "    return story\n",
    "\n",
    "def create_errors_summary(df, normal_style, bold_style, width, margin):\n",
    "    \"\"\"\n",
    "    Creates a summary of errors in a PDF document.\n",
    "\n",
    "    :param df: DataFrame containing error data.\n",
    "    :param normal_style: Style for normal text.\n",
    "    :param bold_style: Style for bold text.\n",
    "    :param width: Width of the page.\n",
    "    :param margin: Margin size.\n",
    "    :return: A list of elements to be added to the PDF.\n",
    "    \"\"\"\n",
    "    story = []\n",
    "    story.append(Paragraph(\"Resumo dos Erros\", bold_style))\n",
    "    story.append(Spacer(1, 12))\n",
    "\n",
    "    # Create a copy of the DataFrame and reset the index\n",
    "    df_copy = df.copy().reset_index()\n",
    "    df_copy.columns = [\n",
    "        'Nome',\n",
    "        'Status',\n",
    "        'Categoria do Teste',\n",
    "        'Tipo de erro',\n",
    "        'Detalhes do erro (100 caracteres)',\n",
    "        'JobId',\n",
    "    ]\n",
    "\n",
    "    df_copy = df_copy.drop('Detalhes do erro (100 caracteres)', axis=1)\n",
    "    display(df_copy)\n",
    "\n",
    "\n",
    "    # Prepare the detailed data for the table\n",
    "    detailed_tests_data = [[Paragraph(str(value), normal_style) for value in df_copy.columns.tolist()]]  # Add header\n",
    "    detailed_tests_data.extend(\n",
    "        [[Paragraph(str(value), normal_style) for value in row] for row in df_copy.values.tolist()]\n",
    "    )\n",
    "\n",
    "    # Calculate available width after applying margins\n",
    "    available_width = width - 2 * margin  # Subtracting left and right margins\n",
    "\n",
    "    # Define column proportions\n",
    "    proportions = [0.3, 0.15, 0.15, 0.15, 0.2, 0.1]  # Example proportions\n",
    "\n",
    "    # Calculate column widths based on the available width\n",
    "    col_widths = [available_width * p for p in proportions]\n",
    "\n",
    "    # Create the table\n",
    "    detailed_table = Table(detailed_tests_data, colWidths=col_widths)\n",
    "    detailed_table.setStyle(TableStyle([\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Center-align all cells\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, colors.black),  # Add grid lines\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),  # Bold header font\n",
    "    ]))\n",
    "    story.append(detailed_table)\n",
    "    story.append(Spacer(1, 24))\n",
    "\n",
    "    return story\n",
    "\n",
    "def create_graphs(normal_style, bold_style, width, margin):\n",
    "    graph_files = build_all_graphs()\n",
    "    story = []\n",
    "\n",
    "    # Add a title to the PDF\n",
    "    story.append(Spacer(1, 12))\n",
    "\n",
    "    story.append(Paragraph(\"Visualização de dados\", bold_style))\n",
    "    story.append(Spacer(1, 12))\n",
    "\n",
    "    # Add the bar chart to the PDF\n",
    "    story.append(Image(graph_files['category_errors_bar'], width=500, height=250))  # Adjust size as needed\n",
    "    story.append(Spacer(1, 24))\n",
    "\n",
    "    # Add the pie chart to the PDF\n",
    "    story.append(Image(graph_files['error_distribution_pie'], width=500, height=250))  # Adjust size as needed\n",
    "    story.append(Spacer(1, 24))\n",
    "\n",
    "    # Add the pass/fail rate bar chart to the PDF\n",
    "    story.append(Image(graph_files['failures_passed_rate'], width=500, height=250))  # Adjust size as needed\n",
    "    story.append(Spacer(1, 24))\n",
    "\n",
    "    return story\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids_in_date_range(df, initial_date, final_date):\n",
    "    # Convert the date strings to datetime objects with UTC timezone\n",
    "    initial_date = pd.to_datetime(initial_date, format=\"%d-%m-%Y\").tz_localize('UTC')\n",
    "    final_date = pd.to_datetime(final_date, format=\"%d-%m-%Y\").tz_localize('UTC')\n",
    "    \n",
    "    filtered_df = df[(df['createdAt'] >= initial_date) & (df['createdAt'] <= final_date)]\n",
    "\n",
    "    return filtered_df['databaseId'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = 'MagaluCloud/s3-specs'\n",
    "query_size = 2\n",
    "\n",
    "workflow = ActionsWorkflow(repository=repo_path, query_size=query_size)\n",
    "\n",
    "initial_date = \"16-01-2025\"\n",
    "final_date = \"21-03-2025\"\n",
    "workflowIds = get_ids_in_date_range(workflow.df, initial_date, final_date)\n",
    "\n",
    "jobs = ActionsJobs(repo_path)\n",
    "\n",
    "all_workflows_jobs = pd.DataFrame()\n",
    "\n",
    "for id in set(workflowIds):\n",
    "    tmp = jobs.get_jobs(id)\n",
    "    all_workflows_jobs = pd.concat([all_workflows_jobs, tmp])\n",
    "\n",
    "artifacts = ActionsArtifacts(workflowIds, repository=repo_path)\n",
    "all_tests_df = pd.DataFrame()\n",
    "all_times_df = pd.DataFrame()\n",
    "all_failures_df = pd.DataFrame()\n",
    "\n",
    "## Mudanca de logica, pegar valores dos workflowsIds checar quais deles nao existem nos valores unique retornados em um dos pytest e entao baixar os que faltarem\n",
    "\n",
    "for path in artifacts.paths:\n",
    "    artifact = extractor.PytestArtifactLogExtractor(path)\n",
    "    pytest_tests_status\t, pytest_run_times, pytest_failures_errors = artifact.log_to_df()\n",
    "    all_tests_df = pd.concat([all_tests_df, pytest_tests_status])\n",
    "    all_times_df = pd.concat([all_times_df, pytest_run_times])\n",
    "    all_failures_df = pd.concat([all_failures_df, pytest_failures_errors])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>num</th>\n",
       "      <th>avg</th>\n",
       "      <th>min</th>\n",
       "      <th>durationType</th>\n",
       "      <th>databaseId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pytest_run_times</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_delete_object_with_versions</th>\n",
       "      <td>28.407</td>\n",
       "      <td>4</td>\n",
       "      <td>6.844</td>\n",
       "      <td>6.413</td>\n",
       "      <td>teardown duration</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_delete_bucket_with_objects_with_versions</th>\n",
       "      <td>26.964</td>\n",
       "      <td>4</td>\n",
       "      <td>6.709</td>\n",
       "      <td>6.602</td>\n",
       "      <td>teardown duration</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_delete_object_with_versions</th>\n",
       "      <td>25.219</td>\n",
       "      <td>4</td>\n",
       "      <td>6.222</td>\n",
       "      <td>5.940</td>\n",
       "      <td>setup duration</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_delete_bucket_with_objects_with_versions</th>\n",
       "      <td>22.849</td>\n",
       "      <td>4</td>\n",
       "      <td>5.544</td>\n",
       "      <td>5.407</td>\n",
       "      <td>setup duration</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_delete_object_with_versions</th>\n",
       "      <td>7.212</td>\n",
       "      <td>4</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.109</td>\n",
       "      <td>call duration</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>existing_bucket_name</th>\n",
       "      <td>1.140</td>\n",
       "      <td>1</td>\n",
       "      <td>1.140</td>\n",
       "      <td>1.140</td>\n",
       "      <td>fixture duration</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bucket_with_lock_enabled</th>\n",
       "      <td>1.051</td>\n",
       "      <td>1</td>\n",
       "      <td>1.051</td>\n",
       "      <td>1.051</td>\n",
       "      <td>fixture duration</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bucket_with_one_object_and_lock_enabled</th>\n",
       "      <td>0.295</td>\n",
       "      <td>1</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.295</td>\n",
       "      <td>fixture duration</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>active_mgc_workspace</th>\n",
       "      <td>0.151</td>\n",
       "      <td>8</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>fixture duration</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_params</th>\n",
       "      <td>0.020</td>\n",
       "      <td>17</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>fixture duration</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1866 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                total num    avg    min  \\\n",
       "pytest_run_times                                                          \n",
       "test_delete_object_with_versions               28.407   4  6.844  6.413   \n",
       "test_delete_bucket_with_objects_with_versions  26.964   4  6.709  6.602   \n",
       "test_delete_object_with_versions               25.219   4  6.222  5.940   \n",
       "test_delete_bucket_with_objects_with_versions  22.849   4  5.544  5.407   \n",
       "test_delete_object_with_versions                7.212   4  1.667  1.109   \n",
       "...                                               ...  ..    ...    ...   \n",
       "existing_bucket_name                            1.140   1  1.140  1.140   \n",
       "bucket_with_lock_enabled                        1.051   1  1.051  1.051   \n",
       "bucket_with_one_object_and_lock_enabled         0.295   1  0.295  0.295   \n",
       "active_mgc_workspace                            0.151   8  0.008  0.008   \n",
       "test_params                                     0.020  17  0.001  0.001   \n",
       "\n",
       "                                                      durationType  \\\n",
       "pytest_run_times                                                     \n",
       "test_delete_object_with_versions                teardown duration    \n",
       "test_delete_bucket_with_objects_with_versions   teardown duration    \n",
       "test_delete_object_with_versions                   setup duration    \n",
       "test_delete_bucket_with_objects_with_versions      setup duration    \n",
       "test_delete_object_with_versions                    call duration    \n",
       "...                                                            ...   \n",
       "existing_bucket_name                             fixture duration    \n",
       "bucket_with_lock_enabled                         fixture duration    \n",
       "bucket_with_one_object_and_lock_enabled          fixture duration    \n",
       "active_mgc_workspace                             fixture duration    \n",
       "test_params                                      fixture duration    \n",
       "\n",
       "                                                databaseId  \n",
       "pytest_run_times                                            \n",
       "test_delete_object_with_versions               13269265723  \n",
       "test_delete_bucket_with_objects_with_versions  13269265723  \n",
       "test_delete_object_with_versions               13269265723  \n",
       "test_delete_bucket_with_objects_with_versions  13269265723  \n",
       "test_delete_object_with_versions               13269265723  \n",
       "...                                                    ...  \n",
       "existing_bucket_name                           13269265723  \n",
       "bucket_with_lock_enabled                       13269265723  \n",
       "bucket_with_one_object_and_lock_enabled        13269265723  \n",
       "active_mgc_workspace                           13269265723  \n",
       "test_params                                    13269265723  \n",
       "\n",
       "[1866 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('./bin/pytest.categories.log.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38442/2656498577.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame([1,2,1])\n",
    "df2 = pd.DataFrame([1,2,3])\n",
    "\n",
    "if df1.isin(df2) == True:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "error_distribution_df = all_tests_df[['category', 'status']]\n",
    "error_passed_info = error_distribution_df.groupby(['status','category']).value_counts()\n",
    "\n",
    "status_freq_df = pd.concat([error_passed_info.FAILED, error_passed_info.PASSED], axis=1).fillna(0).astype(int)\n",
    "status_freq_df.columns = ['FAILED','PASSED']\n",
    "status_freq_df = status_freq_df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'error_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m report_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([report_df, time_count_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     21\u001b[0m errors_df \u001b[38;5;241m=\u001b[39m all_failures_df\n\u001b[0;32m---> 23\u001b[0m \u001b[43mbuild_all_graphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m create_pdf(report_df, errors_df)\n",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m, in \u001b[0;36mbuild_all_graphs\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_all_graphs\u001b[39m():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m----> 3\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory_errors_bar\u001b[39m\u001b[38;5;124m'\u001b[39m: plot_category_errors_bar(\u001b[43merror_df\u001b[49m),\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_distribution_pie\u001b[39m\u001b[38;5;124m'\u001b[39m: error_distribution_pie_chart(error_distribution_df),\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailures_passed_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: categories_failures_passed_rate(status_freq_df),\n\u001b[1;32m      6\u001b[0m     }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'error_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate a tuple with the category name and the summed up values of all index of said class\n",
    "def get_time(metric):\n",
    "    return pd.Series(dict(map(lambda t, x: (x, all_times_df.loc[all_times_df.index == t, metric].sum()), all_tests_df.index.unique(), all_tests_df.category.unique())))\n",
    "\n",
    "total_times = get_time('total')\n",
    "avg_time_test = get_time('avg')\n",
    "min_test_time  = get_time('min')\n",
    "\n",
    "cpf_df = all_tests_df.groupby(['category','status']).size().unstack('status').fillna(0).astype(int)\n",
    "cpf_df['total'] = cpf_df.sum(axis=1)\n",
    "time_count_df = pd.concat([cpf_df['PASSED'], cpf_df['FAILED'], cpf_df['total'], min_test_time, avg_time_test, total_times], axis=1)\n",
    "time_count_df.columns = ['num_passed', 'num_failed', 'total_runs', 'min_test_time', 'avg_test_time', 'total_duration']\n",
    "time_count_df['avg_test_time'] = (time_count_df['avg_test_time'] / time_count_df['total_runs']).round(2) \n",
    "\n",
    "report_df = pd.DataFrame()\n",
    "report_df['name'] = all_tests_df['category'].unique()\n",
    "report_df = report_df.set_index('name')\n",
    "\n",
    "# dfs used on pdf\n",
    "report_df = pd.concat([report_df, time_count_df], axis=1).reset_index().round(2)\n",
    "errors_df = all_failures_df\n",
    "\n",
    "build_all_graphs()\n",
    "create_pdf(report_df, errors_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error distribution (Pie chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_distribution_df = all_tests_df[['category', 'status']]\n",
    "error_passed_info = error_distribution_df.groupby(['status','category']).value_counts()\n",
    "\n",
    "status_freq_df = pd.concat([error_passed_info.FAILED, error_passed_info.PASSED], axis=1).fillna(0).astype(int)\n",
    "status_freq_df.columns = ['FAILED','PASSED']\n",
    "status_freq_df = status_freq_df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_distribution_pie_chat(error_df):\n",
    "    # Filter for FAILED status\n",
    "    failed_df = error_df[error_df['status'] == 'FAILED']\n",
    "\n",
    "    # Group by category and count the number of FAILED statuses\n",
    "    failed_counts = failed_df.groupby('category').size().reset_index(name='count')\n",
    "\n",
    "    # Create the pie chart\n",
    "    fig = px.pie(\n",
    "        failed_counts, \n",
    "        names=\"category\",  # Use 'category' for pie slice labels\n",
    "        values=\"count\",    # Use 'count' for pie slice sizes\n",
    "        title=\"Distribution of FAILED Tests by Category\",\n",
    "        color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "    #   width=400,  # Set the width of the plot (in pixels)\n",
    "    #  height=400,  # Set the height of the plot (in pixels)\n",
    "        margin=dict(l=20, r=20, t=40, b=20)  # Adjust margins if needed\n",
    "    )\n",
    "\n",
    "    # Make the pie chart circle bigger by adjusting the marker size\n",
    "    fig.update_traces(\n",
    "        marker=dict(line=dict(color='white', width=2)),  # Optional: Add a white border\n",
    "        textposition='inside',  # Display text inside the slices\n",
    "        textinfo='percent+label'  # Show percentage and label\n",
    "    )\n",
    "\n",
    "    # Show the pie chart\n",
    "    fig.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_distribution_pie_chat_plt(error_df):\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.pie(\n",
    "        error_passed_info['FAILED'].values,\n",
    "        labels=error_passed_info['FAILED'].index.to_list(),\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=90,\n",
    "        colors=['firebrick', 'lightgreen', 'lightskyblue'],\n",
    "    )\n",
    "    plt.legend(title=\"Error Types\", loc=\"upper right\", bbox_to_anchor=(1.3, 1))\n",
    "    plt.title('Failure Distribution')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion of Passed/Failed (%) with Real Values Displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcular totais e percentuais\n",
    "status_freq_df['Total'] = status_freq_df['PASSED'] + status_freq_df['FAILED']\n",
    "status_freq_df['PASSED_pct'] = (status_freq_df['PASSED'] / status_freq_df['Total']) * 100\n",
    "status_freq_df['FAILED_pct'] = (status_freq_df['FAILED'] / status_freq_df['Total']) * 100\n",
    "\n",
    "# Transformar dados para formato longo\n",
    "status_freq_long = status_freq_df.melt(\n",
    "    id_vars=['category'], \n",
    "    value_vars=['PASSED_pct', 'FAILED_pct'], \n",
    "    var_name='Status', \n",
    "    value_name='Percentage'\n",
    ")\n",
    "\n",
    "# Criar coluna com valores reais correspondentes\n",
    "status_freq_long['Real Value'] = status_freq_long.apply(\n",
    "    lambda row: status_freq_df.loc[status_freq_df['category'] == row['category'], row['Status'].replace('_pct', '')].values[0], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Criar gráfico\n",
    "fig = px.bar(\n",
    "    status_freq_long, \n",
    "    x=\"category\", \n",
    "    y=\"Percentage\", \n",
    "    color=\"Status\", \n",
    "    barmode='stack', \n",
    "    title=\"Proportion of Passed/Failed (%) with Real Values Displayed\",\n",
    "    labels={'Percentage': 'Percentage'},\n",
    "    text=status_freq_long[\"Real Value\"]  # Exibir valores reais nas barras\n",
    ")\n",
    "\n",
    "# Ajustar layout para exibir os valores dentro das barras\n",
    "fig.update_traces(texttemplate='%{text}', textposition='inside')\n",
    "fig.update_yaxes(title='Percentage')\n",
    "fig.update_xaxes(title='Category')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error type rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category_errors_bar(df):\n",
    "    # Calculate the frequency of errors per category\n",
    "    error_freq_df = df.groupby(['category', 'error']).size().reset_index(name='frequency')\n",
    "\n",
    "    # Create the bar plot\n",
    "    fig = px.bar(\n",
    "        error_freq_df, \n",
    "        x=\"category\", \n",
    "        y=\"frequency\", \n",
    "        color=\"error\",  # Use a discrete color sequence\n",
    "        color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "        title=\"Frequency of Errors by Category\",\n",
    "        labels={'frequency': 'Frequency of Errors', 'category': 'Category'},\n",
    "    )\n",
    "\n",
    "    # Adjust layout to control bar width\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Category\",\n",
    "        yaxis_title=\"Frequency of Errors\",\n",
    "        barmode='stack',  \n",
    "        bargroupgap=0.1,  \n",
    "        width=600,\n",
    "        margin=dict(l=20, r=20, t=40, b=20)  \n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
