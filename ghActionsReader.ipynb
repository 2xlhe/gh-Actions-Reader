{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "from itertools import chain\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArqManipulation:\n",
    "    \"\"\"\n",
    "    A utility class for file operations and data manipulation.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod \n",
    "    def read_parquet_file(parquet_file_name: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Reads a Parquet file and returns a DataFrame.\n",
    "\n",
    "        :param parquet_file_name: Path to the Parquet file.\n",
    "        :return: DataFrame with file contents.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(parquet_file_name):\n",
    "                print(f\"File '{parquet_file_name}' does not exist.\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            return pd.read_parquet(parquet_file_name)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error reading Parquet file '{parquet_file_name}': {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def save_df_to_parquet(df: pd.DataFrame, parquet_file_name: str):\n",
    "        \"\"\"\n",
    "        Saves a DataFrame to a Parquet file.\n",
    "\n",
    "        :param df: Dataframe to save.\n",
    "        :param parquet_file_name: Parqueet saving path.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(parquet_file_name), exist_ok=True)\n",
    "            df.to_parquet(parquet_file_name)\n",
    "            print(f\"DataFrame successfully saved to {parquet_file_name}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error saving DataFrame to Parquet file '{parquet_file_name}': {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_ansi_escape(base_str: str) -> str:\n",
    "        \"\"\"\n",
    "        Removes ANSI escape values from a string.\n",
    "\n",
    "        :param base_str: Unformmated string.\n",
    "        :return: Cleaned string.\n",
    "        \"\"\"\n",
    "        return re.sub(r'\\x1B\\[[0-9;]*[A-Za-z]', '', base_str)\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_stdout_json(base_str: str) -> dict:\n",
    "        \"\"\"\n",
    "        Parses JSON output from GitHub CLI after cleaning ANSI escape sequences.\n",
    "\n",
    "        :param base_str: The raw output string from the GitHub CLI.\n",
    "        :return: Parsed JSON dictionary.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            cleaned = ArqManipulation.clean_ansi_escape(base_str)\n",
    "            str_output = ''.join(cleaned.splitlines())\n",
    "            return json.loads(str_output)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise e\n",
    "\n",
    "    @staticmethod\n",
    "    def json_to_df(parsed_json: dict) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Converts a JSON dictionary to a sorted DataFrame with specific columns.\n",
    "\n",
    "        :param parsed_json: Parsed JSON data.\n",
    "        :return: Pandas DataFrame sorted by the 'createdAt' column.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df_json = pd.DataFrame(parsed_json)\n",
    "            required_columns = ['name', 'createdAt', 'conclusion', 'status', 'databaseId', 'workflowDatabaseId']\n",
    "            \n",
    "            if not all(col in df_json.columns for col in required_columns):\n",
    "                raise KeyError(f\"Missing required columns in JSON data: {set(required_columns) - set(df_json.columns)}\")\n",
    "\n",
    "            df_json['createdAt'] = pd.to_datetime(df_json['createdAt'])\n",
    "            return df_json[required_columns].sort_values(by=\"createdAt\")\n",
    "        except KeyError as e:\n",
    "            raise ValueError(f\"Error processing JSON to DataFrame: {e}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Unexpected error in json_to_df: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionsWorkflow:\n",
    "    \"\"\"\n",
    "    A class to extract GitHub Actions workflows using the GitHub CLI, generating a dataframe with returned data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, repository, query_size):\n",
    "        \"\"\"\n",
    "        Initializes the ActionsWorkflow class.\n",
    "\n",
    "        :param repository: GitHub repository in the format \"owner/repo\".\n",
    "        :param query_size: Number of workflows to retrieve.\n",
    "        \"\"\"\n",
    "        self.repository = repository\n",
    "        self.json_attributes = '--json name,status,conclusion,createdAt,databaseId,workflowDatabaseId'\n",
    "        self.query_size = query_size\n",
    "        self.df = self.__gh_list_query__()\n",
    "\n",
    "    def __gh_list_query__(self):\n",
    "        \"\"\"\n",
    "        Calls the GitHub API via the GitHub CLI (`gh run list`) and retrieves\n",
    "        a specified number of workflows.\n",
    "\n",
    "        :return: A DataFrame containing the parsed workflow data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            list_command = f'gh run --repo {self.repository} list {self.json_attributes} -L {self.query_size}'\n",
    "            \n",
    "            output_json = subprocess.run(\n",
    "                list_command, shell=True, text=True, check=True, capture_output=True\n",
    "            ).stdout\n",
    "\n",
    "            parsed_json = ArqManipulation.parse_stdout_json(output_json)\n",
    "            df = ArqManipulation.json_to_df(parsed_json)\n",
    "\n",
    "            ArqManipulation.save_df_to_parquet(df = df, parquet_file_name=\"./bin/actionsWorflow.parquet\")\n",
    "\n",
    "            return df.set_index('name')\n",
    "\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error executing GitHub CLI command: {e}\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame on error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionsJobs:\n",
    "    \"\"\"\n",
    "    A class to interact with GitHub Actions jobs using the GitHub CLI.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, repository, workflow):\n",
    "        \"\"\"\n",
    "        Initializes the ActionsJobs class.\n",
    "\n",
    "        :param repository: GitHub repository in the format \"owner/repo\".\n",
    "        :param workflow: Workflow associated with the jobs.\n",
    "        \"\"\"\n",
    "        self.repository = repository\n",
    "        self.workflow = workflow  \n",
    "\n",
    "    def __retrieve_jobs__(self, database_id: int):\n",
    "        command = f'gh run --repo {self.repository} view {database_id}'\n",
    "        jobs_data = subprocess.run(command, shell=True, text=True, check=True, capture_output=True).stdout\n",
    "\n",
    "        return jobs_data\n",
    "\n",
    "    def get_jobs(self, database_id: int) -> pd.DataFrame:\n",
    "            \"\"\"\n",
    "            Retrieves job data from the GitHub CLI and processes it.\n",
    "\n",
    "            :param database_id: The ID of the workflow run.\n",
    "            :return: A Pandas DataFrame containing job details.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                jobs_df = ArqManipulation.read_parquet_file(parquet_file_name=\"./bin/actionsJobs.parquet\")\n",
    "\n",
    "                if jobs_df.empty:\n",
    "                    data = self.__retrieve_jobs__(database_id=database_id)\n",
    "                    jobs_df = self.__clean_job_text__(data)\n",
    "\n",
    "                    jobs_df[\"databaseId\"] = int(database_id)\n",
    "\n",
    "                    ArqManipulation.save_df_to_parquet(jobs_df, parquet_file_name=\"./bin/actionsJobs.parquet\")\n",
    "\n",
    "                elif not database_id in jobs_df['databaseId'].values:\n",
    "                    data = self.__retrieve_jobs__(database_id=database_id)\n",
    "                    data_df = self.__clean_job_text__(data)\n",
    "                    data_df[\"databaseId\"] = int(database_id)\n",
    "\n",
    "                    jobs_df = pd.concat([jobs_df, data_df], ignore_index=True)\n",
    "\n",
    "                    ArqManipulation.save_df_to_parquet(jobs_df, parquet_file_name=\"./bin/actionsJobs.parquet\")\n",
    "\n",
    "                return jobs_df\n",
    "\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"Error executing GitHub CLI command: {e}\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "                return pd.DataFrame()\n",
    "        \n",
    "    def __split_string__(self, job_list):\n",
    "        \"\"\"\n",
    "        Splits a job string into structured components.\n",
    "\n",
    "        :param job: The job string to split.\n",
    "        :return: A list of cleaned job attributes.\n",
    "        \"\"\"\n",
    "        jobs = []\n",
    "\n",
    "        for job in job_list:\n",
    "            delimiters = r\" \\| | / build in | \\(ID |\\| in| / cleanup in | /| in \" \n",
    "            splitted_job = re.split(delimiters, job)\n",
    "            splitted_job = [s.strip() for s in splitted_job if s.strip()]\n",
    "            jobs.append(splitted_job)\n",
    "        \n",
    "        jobs.pop(0)\n",
    "\n",
    "        return jobs\n",
    "\n",
    "    def __build_cleaned_df__(self, data):\n",
    "        # Define columns\n",
    "        columns = [\"conclusion\", \"test\", \"buildTime (sec)\", \"jobId\"]\n",
    "        jobs_df = pd.DataFrame(columns=columns)\n",
    "        jobs_df[\"failedAt\"] = None\n",
    "\n",
    "        for job in data:\n",
    "            if any(\"ID\" in item and (\"PASSED\" in item or \"FAILED\" in item) for item in job):\n",
    "                temp_df = pd.DataFrame(self.__split_string__(job), columns=columns)\n",
    "\n",
    "                temp_df['buildTime (sec)'] = temp_df['buildTime (sec)'].apply(str_time_to_int)\n",
    "                jobs_df = pd.concat([jobs_df, temp_df], ignore_index=True)\n",
    "            \n",
    "            elif any(\"FAILED\" in item for item in job):\n",
    "                failed = next(item for item in job if \"FAILED\" in item).split(\"FAILED | \")\n",
    "                if not jobs_df.empty:\n",
    "                    jobs_df.at[jobs_df.index[-1], \"failedAt\"] = failed[1]  \n",
    "\n",
    "        jobs_df[\"jobId\"] = jobs_df[\"jobId\"].str.rstrip(\")\").astype('int')\n",
    "        return jobs_df\n",
    "\n",
    "\n",
    "    def __find_jobs__(self, base_str: str) -> list[str]:\n",
    "        lines = base_str.splitlines()\n",
    "        arr = []  # Stores grouped sections\n",
    "        current_group = []  # Temporary storage for the current section\n",
    "\n",
    "        for line in lines:\n",
    "            if line.isupper() or not line.strip():  # New section (uppercase or empty line)\n",
    "                if current_group:  # Avoid adding empty groups\n",
    "                    arr.append(current_group)\n",
    "                current_group = [line]  # Start a new group\n",
    "            else:\n",
    "                current_group.append(line)\n",
    "\n",
    "        if current_group:  # Append the last group\n",
    "            arr.append(current_group)\n",
    "\n",
    "        # Filter out groups that do not start with an uppercase title\n",
    "        filtered_arr = [group for group in arr if group and group[0].isupper()]\n",
    "        return filtered_arr\n",
    "\n",
    "    def __clean_job_text__(self, base_str: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Cleans and structures GitHub job data from CLI output.\n",
    "\n",
    "        :param base_str: Raw job text output from the GitHub CLI.\n",
    "        :return: A Pandas DataFrame with structured job data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Remove ANSI escape sequences and unwanted characters\n",
    "            ansi_cleaned = ArqManipulation.clean_ansi_escape(base_str)\n",
    "            cleaned = ansi_cleaned.replace(\"✓\", \"PASSED |\").replace(\"X\", \"FAILED |\")\n",
    "\n",
    "            stripped_list = self.__find_jobs__(cleaned)\n",
    "\n",
    "            if not (x.find('JOBS') or x.find(\"ANNOTATIONS\") for x in stripped_list):\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            jobs_df = self.__build_cleaned_df__(stripped_list)\n",
    "\n",
    "            return jobs_df\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing job text: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    \n",
    "\n",
    "def str_time_to_int(time_str: str) -> int:\n",
    "    \"\"\"\n",
    "    Converts a time string to seconds.\n",
    "    returns: int\n",
    "    \"\"\"\n",
    "    names = ['d', 'h', 'm', 's']\n",
    "    seconds = [86400, 3600, 60, 1]\n",
    "\n",
    "    total_time = 0\n",
    "\n",
    "    for m, t in zip(names,seconds):\n",
    "        if m in time_str:\n",
    "            time_list = time_str.split(m)\n",
    "            total_time +=  int(time_list[0]) * t\n",
    "            time_str = time_list[1]\n",
    "\n",
    "    return total_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionsArtifacts:\n",
    "    \"\"\"\n",
    "    A class to handle downloading, retrieving, and deleting GitHub Actions artifacts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, repository: str):\n",
    "        \"\"\"\n",
    "        Initializes the ActionsArtifacts object.\n",
    "\n",
    "        :param repository: The GitHub repository in the format \"owner/repo\".\n",
    "        \"\"\"\n",
    "        self.repository = repository\n",
    "        self.folder = './artifacts/'  # Default storage dir\n",
    "        self.paths = self.retrieve_downloaded_artifacts() \n",
    "\n",
    "    def download_artifact(self, database_id: str):\n",
    "        \"\"\"\n",
    "        Downloads an artifact from GitHub Actions using the GitHub CLI.\n",
    "\n",
    "        :param database_id: The database ID of the artifact to download.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Ensure the folder exists before downloading\n",
    "            os.makedirs(self.folder, exist_ok=True)\n",
    "\n",
    "            # Construct the command to download the artifact\n",
    "            command = f'gh run --repo {self.repository} download {database_id} --dir {os.path.join(self.folder, str(database_id))}'\n",
    "\n",
    "            # Execute the command\n",
    "            subprocess.run(command, shell=True, text=True, check=True)\n",
    "            print(\"Download Successful\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error during artifact download: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "\n",
    "    def retrieve_downloaded_artifacts(self) -> list[str]:\n",
    "        \"\"\"\n",
    "        Retrieves all downloaded artifacts file paths.\n",
    "\n",
    "        :return: returns Paths of the downloaded artifacts\n",
    "        \"\"\"\n",
    "        paths = []\n",
    "\n",
    "        # Walk through the artifacts folder and collect all file paths\n",
    "        for path, _, files in os.walk(self.folder):\n",
    "            for file in files:\n",
    "                paths.append(os.path.join(path, file))\n",
    "\n",
    "        return paths\n",
    "\n",
    "    def delete_downloaded_artifacts(self):\n",
    "        \"\"\"\n",
    "        Deletes all downloaded artifacts recursively\n",
    "        \"\"\"\n",
    "        try:\n",
    "            shutil.rmtree(self.folder)\n",
    "            if os.path.exists(self.folder):\n",
    "                print(\"Error: Failed to delete artifacts directory.\")\n",
    "            else:\n",
    "                print(\"Artifacts directory deleted successfully.\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"Artifacts directory not found, nothing to delete.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while deleting artifacts: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytestArtifactLogExtractor:\n",
    "    \"\"\"\n",
    "    A class to extract and process test status and timing information from a pytest artifact log.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str):\n",
    "        \"\"\"\n",
    "        Initializes the PytestArtifactLogExtractor object.\n",
    "\n",
    "        :param path: Path to the pytest artifact log file.\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.data = self.__read_file__()\n",
    "\n",
    "    def __read_file__(self):\n",
    "        \"\"\"\n",
    "        Reads the contents of the log file and returns it as a string.\n",
    "\n",
    "        :return: String containing the file content.\n",
    "        \"\"\"\n",
    "        with open(self.path, \"r\") as file: \n",
    "            data = file.read()\n",
    "\n",
    "        return ArqManipulation.clean_ansi_escape(data)\n",
    "\n",
    "    def log_to_df(self):\n",
    "        \"\"\"\n",
    "        Parses the log file to extract test results and performance metrics.\n",
    "\n",
    "        :return: A DataFrame combining test statuses with time metrics.\n",
    "        \"\"\"\n",
    "\n",
    "        df_parquet = ArqManipulation.read_parquet_file(parquet_file_name='pytest.log.parquet')   \n",
    "\n",
    "        databaseId = self.__extract_self_path_info__().get('databaseId').get(0)\n",
    "        databaseId = int(databaseId) if databaseId else None \n",
    "    \n",
    "        if not df_parquet.empty and (databaseId in df_parquet['databaseId']):\n",
    "            return df_parquet\n",
    "\n",
    "        tests, categories, failures = self.__extract_all_categories__()\n",
    "        \n",
    "        # Creating dataframes test status and categories\n",
    "        status_df = pd.DataFrame(tests, columns=[\"status\", \"name\", \"category\", \"arguments\"]).set_index('name')\n",
    "        categories_df = self.__create_df__(categories)\n",
    "        failures_df = pd.DataFrame(failures,columns=['name', 'category', 'arguments', 'error', 'error_details']).set_index('name')\n",
    "\n",
    "        # Labeling the dfs\n",
    "        status_df.index.name = 'pytest_tests_status'\n",
    "        categories_df.index.name = 'pytest_run_times'\n",
    "        failures_df.index.name = 'pytest_failures_errors'\n",
    "\n",
    "        # Applying individual id for each table\n",
    "        status_df['databaseId'] = databaseId\n",
    "        categories_df['databaseId'] = databaseId\n",
    "        failures_df['databaseId'] = databaseId\n",
    "\n",
    "\n",
    "        return status_df, categories_df, failures_df\n",
    "\n",
    "    def __extract_all_categories__(self):\n",
    "        \"\"\"\n",
    "        Converts extracted timing data into DataFrames.\n",
    "\n",
    "        :param values: A list of lists with extracted time metrics.\n",
    "        :type values: list[list]\n",
    "        :return: A list of DataFrames with execution time statistics.\n",
    "        :rtype: list[pandas.DataFrame]\n",
    "        \"\"\"\n",
    "        header = []\n",
    "        # Filtering out irrelevant categories\n",
    "        keywords = ('deselected', 'passed in', 'grand total', 'live log')\n",
    "\n",
    "        values = self.data.splitlines()\n",
    "        for value in values:\n",
    "            if any(k in value for k in keywords):\n",
    "                continue   \n",
    "            elif re.match(r'=+|-+', value): # Divide by headers demarked by '=' or '-' (logging)\n",
    "                value = value.replace(\"=\", \"\")  \n",
    "                value = value.replace(\"-\", \"\")  \n",
    "                header.append([value]) \n",
    "            else:\n",
    "                # Populate each category and break in the case of the pytest-durations tables while ignoring empty values\n",
    "                value = re.split(r\"\\s+\", value) \n",
    "                if list(filter(None, value)):\n",
    "                    header[-1].append(list(filter(None, value)))\n",
    "\n",
    "        headers = [['live_log','live_log','live_log']]\n",
    "        if not 'live log' in self.data:\n",
    "            headers = self.__extract_test_status_names__(self.__get_list_by_name__(header, 'session')[0])\n",
    "            \n",
    "        categories = self.__get_list_by_name__(header, 'duration top')\n",
    "        failures = self.__extract_failures_errors__(self.__get_list_by_name__(header, 'summary')[0])\n",
    "\n",
    "        return headers, categories, failures\n",
    "\n",
    "    def __get_list_by_name__(self, data: list, name: str):\n",
    "        \"\"\"\n",
    "        Find the sublist containing the specified name in the first element.\n",
    "\n",
    "        :param data: A list of sublists to search through.\n",
    "        :type data: list[list]\n",
    "        :param name: The name to search for in the first element of each sublist.\n",
    "        :type name: str\n",
    "        :return: A list of sublists where the first element matches the name.\n",
    "        :rtype: list[list]\n",
    "        \"\"\"\n",
    "        matching_sublists = []\n",
    "        \n",
    "        for sublist in data:\n",
    "            if re.search(name, sublist[0]):  # Converte os itens para string\n",
    "                matching_sublists.append(sublist)\n",
    "        \n",
    "        return matching_sublists\n",
    "\n",
    "    def __extract_test_status_names__(self, data):\n",
    "        \"\"\"\n",
    "        Extracts the status and the tests names out of the pytest log, breaking them down to a list of lists.\n",
    "\n",
    "        :param data: A list of lines containing test results.\n",
    "        :type data: list[str]\n",
    "        :return: list[list[str]]: A list of lists with test names, statuses (PASSED, FAILED, ERROR), and additional details.\n",
    "        \"\"\"\n",
    "\n",
    "        tests = []\n",
    "        keywords = ('PASSED', 'FAILED', 'ERROR')\n",
    "\n",
    "        for line in data:\n",
    "            line = ''.join(line).strip()\n",
    "            \n",
    "            if any(k in line for k in keywords):\n",
    "                line = re.sub(r'\\[.*?\\d%\\]', '', line)\n",
    "                parts = line.split('::', maxsplit=1)\n",
    "\n",
    "                match = re.search(r'(PASSED|FAILED|ERROR)', parts[0])\n",
    "                if match:\n",
    "                    test_name = parts[0][:match.start()].strip()\n",
    "                    status = match.group(0)\n",
    "                else:\n",
    "                    test_name, status = parts[0], None\n",
    "\n",
    "                tmp = [test_name, status]\n",
    "\n",
    "                if len(parts) > 1:\n",
    "                    values = list(filter(None, re.split(r'\\[(.*?)\\]', parts[1])))\n",
    "                    tmp += values\n",
    "                \n",
    "                while len(tmp) < 4:\n",
    "                    tmp.append(None)\n",
    "\n",
    "                tests.append(tmp)\n",
    "        \n",
    "        return tests\n",
    "\n",
    "    def __extract_failures_errors__(self, data):\n",
    "\n",
    "        \"\"\"\n",
    "        Extracts from the pytest log the details of tests with failures or errors cleaning the data to make it ready to a dataframe.\n",
    "\n",
    "        :param data: A list of strings containing test results.\n",
    "        :type data: list[str]\n",
    "        :return: list[list]: A list of lists containing details of tests with failures and/or errors.\n",
    "        \"\"\"\n",
    "\n",
    "        # Regex asks for a string, cleaning it and concatening the list\n",
    "        data_str = ''.join(list(''.join(d) for d in data[1:]))\n",
    "        data_str = list(filter(None, re.split(r'(FAILED|ERROR)', data_str)))\n",
    "\n",
    "        splitted_data = []\n",
    "\n",
    "        # Splitting test from error\n",
    "        for d in data_str:\n",
    "            if d and ('FAILED' or 'ERROR') not in d:\n",
    "                splitted_data.append(list(filter(None, re.split(r'\\[(.*?)\\]-|::|(\\w+):([\\w=*]+)', d))))   \n",
    "\n",
    "        return splitted_data\n",
    "\n",
    "    def __create_df__(self, values):\n",
    "        \"\"\"\n",
    "        Converts extracted timing information into DataFrames.\n",
    "\n",
    "        :param values: A list of lists containing extracted time metrics.\n",
    "        :return: A list of DataFrames with execution time statistics.\n",
    "        \"\"\"\n",
    "        dfs = pd.DataFrame()\n",
    "        \n",
    "        for h in values:\n",
    "            time_df = pd.DataFrame(h[2:], columns=h[1])\n",
    "\n",
    "            # Converting time-related columns to datetime.time format\n",
    "            time_columns = ['avg', 'min', 'total']\n",
    "            for col in time_columns:\n",
    "                if col in time_df.columns:\n",
    "                    time_df[col] = pd.to_timedelta(time_df[col], errors='coerce').dt.total_seconds().round(3)\n",
    "                    \n",
    "            # Assigning a 'durationType' column for metric categorization\n",
    "            time_df['durationType'] = h[0].replace('top', '').replace('test', '')\n",
    "\n",
    "            dfs = pd.concat([time_df, dfs], ignore_index=True)\n",
    "\n",
    "        if 'name' in dfs.columns:\n",
    "            dfs = dfs.set_index('name') \n",
    "\n",
    "        return dfs\n",
    "\n",
    "    def __extract_self_path_info__(self):\n",
    "        \"\"\"\n",
    "        Extracts test and database ID information from the log file path.\n",
    "\n",
    "        :return: A DataFrame containing 'test' and 'databaseId' information.\n",
    "        \"\"\"\n",
    "        # Extract filename without extension\n",
    "        stripped = self.path.split('/')[-1].split('.')\n",
    "        stripped.pop()  # Remove the file extension\n",
    "\n",
    "        # Ensure there are exactly three elements (fill missing ones with None)\n",
    "        while len(stripped) < 3:\n",
    "            stripped.append(None)  # Fill missing values with NaN\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame([stripped], columns=['test', 'region', 'databaseId'])\n",
    "\n",
    "        return df\n",
    "\n",
    "    def __merge_artifact_dfs__(self, times_df, status_df):\n",
    "        \"\"\"\n",
    "        Merges test execution time data with test status information.\n",
    "\n",
    "        :param times_df: A list of DataFrames containing time-related data.\n",
    "        :param status_df: A DataFrame containing test statuses.\n",
    "        :return: A combined DataFrame containing execution metrics and test results.\n",
    "        \"\"\"\n",
    "        databaseId_df = self.__extract_self_path_info__()  \n",
    "        order = ['category', 'durationType', 'databaseId', 'status', 'num', 'avg', 'min', 'total']\n",
    "        dfs = []\n",
    "\n",
    "        for h in times_df:\n",
    "            joined_df = h.join(status_df)  # Merging time metrics with test statuses\n",
    "\n",
    "            # Adding database ID to each row\n",
    "            for col in databaseId_df.columns.values:\n",
    "                joined_df[col] = databaseId_df[col].values[0]  \n",
    "\n",
    "            # Reordering columns\n",
    "            joined_df = joined_df[order]  \n",
    "            dfs.append(joined_df)\n",
    "\n",
    "        return pd.concat(dfs)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Main\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying and creating each dataframe and their respective classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully saved to ./bin/actionsWorflow.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>createdAt</th>\n",
       "      <th>conclusion</th>\n",
       "      <th>status</th>\n",
       "      <th>databaseId</th>\n",
       "      <th>workflowDatabaseId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pull Request Essential Tests</th>\n",
       "      <td>2025-02-11 14:42:01+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13265481705</td>\n",
       "      <td>132962917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Extra Tests</th>\n",
       "      <td>2025-02-11 14:42:01+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13265481700</td>\n",
       "      <td>142271933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Extra Tests</th>\n",
       "      <td>2025-02-11 17:37:25+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269014124</td>\n",
       "      <td>142271933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Essential Tests</th>\n",
       "      <td>2025-02-11 17:37:25+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269014120</td>\n",
       "      <td>132962917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Essential Tests</th>\n",
       "      <td>2025-02-11 17:39:58+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269057739</td>\n",
       "      <td>132962917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Extra Tests</th>\n",
       "      <td>2025-02-11 17:39:58+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269057738</td>\n",
       "      <td>142271933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Extra Tests</th>\n",
       "      <td>2025-02-11 17:45:26+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269149128</td>\n",
       "      <td>142271933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Essential Tests</th>\n",
       "      <td>2025-02-11 17:45:26+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269149127</td>\n",
       "      <td>132962917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Essential Tests</th>\n",
       "      <td>2025-02-11 17:52:13+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269265728</td>\n",
       "      <td>132962917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Extra Tests</th>\n",
       "      <td>2025-02-11 17:52:13+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269265723</td>\n",
       "      <td>142271933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             createdAt conclusion     status  \\\n",
       "name                                                                           \n",
       "Pull Request Essential Tests 2025-02-11 14:42:01+00:00    success  completed   \n",
       "Pull Request Extra Tests     2025-02-11 14:42:01+00:00    success  completed   \n",
       "Pull Request Extra Tests     2025-02-11 17:37:25+00:00    success  completed   \n",
       "Pull Request Essential Tests 2025-02-11 17:37:25+00:00    success  completed   \n",
       "Pull Request Essential Tests 2025-02-11 17:39:58+00:00    success  completed   \n",
       "Pull Request Extra Tests     2025-02-11 17:39:58+00:00    success  completed   \n",
       "Pull Request Extra Tests     2025-02-11 17:45:26+00:00    success  completed   \n",
       "Pull Request Essential Tests 2025-02-11 17:45:26+00:00    success  completed   \n",
       "Pull Request Essential Tests 2025-02-11 17:52:13+00:00    success  completed   \n",
       "Pull Request Extra Tests     2025-02-11 17:52:13+00:00    success  completed   \n",
       "\n",
       "                               databaseId  workflowDatabaseId  \n",
       "name                                                           \n",
       "Pull Request Essential Tests  13265481705           132962917  \n",
       "Pull Request Extra Tests      13265481700           142271933  \n",
       "Pull Request Extra Tests      13269014124           142271933  \n",
       "Pull Request Essential Tests  13269014120           132962917  \n",
       "Pull Request Essential Tests  13269057739           132962917  \n",
       "Pull Request Extra Tests      13269057738           142271933  \n",
       "Pull Request Extra Tests      13269149128           142271933  \n",
       "Pull Request Essential Tests  13269149127           132962917  \n",
       "Pull Request Essential Tests  13269265728           132962917  \n",
       "Pull Request Extra Tests      13269265723           142271933  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_path = 'MagaluCloud/s3-specs'\n",
    "query_size = 10\n",
    "\n",
    "workflow = ActionsWorkflow(repository=repo_path, query_size=query_size)\n",
    "workflow.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conclusion</th>\n",
       "      <th>test</th>\n",
       "      <th>buildTime (sec)</th>\n",
       "      <th>jobId</th>\n",
       "      <th>failedAt</th>\n",
       "      <th>databaseId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-se1.y...</td>\n",
       "      <td>2168</td>\n",
       "      <td>37043704535</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-ne1.y...</td>\n",
       "      <td>246</td>\n",
       "      <td>37043705230</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (acl, ../params/br-ne1.yaml, ...</td>\n",
       "      <td>398</td>\n",
       "      <td>37043705967</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (bucket_versioning, ../params...</td>\n",
       "      <td>118</td>\n",
       "      <td>37043706472</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (policy, ../params/br-ne1.yam...</td>\n",
       "      <td>165</td>\n",
       "      <td>37043706867</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup_tests</td>\n",
       "      <td>113</td>\n",
       "      <td>37045803570</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (basic, basic, ../params.example.yam...</td>\n",
       "      <td>87</td>\n",
       "      <td>37031740475</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (presign, presign, ../params.example...</td>\n",
       "      <td>73</td>\n",
       "      <td>37031741335</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (cold_storage, cold_storage, ../para...</td>\n",
       "      <td>83</td>\n",
       "      <td>37031742054</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>tests-success</td>\n",
       "      <td>0</td>\n",
       "      <td>37031853981</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup-tests</td>\n",
       "      <td>660</td>\n",
       "      <td>37031865199</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-ne1.y...</td>\n",
       "      <td>222</td>\n",
       "      <td>37031740446</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-se1.y...</td>\n",
       "      <td>10945</td>\n",
       "      <td>37031741305</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (bucket_versioning, ../params...</td>\n",
       "      <td>101</td>\n",
       "      <td>37031741997</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (acl, ../params/br-ne1.yaml, ...</td>\n",
       "      <td>323</td>\n",
       "      <td>37031742597</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (policy, ../params/br-ne1.yam...</td>\n",
       "      <td>156</td>\n",
       "      <td>37031743174</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup_tests</td>\n",
       "      <td>105</td>\n",
       "      <td>37044113674</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (basic, basic, ../params.example.yam...</td>\n",
       "      <td>91</td>\n",
       "      <td>37043704527</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (cold_storage, cold_storage, ../para...</td>\n",
       "      <td>76</td>\n",
       "      <td>37043705219</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (presign, presign, ../params.example...</td>\n",
       "      <td>67</td>\n",
       "      <td>37043705993</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>tests-success</td>\n",
       "      <td>0</td>\n",
       "      <td>37043801778</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup-tests</td>\n",
       "      <td>135</td>\n",
       "      <td>37043810257</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (presign, presign, ../params.example...</td>\n",
       "      <td>69</td>\n",
       "      <td>37043851890</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (basic, basic, ../params.example.yam...</td>\n",
       "      <td>92</td>\n",
       "      <td>37043852293</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (cold_storage, cold_storage, ../para...</td>\n",
       "      <td>76</td>\n",
       "      <td>37043852681</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>tests-success</td>\n",
       "      <td>0</td>\n",
       "      <td>37043951393</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup-tests</td>\n",
       "      <td>100</td>\n",
       "      <td>37043960162</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (bucket_versioning, ../params...</td>\n",
       "      <td>109</td>\n",
       "      <td>37043851761</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-ne1.y...</td>\n",
       "      <td>248</td>\n",
       "      <td>37043852208</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-se1.y...</td>\n",
       "      <td>2174</td>\n",
       "      <td>37043852553</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (acl, ../params/br-ne1.yaml, ...</td>\n",
       "      <td>362</td>\n",
       "      <td>37043852871</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (policy, ../params/br-ne1.yam...</td>\n",
       "      <td>168</td>\n",
       "      <td>37043853176</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup_tests</td>\n",
       "      <td>106</td>\n",
       "      <td>37045950987</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (acl, ../params/br-ne1.yaml, ...</td>\n",
       "      <td>395</td>\n",
       "      <td>37044161190</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (policy, ../params/br-ne1.yam...</td>\n",
       "      <td>189</td>\n",
       "      <td>37044161643</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (bucket_versioning, ../params...</td>\n",
       "      <td>122</td>\n",
       "      <td>37044161988</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-ne1.y...</td>\n",
       "      <td>281</td>\n",
       "      <td>37044162281</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-se1.y...</td>\n",
       "      <td>2336</td>\n",
       "      <td>37044162628</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup_tests</td>\n",
       "      <td>103</td>\n",
       "      <td>37046417463</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (cold_storage, cold_storage, ../para...</td>\n",
       "      <td>85</td>\n",
       "      <td>37044161130</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (basic, basic, ../params.example.yam...</td>\n",
       "      <td>96</td>\n",
       "      <td>37044161606</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (presign, presign, ../params.example...</td>\n",
       "      <td>69</td>\n",
       "      <td>37044161918</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>tests-success</td>\n",
       "      <td>0</td>\n",
       "      <td>37044262983</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup-tests</td>\n",
       "      <td>102</td>\n",
       "      <td>37044273275</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (basic, basic, ../params.example.yam...</td>\n",
       "      <td>90</td>\n",
       "      <td>37044549750</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (presign, presign, ../params.example...</td>\n",
       "      <td>74</td>\n",
       "      <td>37044550292</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (cold_storage, cold_storage, ../para...</td>\n",
       "      <td>75</td>\n",
       "      <td>37044550738</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>tests-success</td>\n",
       "      <td>0</td>\n",
       "      <td>37044639767</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup-tests</td>\n",
       "      <td>107</td>\n",
       "      <td>37044648883</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-ne1.y...</td>\n",
       "      <td>300</td>\n",
       "      <td>37044549759</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-se1.y...</td>\n",
       "      <td>2205</td>\n",
       "      <td>37044550263</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (acl, ../params/br-ne1.yaml, ...</td>\n",
       "      <td>466</td>\n",
       "      <td>37044550660</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (bucket_versioning, ../params...</td>\n",
       "      <td>119</td>\n",
       "      <td>37044550932</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (policy, ../params/br-ne1.yam...</td>\n",
       "      <td>181</td>\n",
       "      <td>37044551314</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup_tests</td>\n",
       "      <td>101</td>\n",
       "      <td>37046670818</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conclusion                                               test  \\\n",
       "0      PASSED  extra_tests_debug (locking, ../params/br-se1.y...   \n",
       "1      PASSED  extra_tests_debug (locking, ../params/br-ne1.y...   \n",
       "2      PASSED  extra_tests_dist (acl, ../params/br-ne1.yaml, ...   \n",
       "3      PASSED  extra_tests_dist (bucket_versioning, ../params...   \n",
       "4      PASSED  extra_tests_dist (policy, ../params/br-ne1.yam...   \n",
       "5      PASSED                                      cleanup_tests   \n",
       "6      PASSED  run_tests (basic, basic, ../params.example.yam...   \n",
       "7      PASSED  run_tests (presign, presign, ../params.example...   \n",
       "8      PASSED  run_tests (cold_storage, cold_storage, ../para...   \n",
       "9      PASSED                                      tests-success   \n",
       "10     PASSED                                      cleanup-tests   \n",
       "11     PASSED  extra_tests_debug (locking, ../params/br-ne1.y...   \n",
       "12     PASSED  extra_tests_debug (locking, ../params/br-se1.y...   \n",
       "13     PASSED  extra_tests_dist (bucket_versioning, ../params...   \n",
       "14     PASSED  extra_tests_dist (acl, ../params/br-ne1.yaml, ...   \n",
       "15     PASSED  extra_tests_dist (policy, ../params/br-ne1.yam...   \n",
       "16     PASSED                                      cleanup_tests   \n",
       "17     PASSED  run_tests (basic, basic, ../params.example.yam...   \n",
       "18     PASSED  run_tests (cold_storage, cold_storage, ../para...   \n",
       "19     PASSED  run_tests (presign, presign, ../params.example...   \n",
       "20     PASSED                                      tests-success   \n",
       "21     PASSED                                      cleanup-tests   \n",
       "22     PASSED  run_tests (presign, presign, ../params.example...   \n",
       "23     PASSED  run_tests (basic, basic, ../params.example.yam...   \n",
       "24     PASSED  run_tests (cold_storage, cold_storage, ../para...   \n",
       "25     PASSED                                      tests-success   \n",
       "26     PASSED                                      cleanup-tests   \n",
       "27     PASSED  extra_tests_dist (bucket_versioning, ../params...   \n",
       "28     PASSED  extra_tests_debug (locking, ../params/br-ne1.y...   \n",
       "29     PASSED  extra_tests_debug (locking, ../params/br-se1.y...   \n",
       "30     PASSED  extra_tests_dist (acl, ../params/br-ne1.yaml, ...   \n",
       "31     PASSED  extra_tests_dist (policy, ../params/br-ne1.yam...   \n",
       "32     PASSED                                      cleanup_tests   \n",
       "33     PASSED  extra_tests_dist (acl, ../params/br-ne1.yaml, ...   \n",
       "34     PASSED  extra_tests_dist (policy, ../params/br-ne1.yam...   \n",
       "35     PASSED  extra_tests_dist (bucket_versioning, ../params...   \n",
       "36     PASSED  extra_tests_debug (locking, ../params/br-ne1.y...   \n",
       "37     PASSED  extra_tests_debug (locking, ../params/br-se1.y...   \n",
       "38     PASSED                                      cleanup_tests   \n",
       "39     PASSED  run_tests (cold_storage, cold_storage, ../para...   \n",
       "40     PASSED  run_tests (basic, basic, ../params.example.yam...   \n",
       "41     PASSED  run_tests (presign, presign, ../params.example...   \n",
       "42     PASSED                                      tests-success   \n",
       "43     PASSED                                      cleanup-tests   \n",
       "44     PASSED  run_tests (basic, basic, ../params.example.yam...   \n",
       "45     PASSED  run_tests (presign, presign, ../params.example...   \n",
       "46     PASSED  run_tests (cold_storage, cold_storage, ../para...   \n",
       "47     PASSED                                      tests-success   \n",
       "48     PASSED                                      cleanup-tests   \n",
       "49     PASSED  extra_tests_debug (locking, ../params/br-ne1.y...   \n",
       "50     PASSED  extra_tests_debug (locking, ../params/br-se1.y...   \n",
       "51     PASSED  extra_tests_dist (acl, ../params/br-ne1.yaml, ...   \n",
       "52     PASSED  extra_tests_dist (bucket_versioning, ../params...   \n",
       "53     PASSED  extra_tests_dist (policy, ../params/br-ne1.yam...   \n",
       "54     PASSED                                      cleanup_tests   \n",
       "\n",
       "    buildTime (sec)        jobId failedAt   databaseId  \n",
       "0              2168  37043704535     None  13269014124  \n",
       "1               246  37043705230     None  13269014124  \n",
       "2               398  37043705967     None  13269014124  \n",
       "3               118  37043706472     None  13269014124  \n",
       "4               165  37043706867     None  13269014124  \n",
       "5               113  37045803570     None  13269014124  \n",
       "6                87  37031740475     None  13265481705  \n",
       "7                73  37031741335     None  13265481705  \n",
       "8                83  37031742054     None  13265481705  \n",
       "9                 0  37031853981     None  13265481705  \n",
       "10              660  37031865199     None  13265481705  \n",
       "11              222  37031740446     None  13265481700  \n",
       "12            10945  37031741305     None  13265481700  \n",
       "13              101  37031741997     None  13265481700  \n",
       "14              323  37031742597     None  13265481700  \n",
       "15              156  37031743174     None  13265481700  \n",
       "16              105  37044113674     None  13265481700  \n",
       "17               91  37043704527     None  13269014120  \n",
       "18               76  37043705219     None  13269014120  \n",
       "19               67  37043705993     None  13269014120  \n",
       "20                0  37043801778     None  13269014120  \n",
       "21              135  37043810257     None  13269014120  \n",
       "22               69  37043851890     None  13269057739  \n",
       "23               92  37043852293     None  13269057739  \n",
       "24               76  37043852681     None  13269057739  \n",
       "25                0  37043951393     None  13269057739  \n",
       "26              100  37043960162     None  13269057739  \n",
       "27              109  37043851761     None  13269057738  \n",
       "28              248  37043852208     None  13269057738  \n",
       "29             2174  37043852553     None  13269057738  \n",
       "30              362  37043852871     None  13269057738  \n",
       "31              168  37043853176     None  13269057738  \n",
       "32              106  37045950987     None  13269057738  \n",
       "33              395  37044161190     None  13269149128  \n",
       "34              189  37044161643     None  13269149128  \n",
       "35              122  37044161988     None  13269149128  \n",
       "36              281  37044162281     None  13269149128  \n",
       "37             2336  37044162628     None  13269149128  \n",
       "38              103  37046417463     None  13269149128  \n",
       "39               85  37044161130     None  13269149127  \n",
       "40               96  37044161606     None  13269149127  \n",
       "41               69  37044161918     None  13269149127  \n",
       "42                0  37044262983     None  13269149127  \n",
       "43              102  37044273275     None  13269149127  \n",
       "44               90  37044549750     None  13269265728  \n",
       "45               74  37044550292     None  13269265728  \n",
       "46               75  37044550738     None  13269265728  \n",
       "47                0  37044639767     None  13269265728  \n",
       "48              107  37044648883     None  13269265728  \n",
       "49              300  37044549759     None  13269265723  \n",
       "50             2205  37044550263     None  13269265723  \n",
       "51              466  37044550660     None  13269265723  \n",
       "52              119  37044550932     None  13269265723  \n",
       "53              181  37044551314     None  13269265723  \n",
       "54              101  37046670818     None  13269265723  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = ActionsJobs(repo_path, workflow)\n",
    "jobs.get_jobs(13269014124)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PASSED', 'cold_storage_test.py', 'test_boto_change_object_class_to_cold_storage', 'dasdasdasdsad]']\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "\n",
    "line = '[gw0] [ 80%] PASSED cold_storage_test.py::test_boto_change_object_class_to_cold_storage[dasdasdasdsad]'\n",
    "\n",
    "\n",
    "match = re.search(r'(PASSED|FAILED|ERROR).*', line).group()\n",
    "match = re.split(r'::', match, 1)\n",
    "tmp = re.split('\\s', match[0])\n",
    "tmp += re.split(r'\\[', match[1], maxsplit=1)\n",
    "\n",
    "print(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./artifacts/13269014120/output_artifact_cold_storage_example.13269014120.13269014120/pytest_output_cold_storage_example.13269014120.log',\n",
       " './artifacts/13269014120/output_artifact_presign_example.13269014120.13269014120/pytest_output_presign_example.13269014120.log',\n",
       " './artifacts/13269014120/output_artifact_basic_example.13269014120.13269014120/pytest_output_basic_example.13269014120.log',\n",
       " './artifacts/13269265728/output_artifact_basic.example.13269265728/pytest_output_basic.example.13269265728.log',\n",
       " './artifacts/13269265728/output_artifact_presign.example.13269265728/pytest_output_presign.example.13269265728.log',\n",
       " './artifacts/13269265728/output_artifact_cold_storage.example.13269265728/pytest_output_cold_storage.example.13269265728.log',\n",
       " './artifacts/13269057739/output_artifact_basic_example.13269057739/pytest_output_basic_example.13269057739.log',\n",
       " './artifacts/13269057739/output_artifact_cold_storage_example.13269057739/pytest_output_cold_storage_example.13269057739.log',\n",
       " './artifacts/13269057739/output_artifact_presign_example.13269057739/pytest_output_presign_example.13269057739.log',\n",
       " './artifacts/13269149128/output_artifact_acl.br_ne1.13269149128/pytest_output_acl.br_ne1.13269149128.log',\n",
       " './artifacts/13269149128/output_artifact_locking.br_se1.13269149128/pytest_output_locking.br_se1.13269149128.log',\n",
       " './artifacts/13269149128/output_artifact_bucket_versioning.br_ne1.13269149128/pytest_output_bucket_versioning.br_ne1.13269149128.log',\n",
       " './artifacts/13269149128/output_artifact_policy.br_ne1.13269149128/pytest_output_policy.br_ne1.13269149128.log',\n",
       " './artifacts/13269149128/output_artifact_locking.br_ne1.13269149128/pytest_output_locking.br_ne1.13269149128.log',\n",
       " './artifacts/13269014124/output_artifact_locking_br_se1.13269014124.13269014124/pytest_output_locking_br_se1.13269014124.log',\n",
       " './artifacts/13269014124/output_artifact_locking_br_ne1.13269014124.13269014124/pytest_output_locking_br_ne1.13269014124.log',\n",
       " './artifacts/13269014124/output_artifact_acl_br_ne1.13269014124.13269014124/pytest_output_acl_br_ne1.13269014124.log',\n",
       " './artifacts/13269014124/output_artifact_policy_br_ne1.13269014124.13269014124/pytest_output_policy_br_ne1.13269014124.log',\n",
       " './artifacts/13269014124/output_artifact_bucket_versioning_br_ne1.13269014124.13269014124/pytest_output_bucket_versioning_br_ne1.13269014124.log',\n",
       " './artifacts/13269149127/output_artifact_cold_storage.example.13269149127/pytest_output_cold_storage.example.13269149127.log',\n",
       " './artifacts/13269149127/output_artifact_basic.example.13269149127/pytest_output_basic.example.13269149127.log',\n",
       " './artifacts/13269149127/output_artifact_presign.example.13269149127/pytest_output_presign.example.13269149127.log',\n",
       " './artifacts/13269057738/output_artifact_policy_br_ne1.13269057738/pytest_output_policy_br_ne1.13269057738.log',\n",
       " './artifacts/13269057738/output_artifact_bucket_versioning_br_ne1.13269057738/pytest_output_bucket_versioning_br_ne1.13269057738.log',\n",
       " './artifacts/13269057738/output_artifact_locking_br_ne1.13269057738/pytest_output_locking_br_ne1.13269057738.log',\n",
       " './artifacts/13269057738/output_artifact_locking_br_se1.13269057738/pytest_output_locking_br_se1.13269057738.log',\n",
       " './artifacts/13269057738/output_artifact_acl_br_ne1.13269057738/pytest_output_acl_br_ne1.13269057738.log',\n",
       " './artifacts/13269265723/output_artifact_locking.br_ne1.13269265723/pytest_output_locking.br_ne1.13269265723.log',\n",
       " './artifacts/13269265723/output_artifact_acl.br_ne1.13269265723/pytest_output_acl.br_ne1.13269265723.log',\n",
       " './artifacts/13269265723/output_artifact_policy.br_ne1.13269265723/pytest_output_policy.br_ne1.13269265723.log',\n",
       " './artifacts/13269265723/output_artifact_locking.br_se1.13269265723/pytest_output_locking.br_se1.13269265723.log',\n",
       " './artifacts/13269265723/output_artifact_bucket_versioning.br_ne1.13269265723/pytest_output_bucket_versioning.br_ne1.13269265723.log']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifacts = ActionsArtifacts(repository=repo_path)\n",
    "#a = artifacts.download_artifact(13269014124)\n",
    "a = artifacts.retrieve_downloaded_artifacts()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'pytest.log.parquet' does not exist.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m artifact \u001b[38;5;241m=\u001b[39m PytestArtifactLogExtractor(path \u001b[38;5;241m=\u001b[39m a[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m pytest_tests_status\t, pytest_run_times, pytest_failures_errors \u001b[38;5;241m=\u001b[39m \u001b[43martifact\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_to_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Trocar databaseId por jobId\u001b[39;00m\n\u001b[1;32m      5\u001b[0m display(pytest_tests_status)\n",
      "Cell \u001b[0;32mIn[6], line 41\u001b[0m, in \u001b[0;36mPytestArtifactLogExtractor.log_to_df\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df_parquet\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;129;01mand\u001b[39;00m (databaseId \u001b[38;5;129;01min\u001b[39;00m df_parquet[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatabaseId\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_parquet\n\u001b[0;32m---> 41\u001b[0m tests, categories, failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__extract_all_categories__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Creating dataframes test status and categories\u001b[39;00m\n\u001b[1;32m     44\u001b[0m status_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(tests, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 93\u001b[0m, in \u001b[0;36mPytestArtifactLogExtractor.__extract_all_categories__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m     headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__extract_test_status_names__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_list_by_name__(header, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     92\u001b[0m categories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_list_by_name__(header, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration top\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__extract_failures_errors__(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_list_by_name__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msummary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m headers, categories, failures\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "artifact = PytestArtifactLogExtractor(path = a[0])\n",
    "pytest_tests_status\t, pytest_run_times, pytest_failures_errors = artifact.log_to_df()\n",
    "\n",
    "# Trocar databaseId por jobId\n",
    "display(pytest_tests_status)\n",
    "display(pytest_run_times)\n",
    "display(pytest_failures_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_passed = pytest_tests_status[pytest_tests_status.index.values != 'PASSED'].set_index('category')\n",
    "total_passed.index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_times = pd.Series(dict(map(lambda t: (t, sum(pytest_run_times[pytest_run_times.index == t].get('total'))), pytest_tests_status.category.unique())))\n",
    "avg_time_test  = pd.Series(dict(map(lambda t: (t, sum(pytest_run_times[pytest_run_times.index == t].get('avg'))), pytest_tests_status.category.unique())))\n",
    "min_test_time  = pd.Series(dict(map(lambda t: (t, sum(pytest_run_times[pytest_run_times.index == t].get('min'))), pytest_tests_status.category.unique())))\n",
    "total_nums = pytest_tests_status['category'].value_counts()\n",
    "total_passed = pytest_tests_status[pytest_tests_status.index.values != 'PASSED'].set_index('category').index.value_counts()\n",
    "time_count_df = pd.concat([total_passed, total_nums - total_passed, total_nums, min_test_time, avg_time_test, total_times], axis=1)\n",
    "time_count_df.columns = ['num_passed', 'num_failed', 'total_runs', 'min_test_time', 'avg_test_time', 'total_duration']\n",
    "\n",
    "report_df = pd.DataFrame()\n",
    "report_df['name'] = pytest_tests_status['category'].unique()\n",
    "report_df = report_df.set_index('name')\n",
    "\n",
    "report_df = pd.concat([report_df, time_count_df], axis=1)\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_details_df = pytest_failures_errors.set_index('category').drop(columns=['arguments', 'databaseId'])\n",
    "df = failed_details_df.reset_index()\n",
    "df = report_df.reset_index().round(3)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blocos que vão existir\n",
    "\n",
    "Topo: Contendo Informações básicas do relatório e se possível alguns campos em branco e também a data de quando o código foi executado\n",
    "\n",
    "Texto: Informações gerais do número de acertos e erros\n",
    "\n",
    "Tabela: Contem o dataframe report_df, mas estilizado\n",
    "\n",
    "Gráficos: fica pra dps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Table, TableStyle, Spacer, ListFlowable, ListItem\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to create PDF\n",
    "def create_pdf(df):\n",
    "    # A4 size dimensions\n",
    "    width, height = A4\n",
    "\n",
    "    # Set 10% margin\n",
    "    margin = 0.1 * width\n",
    "\n",
    "    # Create PDF with margins\n",
    "    doc = SimpleDocTemplate(\"report_v0.pdf\", pagesize=A4,\n",
    "                            leftMargin=margin, rightMargin=margin, topMargin=0.1*height, bottomMargin=0.1*height)\n",
    "\n",
    "    # Styles\n",
    "    styles = getSampleStyleSheet()\n",
    "    heading_style = styles['Heading1']\n",
    "    normal_style = styles['Normal']\n",
    "    normal_style.alignment = 0  # 0 for left alignment\n",
    "\n",
    "    bold_style = ParagraphStyle(\n",
    "        name=\"Bold\",\n",
    "        parent=normal_style,\n",
    "        fontName=\"Helvetica-Bold\",\n",
    "        fontSize=12\n",
    "    )\n",
    "\n",
    "    # Create the story (content) for the PDF\n",
    "    story = []\n",
    "\n",
    "    # Add title with fields\n",
    "    story.extend(create_title(heading_style,normal_style))\n",
    "\n",
    "    # Add each section to the story\n",
    "    story.extend(create_execution_summary(df, normal_style, bold_style))\n",
    "    story.extend(create_detailed_results(df, normal_style, bold_style, width, margin))\n",
    "    story.extend(create_errors_summary(normal_style, bold_style, width, margin))\n",
    "\n",
    "    # Build PDF\n",
    "    doc.build(story)\n",
    "\n",
    "# \n",
    "def create_title(heading_style, normal_style):\n",
    "    # Initialize the story list\n",
    "    story = []\n",
    "\n",
    "    # Get current date and time\n",
    "    agora = datetime.now()\n",
    "    horario_dia = agora.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "    # Create the title\n",
    "    title_text = \"Sumário de Resultados dos Testes\"\n",
    "    title_paragraph = Paragraph(f\"<b>{title_text}</b>\", heading_style)\n",
    "\n",
    "    # Create the formatted text for the execution date on the right side\n",
    "    right_date_style = ParagraphStyle(\n",
    "        \"RightDateStyle\", parent=normal_style, alignment=2, fontSize=10\n",
    "    )\n",
    "    date_paragraph = Paragraph(horario_dia, right_date_style)\n",
    "\n",
    "    # Add title and date to the story as separate elements\n",
    "    story.append(title_paragraph)\n",
    "    story.append(date_paragraph)\n",
    "\n",
    "    # Create the formatted text for the execution date, system version, and environment\n",
    "    execution_paragraph = Paragraph(f\"Data da Execução: \", normal_style)\n",
    "    version_paragraph = Paragraph(\"Versão do Sistema: \", normal_style)\n",
    "    environment_paragraph = Paragraph(\"Ambiente: \", normal_style)\n",
    "\n",
    "    # Add other paragraphs to the story\n",
    "    story.append(execution_paragraph)\n",
    "    story.append(Spacer(1, 12))  # Spacer between execution and version\n",
    "    story.append(version_paragraph)\n",
    "    story.append(Spacer(1, 12))  # Spacer between version and environment\n",
    "    story.append(environment_paragraph)\n",
    "\n",
    "    story.append(Spacer(1, 24))  # Add space at the end\n",
    "\n",
    "    # Return the complete story\n",
    "    return story\n",
    "\n",
    "\n",
    "\n",
    "# Function to create execution summary table with bullet points\n",
    "def create_execution_summary(df, normal_style, bold_style):\n",
    "    story = []\n",
    "    story.append(Paragraph(\"Resumo Geral\", bold_style))\n",
    "    story.append(Spacer(1, 6))\n",
    "\n",
    "    # Criando a lista de resumo corretamente\n",
    "    summary_data = {\n",
    "        'Total de Testes:': df['total_runs'].sum(),\n",
    "        'Testes Bem-Sucedidos:': df['num_passed'].sum(),\n",
    "        'Testes com Falha:': df['num_failed'].sum(),\n",
    "        'Tempo Mínimo de Execução:': f\"{df['min_test_time'].min():.2f} s\",\n",
    "        'Tempo Médio de Execução:': f\"{df['avg_test_time'].mean():.2f} s\",\n",
    "        'Duração Total dos Testes:': f\"{df['total_duration'].sum():.2f} s\"\n",
    "    }\n",
    "\n",
    "    # Criando a lista com bullet points\n",
    "    bullet_points = [\n",
    "        ListItem(Paragraph(f\"<b>{key}</b> {value}\", normal_style), leftIndent=20, spaceAfter=6)\n",
    "        for key, value in summary_data.items()\n",
    "    ]\n",
    "\n",
    "    # Criando o ListFlowable\n",
    "    list_flowable = ListFlowable(bullet_points, bulletType='bullet', leftIndent=20)\n",
    "\n",
    "    # Adicionando ao relatório\n",
    "    story.append(list_flowable)\n",
    "    story.append(Spacer(1, 24))\n",
    "\n",
    "    return story\n",
    "\n",
    "# Function to create detailed results table\n",
    "def create_detailed_results(df, normal_style, bold_style, width, margin):\n",
    "    story = []\n",
    "    story.append(Paragraph(\"Detalhamento dos Testes\", bold_style))\n",
    "    story.append(Spacer(1, 12))\n",
    "    df_renamed = df.copy()  # Create a copy of the DataFrame\n",
    "    df_renamed.columns = [\n",
    "        'Nome do Teste', \n",
    "        'Testes Bem-Sucedidos', \n",
    "        'Falhas', \n",
    "        'Execuções', \n",
    "        'Tempo Mínimo de Execução', \n",
    "        'Tempo Médio', \n",
    "        'Duração Total'\n",
    "    ]\n",
    "\n",
    "    # Dropping the specified columns\n",
    "    df_renamed = df_renamed.drop(columns=['Testes Bem-Sucedidos', 'Tempo Mínimo de Execução'])\n",
    "\n",
    "    df_renamed['Tempo Médio'] = df_renamed['Tempo Médio'].astype(str) + ' sec'\n",
    "    df_renamed['Duração Total'] = df_renamed['Duração Total'].astype(str) + ' sec'\n",
    "\n",
    "    # Prepare the detailed data for the table\n",
    "    detailed_tests_data = [df_renamed.columns.tolist()]  # Add header\n",
    "    detailed_tests_data.extend(\n",
    "        [[Paragraph(str(value), normal_style) for value in row] for row in df_renamed.values.tolist()]\n",
    "    )\n",
    "\n",
    "    # Calculate available width after applying margins\n",
    "    available_width = width - 2 * margin  # Subtracting left and right margins\n",
    "\n",
    "    # Define column proportions\n",
    "    proportions = [0.3, 0.15, 0.15, 0.15, 0.2]  # Example proportions\n",
    "\n",
    "    total_proportion = sum(proportions)\n",
    "    if total_proportion > 1:\n",
    "        proportions = [p / total_proportion for p in proportions]  # Scale proportions to fit within 1\n",
    "\n",
    "    # Calculate column widths based on the available width\n",
    "    col_widths = [available_width * p for p in proportions]\n",
    "\n",
    "    # Create the table\n",
    "    detailed_table = Table(detailed_tests_data, colWidths=col_widths)\n",
    "    detailed_table.setStyle(TableStyle([('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "                                        ('GRID', (0, 0), (-1, -1), 0.5, colors.black)]))\n",
    "    story.append(detailed_table)\n",
    "    story.append(Spacer(1, 24))\n",
    "\n",
    "    return story\n",
    "\n",
    "# Function to create errors summary as a numbered list\n",
    "def create_errors_summary(normal_style, bold_style, width, margin):\n",
    "    story = []\n",
    "    story.append(Paragraph(\"Resumo dos Erros\", bold_style))\n",
    "    story.append(Spacer(1, 12))\n",
    "\n",
    "    # Define um estilo menor para os números da lista\n",
    "    small_number_style = ParagraphStyle(\n",
    "        \"small_number_style\",\n",
    "        parent=normal_style,\n",
    "        fontSize=10  # Tamanho menor para os números\n",
    "    )\n",
    "\n",
    "    # Lista de erros\n",
    "    errors_list = [\n",
    "        \"Timeout na comunicação com a API (Testes: TC_002)\",\n",
    "        \"Falha de autenticação com banco de dados (Testes: TC_007)\",\n",
    "        \"Erro de processamento de dados em alta carga (Testes: TC_015, TC_016)\"\n",
    "    ]\n",
    "\n",
    "    # Criando itens da lista com mais espaço entre eles\n",
    "    numbered_items = [\n",
    "        ListItem(Paragraph(error, normal_style), leftIndent=margin, spaceAfter=10)\n",
    "        for error in errors_list\n",
    "    ]\n",
    "\n",
    "    # Criando a lista numerada\n",
    "    numbered_list = ListFlowable(\n",
    "        numbered_items,\n",
    "        bulletType='1',  # Define como lista numerada (1., 2., 3.)\n",
    "        bulletFontSize=10,  # Define tamanho menor para os números\n",
    "        leftIndent=margin*0.5  # Ajustando a indentação para alinhar com as margens\n",
    "    )\n",
    "\n",
    "    story.append(numbered_list)\n",
    "    story.append(Spacer(1, 24))\n",
    "\n",
    "    return story\n",
    "\n",
    "# Gerar o PDF\n",
    "create_pdf(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.units import cm  # Import cm from reportlab\n",
    "from reportlab.platypus import SimpleDocTemplate, Spacer, Table, TableStyle, Paragraph\n",
    "\n",
    "\n",
    "# Convert DataFrame to list of lists (including header), but wrap text in Paragraph\n",
    "styles = getSampleStyleSheet()\n",
    "normal_style = styles['Normal']\n",
    "\n",
    "table_data = []\n",
    "# Add the header (which is a list of strings, converted to Paragraphs)\n",
    "header = [Paragraph(col, normal_style) for col in df.columns]\n",
    "table_data.append(header)\n",
    "\n",
    "# Add rows, converting each entry to a Paragraph\n",
    "for _, row in df.iterrows():\n",
    "    row_data = [Paragraph(str(value), normal_style) for value in row]\n",
    "    table_data.append(row_data)\n",
    "\n",
    "# Function to calculate column widths based on page size\n",
    "def calculate_column_widths(page_width, num_columns, margin=1*cm):\n",
    "    \"\"\"\n",
    "    Calculate column widths based on the page width and number of columns.\n",
    "    Optionally, adjust for a margin between columns.\n",
    "    \"\"\"\n",
    "    available_width = page_width - 4 * margin \n",
    "    column_width = available_width / num_columns  \n",
    "    return column_width  \n",
    "\n",
    "def get_table_style():\n",
    "    return TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), (0.8, 0.8, 0.8)),  # Light grey background for header\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, (0.5, 0.5, 0.5)),  # Grey grid lines\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Center align both horizontally and vertically for all cells\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),  # Bold font for headers\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 10),  # Font size for all cells\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, -1), 5),  # Padding at the bottom of each cell\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 5),  # Padding at the top of each cell\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 10),  # Padding at the left side of each cell\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 10),  # Padding at the right side of each cell\n",
    "        ('ALIGN', (0, 0), (-1, 0), 'CENTER'),  # Center-align header\n",
    "    ])\n",
    "\n",
    "\n",
    "# Function for the first page\n",
    "def myFirstPage(canvas, doc):\n",
    "    page_width = A4[0] \n",
    "\n",
    "    # Calculate column widths based on the page width (in cm)\n",
    "    num_columns = len(df.columns)\n",
    "    colWidths = calculate_column_widths(page_width, num_columns)\n",
    "\n",
    "\n",
    "    canvas.saveState()\n",
    "    canvas.setFont(\"Helvetica\", 12)\n",
    "    canvas.drawString(100, 750, f\"sizePage{page_width}, num={num_columns} column={colWidths}\")\n",
    "    canvas.restoreState()\n",
    "\n",
    "# Function for subsequent pages\n",
    "def myLaterPages(canvas, doc):\n",
    "    canvas.saveState()\n",
    "    canvas.setFont(\"Helvetica\", 12)\n",
    "    canvas.drawString(100, 750, \"This is a later page\")\n",
    "    canvas.restoreState()\n",
    "\n",
    "# Function to create the document\n",
    "def go():\n",
    "    doc = SimpleDocTemplate(\"hello_with_dataframe_as_table_dynamic_widths_cm.pdf\", pagesize=A4)\n",
    "    \n",
    "    num_columns = len(df.columns)\n",
    "    colWidths = calculate_column_widths(A4[0], num_columns)\n",
    "\n",
    "    Story = [Spacer(1, 2 * cm)]  # Use cm for Spacer as well\n",
    "\n",
    "    # Create the Table object with the data and dynamically calculated column widths\n",
    "    table = Table(table_data, colWidths)\n",
    "    table.setStyle(get_table_style())\n",
    "\n",
    "    # Add the table to the story\n",
    "    Story.append(table)\n",
    "    Story.append(Spacer(1, 0.2 * cm))  # Use cm for spacing\n",
    "\n",
    "    # Generate the PDF\n",
    "    doc.build(Story, onFirstPage=myFirstPage, onLaterPages=myLaterPages)\n",
    "\n",
    "# Call the function to generate the PDF\n",
    "go()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pedir o id do workflow que se quer um relatorio ou varios ids\n",
    "# 2. Colocar todos os jobs do workflow dentro de um dataframe\n",
    "# 3. Para cada job gerar os 3 dataframes necessarios\n",
    "\n",
    "\n",
    "# Data de criação do workflow e seu Id\n",
    "# JobId | Nome | Tempo | Falhas/Acertos | Erros (sem detalhes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Faz o teste -> gera graficos com tempo e taxa de falhas por tipo de teste\n",
    "\n",
    "Workflow -> Job -> Passos -> Resultados pytest \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define color mapping\n",
    "colors = {\n",
    "    'failure': 'firebrick',\n",
    "    'cancelled': 'darkgray',\n",
    "    'startup_failure': 'darkorange',\n",
    "    'success':  'darkgreen'\n",
    "}\n",
    "\n",
    "# Filter the DataFrame\n",
    "a = workflow.df[workflow.df['status'] == 'completed']\n",
    "\n",
    "# Get value counts of the 'conclusion' columnimport matplotlib.pyplot as plt\n",
    "\n",
    "# Define color mapping\n",
    "colors = {\n",
    "    'failure': 'firebrick',\n",
    "    'cancelled': 'darkgray',\n",
    "    'startup_failure':'darkorange',\n",
    "    'success':  'darkgreen'\n",
    "\n",
    "}\n",
    "\n",
    "# Filter the DataFrame\n",
    "a = workflow.df[workflow.df['status'] == 'completed']\n",
    "\n",
    "# Get value counts of the 'conclusion' column\n",
    "value_counts = a['conclusion'].value_counts()\n",
    "\n",
    "# Map colors to the categories in value_counts\n",
    "bar_colors = [colors[cat] for cat in value_counts.index]\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))  # 1 row, 2 columns\n",
    "\n",
    "# Plot the bar chart on the first subplot\n",
    "value_counts.plot.bar(color=bar_colors, ax=ax1)\n",
    "ax1.set_xlabel('Conclusion')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Bar Chart: Conclusion Counts')\n",
    "\n",
    "# Plot the pie chart on the second subplot\n",
    "value_counts.plot.pie(colors=bar_colors, autopct='%1.1f%%', ax=ax2)\n",
    "ax2.set_ylabel('')  # Remove the y-label for the pie chart\n",
    "ax2.set_title('Pie Chart: Conclusion Distribution')\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n",
    "value_counts = a['conclusion'].value_counts()\n",
    "\n",
    "# Map colors to the categories in value_counts\n",
    "bar_colors = [colors[cat] for cat in value_counts.index]\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))  # 1 row, 2 columns\n",
    "\n",
    "# Plot the bar chart on the first subplot\n",
    "value_counts.plot.bar(color=bar_colors, ax=ax1)\n",
    "ax1.set_xlabel('Conclusion')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Bar Chart: Conclusion Counts')\n",
    "\n",
    "# Plot the pie chart on the second subplot\n",
    "value_counts.plot.pie(colors=bar_colors, autopct='%1.1f%%', ax=ax2)\n",
    "ax2.set_ylabel('')  # Remove the y-label for the pie chart\n",
    "ax2.set_title('Pie Chart: Conclusion Distribution')\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jobs Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = ActionsJobs(repository=repo_path, workflow=workflow)\n",
    "ids = workflow.df['databaseId'].unique()\n",
    "all_job_dfs = [jobs.get_jobs(id)for id in ids]\n",
    "jobs_df = pd.concat(all_job_dfs)\n",
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_failed_passed_jobs_bars(df):\n",
    "    unique_names = df.groupby(['Test', 'Conclusion']).size().unstack(fill_value=0)\n",
    "    test_to_number = {test: i + 1 for i, test in enumerate(df['Test'].unique())}\n",
    "\n",
    "    # Define colors for 'FAILED' and 'PASSED'\n",
    "    colors = {\n",
    "        'FAILED': 'firebrick',\n",
    "        'PASSED': 'darkgreen'\n",
    "    }\n",
    "\n",
    "    ax = unique_names.plot.bar(color=[colors['FAILED'], colors['PASSED']], figsize=(8, 4))\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('Test')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('FAILED vs PASSED by Test')\n",
    "\n",
    "    # Change the x-tick labels to their respective numbers\n",
    "    ax.set_xticklabels([test_to_number[test] for test in unique_names.index], rotation=0)\n",
    "\n",
    "    # Create a legend for the test numbers and names\n",
    "    test_legend = [f\"{num}. {test}\" for test, num in test_to_number.items()]\n",
    "    plt.figtext(1.05, 0.5, \"\\n\".join(test_legend), va='center', fontsize=10, wrap=True)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "#plot_failed_passed_jobs_bars(jobs_df[jobs_df['Conclusion'] == 'FAILED'])\n",
    "plot_failed_passed_jobs_bars(jobs_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
