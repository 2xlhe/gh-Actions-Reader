{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArqManipulation:\n",
    "    \"\"\"\n",
    "    A utility class for file operations and data manipulation.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod \n",
    "    def read_parquet_file(parquet_file_name: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Reads a Parquet file and returns a DataFrame.\n",
    "\n",
    "        :param parquet_file_name: Path to the Parquet file.\n",
    "        :return: DataFrame with file contents.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(parquet_file_name):\n",
    "                print(f\"File '{parquet_file_name}' does not exist.\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            return pd.read_parquet(parquet_file_name)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error reading Parquet file '{parquet_file_name}': {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def save_df_to_parquet(df: pd.DataFrame, parquet_file_name: str):\n",
    "        \"\"\"\n",
    "        Saves a DataFrame to a Parquet file.\n",
    "\n",
    "        :param df: Dataframe to save.\n",
    "        :param parquet_file_name: Parqueet saving path.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(parquet_file_name), exist_ok=True)\n",
    "            df.to_parquet(parquet_file_name)\n",
    "            print(f\"DataFrame successfully saved to {parquet_file_name}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error saving DataFrame to Parquet file '{parquet_file_name}': {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_ansi_escape(base_str: str) -> str:\n",
    "        \"\"\"\n",
    "        Removes ANSI escape values from a string.\n",
    "\n",
    "        :param base_str: Unformmated string.\n",
    "        :return: Cleaned string.\n",
    "        \"\"\"\n",
    "        return re.sub(r'\\x1B\\[[0-9;]*[A-Za-z]', '', base_str)\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_stdout_json(base_str: str) -> dict:\n",
    "        \"\"\"\n",
    "        Parses JSON output from GitHub CLI after cleaning ANSI escape sequences.\n",
    "\n",
    "        :param base_str: The raw output string from the GitHub CLI.\n",
    "        :return: Parsed JSON dictionary.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            cleaned = ArqManipulation.clean_ansi_escape(base_str)\n",
    "            str_output = ''.join(cleaned.splitlines())\n",
    "            return json.loads(str_output)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise e\n",
    "\n",
    "    @staticmethod\n",
    "    def json_to_df(parsed_json: dict) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Converts a JSON dictionary to a sorted DataFrame with specific columns.\n",
    "\n",
    "        :param parsed_json: Parsed JSON data.\n",
    "        :return: Pandas DataFrame sorted by the 'createdAt' column.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df_json = pd.DataFrame(parsed_json)\n",
    "            required_columns = ['name', 'createdAt', 'conclusion', 'status', 'databaseId', 'workflowDatabaseId']\n",
    "            \n",
    "            if not all(col in df_json.columns for col in required_columns):\n",
    "                raise KeyError(f\"Missing required columns in JSON data: {set(required_columns) - set(df_json.columns)}\")\n",
    "\n",
    "            df_json['createdAt'] = pd.to_datetime(df_json['createdAt'])\n",
    "            return df_json[required_columns].sort_values(by=\"createdAt\")\n",
    "        except KeyError as e:\n",
    "            raise ValueError(f\"Error processing JSON to DataFrame: {e}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Unexpected error in json_to_df: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionsWorkflow:\n",
    "    \"\"\"\n",
    "    A class to extract GitHub Actions workflows using the GitHub CLI, generating a dataframe with returned data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, repository, query_size):\n",
    "        \"\"\"\n",
    "        Initializes the ActionsWorkflow class.\n",
    "\n",
    "        :param repository: GitHub repository in the format \"owner/repo\".\n",
    "        :param query_size: Number of workflows to retrieve.\n",
    "        \"\"\"\n",
    "        self.repository = repository\n",
    "        self.json_attributes = '--json name,status,conclusion,createdAt,databaseId,workflowDatabaseId'\n",
    "        self.query_size = query_size\n",
    "        self.df = self.__gh_list_query__()\n",
    "\n",
    "    def __gh_list_query__(self):\n",
    "        \"\"\"\n",
    "        Calls the GitHub API via the GitHub CLI (`gh run list`) and retrieves\n",
    "        a specified number of workflows.\n",
    "\n",
    "        :return: A DataFrame containing the parsed workflow data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            list_command = f'gh run --repo {self.repository} list {self.json_attributes} -L {self.query_size}'\n",
    "            \n",
    "            output_json = subprocess.run(\n",
    "                list_command, shell=True, text=True, check=True, capture_output=True\n",
    "            ).stdout\n",
    "\n",
    "            parsed_json = ArqManipulation.parse_stdout_json(output_json)\n",
    "            df = ArqManipulation.json_to_df(parsed_json)\n",
    "\n",
    "            ArqManipulation.save_df_to_parquet(df = df, parquet_file_name=\"./bin/actionsWorflow.parquet\")\n",
    "\n",
    "            return df.set_index('name')\n",
    "\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error executing GitHub CLI command: {e}\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame on error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionsJobs:\n",
    "    \"\"\"\n",
    "    A class to interact with GitHub Actions jobs using the GitHub CLI.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, repository, workflow):\n",
    "        \"\"\"\n",
    "        Initializes the ActionsJobs class.\n",
    "\n",
    "        :param repository: GitHub repository in the format \"owner/repo\".\n",
    "        :param workflow: Workflow associated with the jobs.\n",
    "        \"\"\"\n",
    "        self.repository = repository\n",
    "        self.workflow = workflow  \n",
    "\n",
    "    def __retrieve_jobs__(self, database_id: int):\n",
    "        command = f'gh run --repo {self.repository} view {database_id}'\n",
    "        jobs_data = subprocess.run(command, shell=True, text=True, check=True, capture_output=True).stdout\n",
    "\n",
    "        return jobs_data\n",
    "\n",
    "    def get_jobs(self, database_id: int) -> pd.DataFrame:\n",
    "            \"\"\"\n",
    "            Retrieves job data from the GitHub CLI and processes it.\n",
    "\n",
    "            :param database_id: The ID of the workflow run.\n",
    "            :return: A Pandas DataFrame containing job details.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                jobs_df = ArqManipulation.read_parquet_file(parquet_file_name=\"./bin/actionsJobs.parquet\")\n",
    "\n",
    "                if jobs_df.empty:\n",
    "                    data = self.__retrieve_jobs__(database_id=database_id)\n",
    "                    jobs_df = self.__clean_job_text__(data)\n",
    "\n",
    "                    jobs_df[\"databaseId\"] = int(database_id)\n",
    "\n",
    "                    ArqManipulation.save_df_to_parquet(jobs_df, parquet_file_name=\"./bin/actionsJobs.parquet\")\n",
    "\n",
    "                elif not database_id in jobs_df['databaseId'].values:\n",
    "                    data = self.__retrieve_jobs__(database_id=database_id)\n",
    "                    data_df = self.__clean_job_text__(data)\n",
    "                    data_df[\"databaseId\"] = int(database_id)\n",
    "\n",
    "                    jobs_df = pd.concat([jobs_df, data_df], ignore_index=True)\n",
    "\n",
    "                    ArqManipulation.save_df_to_parquet(jobs_df, parquet_file_name=\"./bin/actionsJobs.parquet\")\n",
    "\n",
    "                return jobs_df\n",
    "\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"Error executing GitHub CLI command: {e}\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "                return pd.DataFrame()\n",
    "        \n",
    "    def __split_string__(self, job_list):\n",
    "        \"\"\"\n",
    "        Splits a job string into structured components.\n",
    "\n",
    "        :param job: The job string to split.\n",
    "        :return: A list of cleaned job attributes.\n",
    "        \"\"\"\n",
    "        jobs = []\n",
    "\n",
    "        for job in job_list:\n",
    "            delimiters = r\" \\| | / build in | \\(ID |\\| in| / cleanup in | /| in \" \n",
    "            splitted_job = re.split(delimiters, job)\n",
    "            splitted_job = [s.strip() for s in splitted_job if s.strip()]\n",
    "            jobs.append(splitted_job)\n",
    "        \n",
    "        jobs.pop(0)\n",
    "\n",
    "        return jobs\n",
    "\n",
    "    def __build_cleaned_df__(self, data):\n",
    "        # Define columns\n",
    "        columns = [\"conclusion\", \"test\", \"buildTime (sec)\", \"jobId\"]\n",
    "        jobs_df = pd.DataFrame(columns=columns)\n",
    "        jobs_df[\"failedAt\"] = None\n",
    "\n",
    "        for job in data:\n",
    "            if any(\"ID\" in item and (\"PASSED\" in item or \"FAILED\" in item) for item in job):\n",
    "                temp_df = pd.DataFrame(self.__split_string__(job), columns=columns)\n",
    "\n",
    "                temp_df['buildTime (sec)'] = temp_df['buildTime (sec)'].apply(str_time_to_int)\n",
    "                jobs_df = pd.concat([jobs_df, temp_df], ignore_index=True)\n",
    "            \n",
    "            elif any(\"FAILED\" in item for item in job):\n",
    "                failed = next(item for item in job if \"FAILED\" in item).split(\"FAILED | \")\n",
    "                if not jobs_df.empty:\n",
    "                    jobs_df.at[jobs_df.index[-1], \"failedAt\"] = failed[1]  \n",
    "\n",
    "        jobs_df[\"jobId\"] = jobs_df[\"jobId\"].str.rstrip(\")\").astype('int')\n",
    "        return jobs_df\n",
    "\n",
    "\n",
    "    def __find_jobs__(self, base_str: str) -> list[str]:\n",
    "        lines = base_str.splitlines()\n",
    "        arr = []  # Stores grouped sections\n",
    "        current_group = []  # Temporary storage for the current section\n",
    "\n",
    "        for line in lines:\n",
    "            if line.isupper() or not line.strip():  # New section (uppercase or empty line)\n",
    "                if current_group:  # Avoid adding empty groups\n",
    "                    arr.append(current_group)\n",
    "                current_group = [line]  # Start a new group\n",
    "            else:\n",
    "                current_group.append(line)\n",
    "\n",
    "        if current_group:  # Append the last group\n",
    "            arr.append(current_group)\n",
    "\n",
    "        # Filter out groups that do not start with an uppercase title\n",
    "        filtered_arr = [group for group in arr if group and group[0].isupper()]\n",
    "        return filtered_arr\n",
    "\n",
    "    def __clean_job_text__(self, base_str: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Cleans and structures GitHub job data from CLI output.\n",
    "\n",
    "        :param base_str: Raw job text output from the GitHub CLI.\n",
    "        :return: A Pandas DataFrame with structured job data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Remove ANSI escape sequences and unwanted characters\n",
    "            ansi_cleaned = ArqManipulation.clean_ansi_escape(base_str)\n",
    "            cleaned = ansi_cleaned.replace(\"✓\", \"PASSED |\").replace(\"X\", \"FAILED |\")\n",
    "\n",
    "            stripped_list = self.__find_jobs__(cleaned)\n",
    "\n",
    "            if not (x.find('JOBS') or x.find(\"ANNOTATIONS\") for x in stripped_list):\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            jobs_df = self.__build_cleaned_df__(stripped_list)\n",
    "\n",
    "            return jobs_df\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing job text: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    \n",
    "\n",
    "def str_time_to_int(time_str):\n",
    "    names = ['d', 'h', 'm', 's']\n",
    "    seconds = [86400, 3600, 60, 1]\n",
    "\n",
    "    total_time = 0\n",
    "\n",
    "    for m, t in zip(names,seconds):\n",
    "        if m in time_str:\n",
    "            time_list = time_str.split(m)\n",
    "            total_time +=  int(time_list[0]) * t\n",
    "            time_str = time_list[1]\n",
    "\n",
    "    return total_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionsArtifacts:\n",
    "    \"\"\"\n",
    "    A class to handle downloading, retrieving, and deleting GitHub Actions artifacts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, repository: str):\n",
    "        \"\"\"\n",
    "        Initializes the ActionsArtifacts object.\n",
    "\n",
    "        :param repository: The GitHub repository in the format \"owner/repo\".\n",
    "        \"\"\"\n",
    "        self.repository = repository\n",
    "        self.folder = './artifacts/'  # Default storage dir\n",
    "        self.paths = self.retrieve_downloaded_artifacts() \n",
    "\n",
    "    def download_artifact(self, database_id: str):\n",
    "        \"\"\"\n",
    "        Downloads an artifact from GitHub Actions using the GitHub CLI.\n",
    "\n",
    "        :param database_id: The database ID of the artifact to download.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Ensure the folder exists before downloading\n",
    "            os.makedirs(self.folder, exist_ok=True)\n",
    "\n",
    "            # Construct the command to download the artifact\n",
    "            command = f'gh run --repo {self.repository} download {database_id} --dir {os.path.join(self.folder, str(database_id))}'\n",
    "\n",
    "            # Execute the command\n",
    "            subprocess.run(command, shell=True, text=True, check=True)\n",
    "            print(\"Download Successful\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error during artifact download: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "\n",
    "    def retrieve_downloaded_artifacts(self) -> list[str]:\n",
    "        \"\"\"\n",
    "        Retrieves all downloaded artifacts file paths.\n",
    "\n",
    "        :return: returns Paths of the downloaded artifacts\n",
    "        \"\"\"\n",
    "        paths = []\n",
    "\n",
    "        # Walk through the artifacts folder and collect all file paths\n",
    "        for path, _, files in os.walk(self.folder):\n",
    "            for file in files:\n",
    "                paths.append(os.path.join(path, file))\n",
    "\n",
    "        return paths\n",
    "\n",
    "    def delete_downloaded_artifacts(self):\n",
    "        \"\"\"\n",
    "        Deletes all downloaded artifacts recursively\n",
    "        \"\"\"\n",
    "        try:\n",
    "            shutil.rmtree(self.folder)\n",
    "            if os.path.exists(self.folder):\n",
    "                print(\"Error: Failed to delete artifacts directory.\")\n",
    "            else:\n",
    "                print(\"Artifacts directory deleted successfully.\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"Artifacts directory not found, nothing to delete.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while deleting artifacts: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytestArtifactLogExtractor:\n",
    "    \"\"\"\n",
    "    A class to extract and process test status and timing information from a pytest artifact log.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str):\n",
    "        \"\"\"\n",
    "        Initializes the PytestArtifactLogExtractor object.\n",
    "\n",
    "        :param path: Path to the pytest artifact log file.\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.data = self.__read_file__()\n",
    "\n",
    "    def __read_file__(self):\n",
    "        \"\"\"\n",
    "        Reads the contents of the log file and returns it as a string.\n",
    "\n",
    "        :return: String containing the file content.\n",
    "        \"\"\"\n",
    "        with open(self.path, \"r\") as file: \n",
    "            data = file.read()\n",
    "\n",
    "        return ArqManipulation.clean_ansi_escape(data)\n",
    "\n",
    "    def __extract_test_status_names__(self, data):\n",
    "        tests = []\n",
    "        keywords = ('PASSED', 'FAILED', 'ERROR')\n",
    "\n",
    "        for line in data:\n",
    "            line = ''.join(line)\n",
    "\n",
    "            # Check if any keyword is present\n",
    "            if any(k in line for k in keywords):\n",
    "                \n",
    "                parts = re.sub(r'\\[.*?\\d%\\]', '', line).split('::')\n",
    "                tmp = list(filter(None,list(parts[0].partition('PASSED'))))\n",
    "                if '[' in parts[1]:\n",
    "                    tmp.append(re.findall(r'\\[(.*?)\\]',parts[1]))\n",
    "\n",
    "                while len(tmp) < 3:\n",
    "                    tmp.append(None)\n",
    "\n",
    "                tests.append(tmp)\n",
    "        \n",
    "        return tests\n",
    "\n",
    "    def log_to_df(self):\n",
    "        \"\"\"\n",
    "        Parses the log file to extract test results and performance metrics.\n",
    "\n",
    "        :return: A DataFrame combining test statuses with time metrics.\n",
    "        \"\"\"\n",
    "\n",
    "        df_parquet = ArqManipulation.read_parquet_file(parquet_file_name='pytest.log.parquet')   \n",
    "\n",
    "        databaseId = self.__extract_self_path_info__().get('databaseId').values\n",
    "        databaseId = int(databaseId) if databaseId else None \n",
    "    \n",
    "        if not df_parquet.empty and (databaseId in df_parquet['databaseId']):\n",
    "            return df_parquet\n",
    "\n",
    "        tests, categories = self.__extract_all_categories__()\n",
    "        \n",
    "        # Creating dataframes test status and categories\n",
    "        status_df = pd.DataFrame(tests, columns=[\"status\", \"name\", \"arguments\"]).set_index('name')\n",
    "        categories_df = self.__create_df__(categories)\n",
    "\n",
    "\n",
    "        # Applying individual id for each table\n",
    "        status_df['databaseId'] = databaseId\n",
    "        categories_df['databaseId'] = databaseId\n",
    "\n",
    "\n",
    "        return status_df, categories_df\n",
    "\n",
    "    def __extract_all_categories__(self):\n",
    "        header = []\n",
    "        # Filtering out irrelevant categories\n",
    "        keywords = ('deselected', 'passed in', 'grand total', 'live log')\n",
    "\n",
    "        values = self.data.splitlines()\n",
    "        for value in values:\n",
    "            if any(k in value for k in keywords):\n",
    "                continue   \n",
    "            elif re.match(r'=+|-+', value): # Divide by headers demarked by '=' or '-' (logging)\n",
    "                value = value.replace(\"=\", \"\")  \n",
    "                value = value.replace(\"-\", \"\")  \n",
    "                header.append([value]) \n",
    "            else:\n",
    "                # Populate each category and break in the case of the pytest-durations tables while ignoring empty values\n",
    "                value = re.split(r\"\\s+\", value) \n",
    "                if list(filter(None, value)):\n",
    "                    header[-1].append(list(filter(None, value)))\n",
    "\n",
    "        #TODO Bug no livelog, skipar quando aparecer, a estrutura é totalmente diferente    \n",
    "        headers = self.__extract_test_status_names__(header[0])\n",
    "\n",
    "        categories = header[1:]\n",
    "\n",
    "        return headers, categories\n",
    "\n",
    "    def __create_df__(self, values):\n",
    "        \"\"\"\n",
    "        Converts extracted timing information into DataFrames.\n",
    "\n",
    "        :param values: A list of lists containing extracted time metrics.\n",
    "        :return: A list of DataFrames with execution time statistics.\n",
    "        \"\"\"\n",
    "        dfs = pd.DataFrame()\n",
    "        \n",
    "        for h in values:\n",
    "            time_df = pd.DataFrame(h[2:], columns=h[1])\n",
    "    \n",
    "            #if 'name' in time_df.columns:\n",
    "            #    time_df = time_df.set_index('name') \n",
    "\n",
    "            # Converting time-related columns to datetime.time format\n",
    "            time_columns = ['avg', 'min', 'total']\n",
    "            for col in time_columns:\n",
    "                if col in time_df.columns:\n",
    "                    time_df[col] = pd.to_datetime(time_df[col], format=\"%H:%M:%S.%f\", errors='coerce').dt.time  \n",
    "\n",
    "            # Assigning a 'durationType' column for metric categorization\n",
    "            time_df['durationType'] = h[0].replace('top', '').replace('test', '')\n",
    "\n",
    "            dfs = pd.concat([time_df, dfs], ignore_index=True)\n",
    "\n",
    "        if 'name' in dfs.columns:\n",
    "            dfs = dfs.set_index('name') \n",
    "\n",
    "        return dfs\n",
    "\n",
    "    def __extract_self_path_info__(self):\n",
    "        \"\"\"\n",
    "        Extracts test and database ID information from the log file path.\n",
    "\n",
    "        :return: A DataFrame containing 'test' and 'databaseId' information.\n",
    "        \"\"\"\n",
    "        # Extract filename without extension\n",
    "        stripped = self.path.split('/')[-1].split('.')\n",
    "        stripped.pop()  # Remove the file extension\n",
    "\n",
    "        # Ensure there are exactly three elements (fill missing ones with None)\n",
    "        while len(stripped) < 3:\n",
    "            stripped.append(None)  # Fill missing values with NaN\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame([stripped], columns=['test', 'region', 'databaseId'])\n",
    "\n",
    "        return df\n",
    "\n",
    "    def __merge_artifact_dfs__(self, times_df, status_df):\n",
    "        \"\"\"\n",
    "        Merges test execution time data with test status information.\n",
    "\n",
    "        :param times_df: A list of DataFrames containing time-related data.\n",
    "        :param status_df: A DataFrame containing test statuses.\n",
    "        :return: A combined DataFrame containing execution metrics and test results.\n",
    "        \"\"\"\n",
    "        databaseId_df = self.__extract_self_path_info__()  \n",
    "        order = ['category', 'durationType', 'databaseId', 'status', 'num', 'avg', 'min', 'total']\n",
    "        dfs = []\n",
    "\n",
    "        for h in times_df:\n",
    "            joined_df = h.join(status_df)  # Merging time metrics with test statuses\n",
    "\n",
    "            # Adding database ID to each row\n",
    "            for col in databaseId_df.columns.values:\n",
    "                joined_df[col] = databaseId_df[col].values[0]  \n",
    "\n",
    "            # Reordering columns\n",
    "            joined_df = joined_df[order]  \n",
    "            dfs.append(joined_df)\n",
    "\n",
    "        return pd.concat(dfs)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conclusion</th>\n",
       "      <th>test</th>\n",
       "      <th>buildTime (sec)</th>\n",
       "      <th>jobId</th>\n",
       "      <th>failedAt</th>\n",
       "      <th>databaseId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (cold_storage, cold_storage, ../para...</td>\n",
       "      <td>85</td>\n",
       "      <td>37044161130</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (basic, basic, ../params.example.yam...</td>\n",
       "      <td>96</td>\n",
       "      <td>37044161606</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (presign, presign, ../params.example...</td>\n",
       "      <td>69</td>\n",
       "      <td>37044161918</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>tests-success</td>\n",
       "      <td>0</td>\n",
       "      <td>37044262983</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup-tests</td>\n",
       "      <td>102</td>\n",
       "      <td>37044273275</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-ne1.y...</td>\n",
       "      <td>222</td>\n",
       "      <td>37031740446</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-se1.y...</td>\n",
       "      <td>10945</td>\n",
       "      <td>37031741305</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (bucket_versioning, ../params...</td>\n",
       "      <td>101</td>\n",
       "      <td>37031741997</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (acl, ../params/br-ne1.yaml, ...</td>\n",
       "      <td>323</td>\n",
       "      <td>37031742597</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (policy, ../params/br-ne1.yam...</td>\n",
       "      <td>156</td>\n",
       "      <td>37031743174</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup_tests</td>\n",
       "      <td>105</td>\n",
       "      <td>37044113674</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-se1.y...</td>\n",
       "      <td>2168</td>\n",
       "      <td>37043704535</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-ne1.y...</td>\n",
       "      <td>246</td>\n",
       "      <td>37043705230</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (acl, ../params/br-ne1.yaml, ...</td>\n",
       "      <td>398</td>\n",
       "      <td>37043705967</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (bucket_versioning, ../params...</td>\n",
       "      <td>118</td>\n",
       "      <td>37043706472</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (policy, ../params/br-ne1.yam...</td>\n",
       "      <td>165</td>\n",
       "      <td>37043706867</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup_tests</td>\n",
       "      <td>113</td>\n",
       "      <td>37045803570</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conclusion                                               test  \\\n",
       "0      PASSED  run_tests (cold_storage, cold_storage, ../para...   \n",
       "1      PASSED  run_tests (basic, basic, ../params.example.yam...   \n",
       "2      PASSED  run_tests (presign, presign, ../params.example...   \n",
       "3      PASSED                                      tests-success   \n",
       "4      PASSED                                      cleanup-tests   \n",
       "5      PASSED  extra_tests_debug (locking, ../params/br-ne1.y...   \n",
       "6      PASSED  extra_tests_debug (locking, ../params/br-se1.y...   \n",
       "7      PASSED  extra_tests_dist (bucket_versioning, ../params...   \n",
       "8      PASSED  extra_tests_dist (acl, ../params/br-ne1.yaml, ...   \n",
       "9      PASSED  extra_tests_dist (policy, ../params/br-ne1.yam...   \n",
       "10     PASSED                                      cleanup_tests   \n",
       "11     PASSED  extra_tests_debug (locking, ../params/br-se1.y...   \n",
       "12     PASSED  extra_tests_debug (locking, ../params/br-ne1.y...   \n",
       "13     PASSED  extra_tests_dist (acl, ../params/br-ne1.yaml, ...   \n",
       "14     PASSED  extra_tests_dist (bucket_versioning, ../params...   \n",
       "15     PASSED  extra_tests_dist (policy, ../params/br-ne1.yam...   \n",
       "16     PASSED                                      cleanup_tests   \n",
       "\n",
       "    buildTime (sec)        jobId failedAt   databaseId  \n",
       "0                85  37044161130     None  13269149127  \n",
       "1                96  37044161606     None  13269149127  \n",
       "2                69  37044161918     None  13269149127  \n",
       "3                 0  37044262983     None  13269149127  \n",
       "4               102  37044273275     None  13269149127  \n",
       "5               222  37031740446     None  13265481700  \n",
       "6             10945  37031741305     None  13265481700  \n",
       "7               101  37031741997     None  13265481700  \n",
       "8               323  37031742597     None  13265481700  \n",
       "9               156  37031743174     None  13265481700  \n",
       "10              105  37044113674     None  13265481700  \n",
       "11             2168  37043704535     None  13269014124  \n",
       "12              246  37043705230     None  13269014124  \n",
       "13              398  37043705967     None  13269014124  \n",
       "14              118  37043706472     None  13269014124  \n",
       "15              165  37043706867     None  13269014124  \n",
       "16              113  37045803570     None  13269014124  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jobs = ActionsJobs(repo_path, workflow)\n",
    "jobs.get_jobs(13269014124)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Main\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully saved to ./bin/actionsWorflow.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>createdAt</th>\n",
       "      <th>conclusion</th>\n",
       "      <th>status</th>\n",
       "      <th>databaseId</th>\n",
       "      <th>workflowDatabaseId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pull Request Essential Tests</th>\n",
       "      <td>2025-02-11 14:42:01+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13265481705</td>\n",
       "      <td>132962917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Extra Tests</th>\n",
       "      <td>2025-02-11 14:42:01+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13265481700</td>\n",
       "      <td>142271933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Extra Tests</th>\n",
       "      <td>2025-02-11 17:37:25+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269014124</td>\n",
       "      <td>142271933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Essential Tests</th>\n",
       "      <td>2025-02-11 17:37:25+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269014120</td>\n",
       "      <td>132962917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Essential Tests</th>\n",
       "      <td>2025-02-11 17:39:58+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269057739</td>\n",
       "      <td>132962917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Extra Tests</th>\n",
       "      <td>2025-02-11 17:39:58+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269057738</td>\n",
       "      <td>142271933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Extra Tests</th>\n",
       "      <td>2025-02-11 17:45:26+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269149128</td>\n",
       "      <td>142271933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Essential Tests</th>\n",
       "      <td>2025-02-11 17:45:26+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269149127</td>\n",
       "      <td>132962917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Essential Tests</th>\n",
       "      <td>2025-02-11 17:52:13+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269265728</td>\n",
       "      <td>132962917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Extra Tests</th>\n",
       "      <td>2025-02-11 17:52:13+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269265723</td>\n",
       "      <td>142271933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             createdAt conclusion     status  \\\n",
       "name                                                                           \n",
       "Pull Request Essential Tests 2025-02-11 14:42:01+00:00    success  completed   \n",
       "Pull Request Extra Tests     2025-02-11 14:42:01+00:00    success  completed   \n",
       "Pull Request Extra Tests     2025-02-11 17:37:25+00:00    success  completed   \n",
       "Pull Request Essential Tests 2025-02-11 17:37:25+00:00    success  completed   \n",
       "Pull Request Essential Tests 2025-02-11 17:39:58+00:00    success  completed   \n",
       "Pull Request Extra Tests     2025-02-11 17:39:58+00:00    success  completed   \n",
       "Pull Request Extra Tests     2025-02-11 17:45:26+00:00    success  completed   \n",
       "Pull Request Essential Tests 2025-02-11 17:45:26+00:00    success  completed   \n",
       "Pull Request Essential Tests 2025-02-11 17:52:13+00:00    success  completed   \n",
       "Pull Request Extra Tests     2025-02-11 17:52:13+00:00    success  completed   \n",
       "\n",
       "                               databaseId  workflowDatabaseId  \n",
       "name                                                           \n",
       "Pull Request Essential Tests  13265481705           132962917  \n",
       "Pull Request Extra Tests      13265481700           142271933  \n",
       "Pull Request Extra Tests      13269014124           142271933  \n",
       "Pull Request Essential Tests  13269014120           132962917  \n",
       "Pull Request Essential Tests  13269057739           132962917  \n",
       "Pull Request Extra Tests      13269057738           142271933  \n",
       "Pull Request Extra Tests      13269149128           142271933  \n",
       "Pull Request Essential Tests  13269149127           132962917  \n",
       "Pull Request Essential Tests  13269265728           132962917  \n",
       "Pull Request Extra Tests      13269265723           142271933  "
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_path = 'MagaluCloud/s3-specs'\n",
    "query_size = 10\n",
    "\n",
    "workflow = ActionsWorkflow(repository=repo_path, query_size=query_size)\n",
    "workflow.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conclusion</th>\n",
       "      <th>test</th>\n",
       "      <th>buildTime (sec)</th>\n",
       "      <th>jobId</th>\n",
       "      <th>failedAt</th>\n",
       "      <th>databaseId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (cold_storage, cold_storage, ../para...</td>\n",
       "      <td>85</td>\n",
       "      <td>37044161130</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (basic, basic, ../params.example.yam...</td>\n",
       "      <td>96</td>\n",
       "      <td>37044161606</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (presign, presign, ../params.example...</td>\n",
       "      <td>69</td>\n",
       "      <td>37044161918</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>tests-success</td>\n",
       "      <td>0</td>\n",
       "      <td>37044262983</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup-tests</td>\n",
       "      <td>102</td>\n",
       "      <td>37044273275</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-ne1.y...</td>\n",
       "      <td>222</td>\n",
       "      <td>37031740446</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-se1.y...</td>\n",
       "      <td>10945</td>\n",
       "      <td>37031741305</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (bucket_versioning, ../params...</td>\n",
       "      <td>101</td>\n",
       "      <td>37031741997</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (acl, ../params/br-ne1.yaml, ...</td>\n",
       "      <td>323</td>\n",
       "      <td>37031742597</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (policy, ../params/br-ne1.yam...</td>\n",
       "      <td>156</td>\n",
       "      <td>37031743174</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup_tests</td>\n",
       "      <td>105</td>\n",
       "      <td>37044113674</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-se1.y...</td>\n",
       "      <td>2168</td>\n",
       "      <td>37043704535</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-ne1.y...</td>\n",
       "      <td>246</td>\n",
       "      <td>37043705230</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (acl, ../params/br-ne1.yaml, ...</td>\n",
       "      <td>398</td>\n",
       "      <td>37043705967</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (bucket_versioning, ../params...</td>\n",
       "      <td>118</td>\n",
       "      <td>37043706472</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (policy, ../params/br-ne1.yam...</td>\n",
       "      <td>165</td>\n",
       "      <td>37043706867</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup_tests</td>\n",
       "      <td>113</td>\n",
       "      <td>37045803570</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conclusion                                               test  \\\n",
       "0      PASSED  run_tests (cold_storage, cold_storage, ../para...   \n",
       "1      PASSED  run_tests (basic, basic, ../params.example.yam...   \n",
       "2      PASSED  run_tests (presign, presign, ../params.example...   \n",
       "3      PASSED                                      tests-success   \n",
       "4      PASSED                                      cleanup-tests   \n",
       "5      PASSED  extra_tests_debug (locking, ../params/br-ne1.y...   \n",
       "6      PASSED  extra_tests_debug (locking, ../params/br-se1.y...   \n",
       "7      PASSED  extra_tests_dist (bucket_versioning, ../params...   \n",
       "8      PASSED  extra_tests_dist (acl, ../params/br-ne1.yaml, ...   \n",
       "9      PASSED  extra_tests_dist (policy, ../params/br-ne1.yam...   \n",
       "10     PASSED                                      cleanup_tests   \n",
       "11     PASSED  extra_tests_debug (locking, ../params/br-se1.y...   \n",
       "12     PASSED  extra_tests_debug (locking, ../params/br-ne1.y...   \n",
       "13     PASSED  extra_tests_dist (acl, ../params/br-ne1.yaml, ...   \n",
       "14     PASSED  extra_tests_dist (bucket_versioning, ../params...   \n",
       "15     PASSED  extra_tests_dist (policy, ../params/br-ne1.yam...   \n",
       "16     PASSED                                      cleanup_tests   \n",
       "\n",
       "    buildTime (sec)        jobId failedAt   databaseId  \n",
       "0                85  37044161130     None  13269149127  \n",
       "1                96  37044161606     None  13269149127  \n",
       "2                69  37044161918     None  13269149127  \n",
       "3                 0  37044262983     None  13269149127  \n",
       "4               102  37044273275     None  13269149127  \n",
       "5               222  37031740446     None  13265481700  \n",
       "6             10945  37031741305     None  13265481700  \n",
       "7               101  37031741997     None  13265481700  \n",
       "8               323  37031742597     None  13265481700  \n",
       "9               156  37031743174     None  13265481700  \n",
       "10              105  37044113674     None  13265481700  \n",
       "11             2168  37043704535     None  13269014124  \n",
       "12              246  37043705230     None  13269014124  \n",
       "13              398  37043705967     None  13269014124  \n",
       "14              118  37043706472     None  13269014124  \n",
       "15              165  37043706867     None  13269014124  \n",
       "16              113  37045803570     None  13269014124  "
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = ActionsJobs(repo_path, workflow)\n",
    "jobs.get_jobs(13269014124)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./artifacts/13160019050/output_artifact_not_cli_and_locking_se1.13160019050/pytest_output_not_cli_and_locking_se1.13160019050.log',\n",
       " './artifacts/13160019050/output_artifact_not_cli_and_locking_ne1.13160019050/pytest_output_not_cli_and_locking_ne1.13160019050.log',\n",
       " './artifacts/13269014124/output_artifact_policy_br.ne1.13269014124.13269014124/pytest_output_policy_br_ne1.13269014124.log',\n",
       " './artifacts/13269014124/output_artifact_locking_br.ne1.13269014124.13269014124/pytest_output_locking_br.ne1.13269014124.log',\n",
       " './artifacts/13269014124/output_artifact_bucket_versioning_br.ne1.13269014124.13269014124/pytest_output_bucket_versioning.br_ne1.13269014124.log',\n",
       " './artifacts/13269014124/output_artifact_locking_br.se1.13269014124.13269014124/pytest_output_locking_br_se1.13269014124.log',\n",
       " './artifacts/13269014124/output_artifact_acl_br.ne1.13269014124.13269014124/pytest_output_acl.br_ne1.13269014124.log']"
      ]
     },
     "execution_count": 918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifacts = ActionsArtifacts(repository=repo_path)\n",
    "#a = artifacts.download_artifact(13269014124)\n",
    "a = artifacts.retrieve_downloaded_artifacts()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regex like:\n",
    "+= (ALPHANUM and space) =+\n",
    "\n",
    "Get the categories and get everything in between but log stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./artifacts/13269014124/output_artifact_locking_br.ne1.13269014124.13269014124/pytest_output_locking_br.ne1.13269014124.log'"
      ]
     },
     "execution_count": 1063,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'pytest.log.parquet' does not exist.\n",
      "[' test session starts ', ['platform', 'linux', '--', 'Python', '3.13.1,', 'pytest-8.3.4,', 'pluggy-1.5.0', '--', '/__w/s3-specs/s3-specs/.venv/bin/python'], ['cachedir:', '.pytest_cache'], ['rootdir:', '/__w/s3-specs/s3-specs'], ['configfile:', 'pyproject.toml'], ['plugins:', 'durations-1.3.1,', 'repeat-0.9.3,', 'rerunfailures-15.0,', 'xdist-3.6.1,', 'env-1.1.5'], ['created:', '2/2', 'workers'], ['2', 'workers', '[28', 'items]'], ['scheduling', 'tests', 'via', 'LoadScheduling'], ['locking_test.py::test_policy_for_put_object_retention[bucket_with_policy0]'], [\"policies_test.py::test_put_invalid_bucket_policy[''-MalformedJSON]\"], ['[gw1]', '[', '3%]', 'PASSED', \"policies_test.py::test_put_invalid_bucket_policy[''-MalformedJSON]\"], ['policies_test.py::test_put_invalid_bucket_policy[{\\\\n', '\"Version\":', '\"2012-10-18\",\\\\n', '\"Statement\":', '[\\\\n', '{\\\\n', '\\\\xa8\\\\xa8', 'dsa\\\\n', '\"Effect\":', '\"Allow\",\\\\n', '\"Principal\":', '\"*\",\\\\n', '\"Action\":', '\"s3:GetObject\",\\\\n', '\"Resource\":', '\"vosso-bucket/*\"\\\\n', '}\\\\n', ']\\\\n}\\\\n-MalformedJSON]'], ['[gw0]', '[', '7%]', 'PASSED', 'locking_test.py::test_policy_for_put_object_retention[bucket_with_policy0]'], ['[gw1]', '[', '10%]', 'PASSED', 'policies_test.py::test_put_invalid_bucket_policy[{\\\\n', '\"Version\":', '\"2012-10-18\",\\\\n', '\"Statement\":', '[\\\\n', '{\\\\n', '\\\\xa8\\\\xa8', 'dsa\\\\n', '\"Effect\":', '\"Allow\",\\\\n', '\"Principal\":', '\"*\",\\\\n', '\"Action\":', '\"s3:GetObject\",\\\\n', '\"Resource\":', '\"vosso-bucket/*\"\\\\n', '}\\\\n', ']\\\\n}\\\\n-MalformedJSON]'], ['policies_test.py::test_put_invalid_bucket_policy[{\\\\n', '\"Version\":', '\"2012-10-18\",\\\\n', '\"Statement\":', '\\\\n', '{\\\\n', '\"Effect\":', '\"Allow\",\\\\n', '\"Principal\":', '\"*\",\\\\n', '\"Action\":', '\"s3:GetObject\",\\\\n', '\"Resource\":', '\"teu-bucket/*\"\\\\n', '}\\\\n', ']\\\\n}\\\\n-MalformedJSON]'], ['[gw1]', '[', '14%]', 'PASSED', 'policies_test.py::test_put_invalid_bucket_policy[{\\\\n', '\"Version\":', '\"2012-10-18\",\\\\n', '\"Statement\":', '\\\\n', '{\\\\n', '\"Effect\":', '\"Allow\",\\\\n', '\"Principal\":', '\"*\",\\\\n', '\"Action\":', '\"s3:GetObject\",\\\\n', '\"Resource\":', '\"teu-bucket/*\"\\\\n', '}\\\\n', ']\\\\n}\\\\n-MalformedJSON]'], ['policies_test.py::test_put_invalid_bucket_policy[-MalformedJSON]'], ['policies_test.py::test_put_invalid_bucket_policy[{}-MalformedPolicy]'], ['[gw1]', '[', '17%]', 'PASSED', 'policies_test.py::test_put_invalid_bucket_policy[{}-MalformedPolicy]'], ['[gw0]', '[', '21%]', 'PASSED', 'policies_test.py::test_put_invalid_bucket_policy[-MalformedJSON]'], ['policies_test.py::test_put_invalid_bucket_policy[\"\"-MalformedPolicy]'], ['policies_test.py::test_put_invalid_bucket_policy[jason-MalformedJSON]'], ['[gw1]', '[', '25%]', 'PASSED', 'policies_test.py::test_put_invalid_bucket_policy[\"\"-MalformedPolicy]'], ['[gw0]', '[', '28%]', 'PASSED', 'policies_test.py::test_put_invalid_bucket_policy[jason-MalformedJSON]'], ['policies_test.py::test_put_invalid_bucket_policy[{\\\\n', '\"Version\":', '\"2012-10-18\",\\\\n', '\"Statement\":', '[\\\\n', '{\\\\n', '\"Effect\":', '\"Allow\",\\\\n', '\"Principal\":', '\"*\",\\\\n', '\"Action\":', '\"s3:GetObject\",\\\\n', '\"Resource\":', '\"meu-bucket/*\"\\\\n', '}\\\\n', ']\\\\n}-MalformedPolicy]'], ['policies_test.py::test_setup_policies[s3:GetObject]'], ['[gw1]', '[', '32%]', 'PASSED', 'policies_test.py::test_put_invalid_bucket_policy[{\\\\n', '\"Version\":', '\"2012-10-18\",\\\\n', '\"Statement\":', '[\\\\n', '{\\\\n', '\"Effect\":', '\"Allow\",\\\\n', '\"Principal\":', '\"*\",\\\\n', '\"Action\":', '\"s3:GetObject\",\\\\n', '\"Resource\":', '\"meu-bucket/*\"\\\\n', '}\\\\n', ']\\\\n}-MalformedPolicy]'], ['policies_test.py::test_setup_policies[s3:PutObject]'], ['[gw0]', '[', '35%]', 'PASSED', 'policies_test.py::test_setup_policies[s3:GetObject]'], ['policies_test.py::test_setup_policies[s3:DeleteObject]'], ['[gw1]', '[', '39%]', 'PASSED', 'policies_test.py::test_setup_policies[s3:PutObject]'], ['policies_test.py::test_setup_policies[s3:GetObjectRetention]'], ['[gw0]', '[', '42%]', 'PASSED', 'policies_test.py::test_setup_policies[s3:DeleteObject]'], ['policies_test.py::test_setup_policies[s3:GetBucketObjectLockConfiguration]'], ['[gw1]', '[', '46%]', 'PASSED', 'policies_test.py::test_setup_policies[s3:GetObjectRetention]'], ['policies_test.py::test_setup_policies[s3:PutBucketObjectLockConfiguration]'], ['[gw0]', '[', '50%]', 'PASSED', 'policies_test.py::test_setup_policies[s3:GetBucketObjectLockConfiguration]'], ['policies_test.py::test_setup_policies[s3:PutObjectRetention]'], ['[gw1]', '[', '53%]', 'PASSED', 'policies_test.py::test_setup_policies[s3:PutBucketObjectLockConfiguration]'], ['[gw0]', '[', '57%]', 'PASSED', 'policies_test.py::test_setup_policies[s3:PutObjectRetention]'], ['policies_test.py::test_denied_policy_operations_by_owner[s3:GetObject,get_object]'], ['policies_test.py::test_denied_policy_operations_by_owner[s3:PutObject,put_object]'], ['[gw1]', '[', '60%]', 'PASSED', 'policies_test.py::test_denied_policy_operations_by_owner[s3:GetObject,get_object]'], ['[gw0]', '[', '64%]', 'PASSED', 'policies_test.py::test_denied_policy_operations_by_owner[s3:PutObject,put_object]'], ['policies_test.py::test_denied_policy_operations_by_owner[s3:DeleteObject,delete_object]'], ['policies_test.py::test_allow_policy_operations_by_owner[multiple_s3_clients0-bucket_with_one_object_policy0-put_object-200]'], ['[gw0]', '[', '67%]', 'PASSED', 'policies_test.py::test_allow_policy_operations_by_owner[multiple_s3_clients0-bucket_with_one_object_policy0-put_object-200]'], ['[gw1]', '[', '71%]', 'PASSED', 'policies_test.py::test_denied_policy_operations_by_owner[s3:DeleteObject,delete_object]'], ['policies_test.py::test_allow_policy_operations_by_owner[multiple_s3_clients1-bucket_with_one_object_policy1-get_object-200]'], ['policies_test.py::test_allow_policy_operations_by_owner[multiple_s3_clients2-bucket_with_one_object_policy2-delete_object-204]'], ['[gw1]', '[', '75%]', 'PASSED', 'policies_test.py::test_allow_policy_operations_by_owner[multiple_s3_clients1-bucket_with_one_object_policy1-get_object-200]'], ['[gw0]', '[', '78%]', 'PASSED', 'policies_test.py::test_allow_policy_operations_by_owner[multiple_s3_clients2-bucket_with_one_object_policy2-delete_object-204]'], ['profiles_policies_test.py::test_denied_policy_operations[multiple_s3_clients1-bucket_with_one_object_policy1-put_object]'], ['profiles_policies_test.py::test_denied_policy_operations[multiple_s3_clients0-bucket_with_one_object_policy0-get_object]'], ['[gw0]', '[', '82%]', 'PASSED', 'profiles_policies_test.py::test_denied_policy_operations[multiple_s3_clients1-bucket_with_one_object_policy1-put_object]'], ['[gw1]', '[', '85%]', 'PASSED', 'profiles_policies_test.py::test_denied_policy_operations[multiple_s3_clients0-bucket_with_one_object_policy0-get_object]'], ['profiles_policies_test.py::test_denied_policy_operations[multiple_s3_clients2-bucket_with_one_object_policy2-delete_object]'], ['profiles_policies_test.py::test_allowed_policy_operations[bucket_with_one_object_policy0-multiple_s3_clients0-get_object-200]'], ['[gw0]', '[', '89%]', 'PASSED', 'profiles_policies_test.py::test_denied_policy_operations[multiple_s3_clients2-bucket_with_one_object_policy2-delete_object]'], ['[gw1]', '[', '92%]', 'PASSED', 'profiles_policies_test.py::test_allowed_policy_operations[bucket_with_one_object_policy0-multiple_s3_clients0-get_object-200]'], ['profiles_policies_test.py::test_allowed_policy_operations[bucket_with_one_object_policy1-multiple_s3_clients1-put_object-200]'], ['profiles_policies_test.py::test_allowed_policy_operations[bucket_with_one_object_policy2-multiple_s3_clients2-delete_object-204]'], ['[gw0]', '[', '96%]', 'PASSED', 'profiles_policies_test.py::test_allowed_policy_operations[bucket_with_one_object_policy1-multiple_s3_clients1-put_object-200]'], ['[gw1]', '[100%]', 'PASSED', 'profiles_policies_test.py::test_allowed_policy_operations[bucket_with_one_object_policy2-multiple_s3_clients2-delete_object-204]']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>arguments</th>\n",
       "      <th>databaseId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[''-MalformedJSON]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locking_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[bucket_with_policy0]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[{\\n\"Version\":\"2012-10-18\",\\n\"Statement\":[\\n{\\...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[{\\n\"Version\":\"2012-10-18\",\\n\"Statement\":\\n{\\n...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[{}-MalformedPolicy]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[-MalformedJSON]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[\"\"-MalformedPolicy]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[jason-MalformedJSON]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[{\\n\"Version\":\"2012-10-18\",\\n\"Statement\":[\\n{\\...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[s3:GetObject]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[s3:PutObject]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[s3:DeleteObject]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[s3:GetObjectRetention]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[s3:GetBucketObjectLockConfiguration]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[s3:PutBucketObjectLockConfiguration]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[s3:PutObjectRetention]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[s3:GetObject,get_object]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[s3:PutObject,put_object]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[multiple_s3_clients0-bucket_with_one_object_p...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[s3:DeleteObject,delete_object]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[multiple_s3_clients1-bucket_with_one_object_p...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[multiple_s3_clients2-bucket_with_one_object_p...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profiles_policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[multiple_s3_clients1-bucket_with_one_object_p...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profiles_policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[multiple_s3_clients0-bucket_with_one_object_p...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profiles_policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[multiple_s3_clients2-bucket_with_one_object_p...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profiles_policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[bucket_with_one_object_policy0-multiple_s3_cl...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profiles_policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[bucket_with_one_object_policy1-multiple_s3_cl...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profiles_policies_test.py</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>[bucket_with_one_object_policy2-multiple_s3_cl...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           status  \\\n",
       "name                                \n",
       "policies_test.py           PASSED   \n",
       "locking_test.py            PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "policies_test.py           PASSED   \n",
       "profiles_policies_test.py  PASSED   \n",
       "profiles_policies_test.py  PASSED   \n",
       "profiles_policies_test.py  PASSED   \n",
       "profiles_policies_test.py  PASSED   \n",
       "profiles_policies_test.py  PASSED   \n",
       "profiles_policies_test.py  PASSED   \n",
       "\n",
       "                                                                   arguments  \\\n",
       "name                                                                           \n",
       "policies_test.py                                          [''-MalformedJSON]   \n",
       "locking_test.py                                        [bucket_with_policy0]   \n",
       "policies_test.py           [{\\n\"Version\":\"2012-10-18\",\\n\"Statement\":[\\n{\\...   \n",
       "policies_test.py           [{\\n\"Version\":\"2012-10-18\",\\n\"Statement\":\\n{\\n...   \n",
       "policies_test.py                                        [{}-MalformedPolicy]   \n",
       "policies_test.py                                            [-MalformedJSON]   \n",
       "policies_test.py                                        [\"\"-MalformedPolicy]   \n",
       "policies_test.py                                       [jason-MalformedJSON]   \n",
       "policies_test.py           [{\\n\"Version\":\"2012-10-18\",\\n\"Statement\":[\\n{\\...   \n",
       "policies_test.py                                              [s3:GetObject]   \n",
       "policies_test.py                                              [s3:PutObject]   \n",
       "policies_test.py                                           [s3:DeleteObject]   \n",
       "policies_test.py                                     [s3:GetObjectRetention]   \n",
       "policies_test.py                       [s3:GetBucketObjectLockConfiguration]   \n",
       "policies_test.py                       [s3:PutBucketObjectLockConfiguration]   \n",
       "policies_test.py                                     [s3:PutObjectRetention]   \n",
       "policies_test.py                                   [s3:GetObject,get_object]   \n",
       "policies_test.py                                   [s3:PutObject,put_object]   \n",
       "policies_test.py           [multiple_s3_clients0-bucket_with_one_object_p...   \n",
       "policies_test.py                             [s3:DeleteObject,delete_object]   \n",
       "policies_test.py           [multiple_s3_clients1-bucket_with_one_object_p...   \n",
       "policies_test.py           [multiple_s3_clients2-bucket_with_one_object_p...   \n",
       "profiles_policies_test.py  [multiple_s3_clients1-bucket_with_one_object_p...   \n",
       "profiles_policies_test.py  [multiple_s3_clients0-bucket_with_one_object_p...   \n",
       "profiles_policies_test.py  [multiple_s3_clients2-bucket_with_one_object_p...   \n",
       "profiles_policies_test.py  [bucket_with_one_object_policy0-multiple_s3_cl...   \n",
       "profiles_policies_test.py  [bucket_with_one_object_policy1-multiple_s3_cl...   \n",
       "profiles_policies_test.py  [bucket_with_one_object_policy2-multiple_s3_cl...   \n",
       "\n",
       "                          databaseId  \n",
       "name                                  \n",
       "policies_test.py                None  \n",
       "locking_test.py                 None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "policies_test.py                None  \n",
       "profiles_policies_test.py       None  \n",
       "profiles_policies_test.py       None  \n",
       "profiles_policies_test.py       None  \n",
       "profiles_policies_test.py       None  \n",
       "profiles_policies_test.py       None  \n",
       "profiles_policies_test.py       None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>num</th>\n",
       "      <th>avg</th>\n",
       "      <th>min</th>\n",
       "      <th>durationType</th>\n",
       "      <th>databaseId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_put_invalid_bucket_policy</th>\n",
       "      <td>00:00:10.547867</td>\n",
       "      <td>8</td>\n",
       "      <td>00:00:01.245508</td>\n",
       "      <td>00:00:01.154643</td>\n",
       "      <td>teardown duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_setup_policies</th>\n",
       "      <td>00:00:08.901066</td>\n",
       "      <td>7</td>\n",
       "      <td>00:00:01.226939</td>\n",
       "      <td>00:00:01.172176</td>\n",
       "      <td>teardown duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_policy_for_put_object_retention</th>\n",
       "      <td>00:00:07.686073</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:07.686073</td>\n",
       "      <td>00:00:07.686073</td>\n",
       "      <td>teardown duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_allow_policy_operations_by_owner</th>\n",
       "      <td>00:00:05.753325</td>\n",
       "      <td>3</td>\n",
       "      <td>00:00:02.281439</td>\n",
       "      <td>00:00:01.180476</td>\n",
       "      <td>teardown duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_denied_policy_operations</th>\n",
       "      <td>00:00:05.617999</td>\n",
       "      <td>3</td>\n",
       "      <td>00:00:01.829861</td>\n",
       "      <td>00:00:01.610648</td>\n",
       "      <td>teardown duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_denied_policy_operations_by_owner</th>\n",
       "      <td>00:00:05.401870</td>\n",
       "      <td>3</td>\n",
       "      <td>00:00:01.790580</td>\n",
       "      <td>00:00:01.635309</td>\n",
       "      <td>teardown duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_allowed_policy_operations</th>\n",
       "      <td>00:00:05.318242</td>\n",
       "      <td>3</td>\n",
       "      <td>00:00:01.642999</td>\n",
       "      <td>00:00:01.348751</td>\n",
       "      <td>teardown duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_denied_policy_operations_by_owner</th>\n",
       "      <td>00:00:27.781105</td>\n",
       "      <td>3</td>\n",
       "      <td>00:00:09.450651</td>\n",
       "      <td>00:00:08.359582</td>\n",
       "      <td>setup duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_allowed_policy_operations</th>\n",
       "      <td>00:00:25.494411</td>\n",
       "      <td>3</td>\n",
       "      <td>00:00:08.282293</td>\n",
       "      <td>00:00:08.204473</td>\n",
       "      <td>setup duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_denied_policy_operations</th>\n",
       "      <td>00:00:25.032095</td>\n",
       "      <td>3</td>\n",
       "      <td>00:00:08.180985</td>\n",
       "      <td>00:00:08.073443</td>\n",
       "      <td>setup duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_allow_policy_operations_by_owner</th>\n",
       "      <td>00:00:23.969315</td>\n",
       "      <td>3</td>\n",
       "      <td>00:00:08.100510</td>\n",
       "      <td>00:00:07.640353</td>\n",
       "      <td>setup duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_put_invalid_bucket_policy</th>\n",
       "      <td>00:00:23.644812</td>\n",
       "      <td>8</td>\n",
       "      <td>00:00:02.468826</td>\n",
       "      <td>00:00:01.783888</td>\n",
       "      <td>setup duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_setup_policies</th>\n",
       "      <td>00:00:13.412133</td>\n",
       "      <td>7</td>\n",
       "      <td>00:00:01.762887</td>\n",
       "      <td>00:00:01.648712</td>\n",
       "      <td>setup duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_policy_for_put_object_retention</th>\n",
       "      <td>00:00:09.406224</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:09.406224</td>\n",
       "      <td>00:00:09.406224</td>\n",
       "      <td>setup duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_setup_policies</th>\n",
       "      <td>00:00:02.977181</td>\n",
       "      <td>7</td>\n",
       "      <td>00:00:00.390910</td>\n",
       "      <td>00:00:00.282021</td>\n",
       "      <td>call duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_put_invalid_bucket_policy</th>\n",
       "      <td>00:00:02.238012</td>\n",
       "      <td>8</td>\n",
       "      <td>00:00:00.254690</td>\n",
       "      <td>00:00:00.250862</td>\n",
       "      <td>call duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_denied_policy_operations_by_owner</th>\n",
       "      <td>00:00:01.998813</td>\n",
       "      <td>3</td>\n",
       "      <td>00:00:00.660984</td>\n",
       "      <td>00:00:00.561960</td>\n",
       "      <td>call duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_allowed_policy_operations</th>\n",
       "      <td>00:00:01.241278</td>\n",
       "      <td>3</td>\n",
       "      <td>00:00:00.387190</td>\n",
       "      <td>00:00:00.312773</td>\n",
       "      <td>call duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_denied_policy_operations</th>\n",
       "      <td>00:00:01.070454</td>\n",
       "      <td>3</td>\n",
       "      <td>00:00:00.394271</td>\n",
       "      <td>00:00:00.272539</td>\n",
       "      <td>call duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_allow_policy_operations_by_owner</th>\n",
       "      <td>00:00:00.784549</td>\n",
       "      <td>3</td>\n",
       "      <td>00:00:00.251815</td>\n",
       "      <td>00:00:00.190266</td>\n",
       "      <td>call duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_policy_for_put_object_retention</th>\n",
       "      <td>00:00:00.208954</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:00.208954</td>\n",
       "      <td>00:00:00.208954</td>\n",
       "      <td>call duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bucket_with_one_object_policy</th>\n",
       "      <td>00:01:39.876942</td>\n",
       "      <td>12</td>\n",
       "      <td>00:00:08.082080</td>\n",
       "      <td>00:00:07.502911</td>\n",
       "      <td>fixture duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>existing_bucket_name</th>\n",
       "      <td>00:00:35.735850</td>\n",
       "      <td>15</td>\n",
       "      <td>00:00:01.955791</td>\n",
       "      <td>00:00:01.581206</td>\n",
       "      <td>fixture duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versioned_bucket_with_one_object</th>\n",
       "      <td>00:00:05.708998</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:05.708998</td>\n",
       "      <td>00:00:05.708998</td>\n",
       "      <td>fixture duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versioned_bucket_with_lock_config</th>\n",
       "      <td>00:00:03.018594</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:03.018594</td>\n",
       "      <td>00:00:03.018594</td>\n",
       "      <td>fixture duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_s3_clients</th>\n",
       "      <td>00:00:02.177794</td>\n",
       "      <td>12</td>\n",
       "      <td>00:00:00.150361</td>\n",
       "      <td>00:00:00.134375</td>\n",
       "      <td>fixture duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3_client</th>\n",
       "      <td>00:00:01.755754</td>\n",
       "      <td>19</td>\n",
       "      <td>00:00:00.067996</td>\n",
       "      <td>00:00:00.064265</td>\n",
       "      <td>fixture duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bucket_with_policy</th>\n",
       "      <td>00:00:00.416131</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:00.416131</td>\n",
       "      <td>00:00:00.416131</td>\n",
       "      <td>fixture duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_params</th>\n",
       "      <td>00:00:00.033509</td>\n",
       "      <td>28</td>\n",
       "      <td>00:00:00.001152</td>\n",
       "      <td>00:00:00.001095</td>\n",
       "      <td>fixture duration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  total num              avg  \\\n",
       "name                                                                           \n",
       "test_put_invalid_bucket_policy          00:00:10.547867   8  00:00:01.245508   \n",
       "test_setup_policies                     00:00:08.901066   7  00:00:01.226939   \n",
       "test_policy_for_put_object_retention    00:00:07.686073   1  00:00:07.686073   \n",
       "test_allow_policy_operations_by_owner   00:00:05.753325   3  00:00:02.281439   \n",
       "test_denied_policy_operations           00:00:05.617999   3  00:00:01.829861   \n",
       "test_denied_policy_operations_by_owner  00:00:05.401870   3  00:00:01.790580   \n",
       "test_allowed_policy_operations          00:00:05.318242   3  00:00:01.642999   \n",
       "test_denied_policy_operations_by_owner  00:00:27.781105   3  00:00:09.450651   \n",
       "test_allowed_policy_operations          00:00:25.494411   3  00:00:08.282293   \n",
       "test_denied_policy_operations           00:00:25.032095   3  00:00:08.180985   \n",
       "test_allow_policy_operations_by_owner   00:00:23.969315   3  00:00:08.100510   \n",
       "test_put_invalid_bucket_policy          00:00:23.644812   8  00:00:02.468826   \n",
       "test_setup_policies                     00:00:13.412133   7  00:00:01.762887   \n",
       "test_policy_for_put_object_retention    00:00:09.406224   1  00:00:09.406224   \n",
       "test_setup_policies                     00:00:02.977181   7  00:00:00.390910   \n",
       "test_put_invalid_bucket_policy          00:00:02.238012   8  00:00:00.254690   \n",
       "test_denied_policy_operations_by_owner  00:00:01.998813   3  00:00:00.660984   \n",
       "test_allowed_policy_operations          00:00:01.241278   3  00:00:00.387190   \n",
       "test_denied_policy_operations           00:00:01.070454   3  00:00:00.394271   \n",
       "test_allow_policy_operations_by_owner   00:00:00.784549   3  00:00:00.251815   \n",
       "test_policy_for_put_object_retention    00:00:00.208954   1  00:00:00.208954   \n",
       "bucket_with_one_object_policy           00:01:39.876942  12  00:00:08.082080   \n",
       "existing_bucket_name                    00:00:35.735850  15  00:00:01.955791   \n",
       "versioned_bucket_with_one_object        00:00:05.708998   1  00:00:05.708998   \n",
       "versioned_bucket_with_lock_config       00:00:03.018594   1  00:00:03.018594   \n",
       "multiple_s3_clients                     00:00:02.177794  12  00:00:00.150361   \n",
       "s3_client                               00:00:01.755754  19  00:00:00.067996   \n",
       "bucket_with_policy                      00:00:00.416131   1  00:00:00.416131   \n",
       "test_params                             00:00:00.033509  28  00:00:00.001152   \n",
       "\n",
       "                                                    min  \\\n",
       "name                                                      \n",
       "test_put_invalid_bucket_policy          00:00:01.154643   \n",
       "test_setup_policies                     00:00:01.172176   \n",
       "test_policy_for_put_object_retention    00:00:07.686073   \n",
       "test_allow_policy_operations_by_owner   00:00:01.180476   \n",
       "test_denied_policy_operations           00:00:01.610648   \n",
       "test_denied_policy_operations_by_owner  00:00:01.635309   \n",
       "test_allowed_policy_operations          00:00:01.348751   \n",
       "test_denied_policy_operations_by_owner  00:00:08.359582   \n",
       "test_allowed_policy_operations          00:00:08.204473   \n",
       "test_denied_policy_operations           00:00:08.073443   \n",
       "test_allow_policy_operations_by_owner   00:00:07.640353   \n",
       "test_put_invalid_bucket_policy          00:00:01.783888   \n",
       "test_setup_policies                     00:00:01.648712   \n",
       "test_policy_for_put_object_retention    00:00:09.406224   \n",
       "test_setup_policies                     00:00:00.282021   \n",
       "test_put_invalid_bucket_policy          00:00:00.250862   \n",
       "test_denied_policy_operations_by_owner  00:00:00.561960   \n",
       "test_allowed_policy_operations          00:00:00.312773   \n",
       "test_denied_policy_operations           00:00:00.272539   \n",
       "test_allow_policy_operations_by_owner   00:00:00.190266   \n",
       "test_policy_for_put_object_retention    00:00:00.208954   \n",
       "bucket_with_one_object_policy           00:00:07.502911   \n",
       "existing_bucket_name                    00:00:01.581206   \n",
       "versioned_bucket_with_one_object        00:00:05.708998   \n",
       "versioned_bucket_with_lock_config       00:00:03.018594   \n",
       "multiple_s3_clients                     00:00:00.134375   \n",
       "s3_client                               00:00:00.064265   \n",
       "bucket_with_policy                      00:00:00.416131   \n",
       "test_params                             00:00:00.001095   \n",
       "\n",
       "                                                 durationType databaseId  \n",
       "name                                                                      \n",
       "test_put_invalid_bucket_policy            teardown duration         None  \n",
       "test_setup_policies                       teardown duration         None  \n",
       "test_policy_for_put_object_retention      teardown duration         None  \n",
       "test_allow_policy_operations_by_owner     teardown duration         None  \n",
       "test_denied_policy_operations             teardown duration         None  \n",
       "test_denied_policy_operations_by_owner    teardown duration         None  \n",
       "test_allowed_policy_operations            teardown duration         None  \n",
       "test_denied_policy_operations_by_owner       setup duration         None  \n",
       "test_allowed_policy_operations               setup duration         None  \n",
       "test_denied_policy_operations                setup duration         None  \n",
       "test_allow_policy_operations_by_owner        setup duration         None  \n",
       "test_put_invalid_bucket_policy               setup duration         None  \n",
       "test_setup_policies                          setup duration         None  \n",
       "test_policy_for_put_object_retention         setup duration         None  \n",
       "test_setup_policies                           call duration         None  \n",
       "test_put_invalid_bucket_policy                call duration         None  \n",
       "test_denied_policy_operations_by_owner        call duration         None  \n",
       "test_allowed_policy_operations                call duration         None  \n",
       "test_denied_policy_operations                 call duration         None  \n",
       "test_allow_policy_operations_by_owner         call duration         None  \n",
       "test_policy_for_put_object_retention          call duration         None  \n",
       "bucket_with_one_object_policy              fixture duration         None  \n",
       "existing_bucket_name                       fixture duration         None  \n",
       "versioned_bucket_with_one_object           fixture duration         None  \n",
       "versioned_bucket_with_lock_config          fixture duration         None  \n",
       "multiple_s3_clients                        fixture duration         None  \n",
       "s3_client                                  fixture duration         None  \n",
       "bucket_with_policy                         fixture duration         None  \n",
       "test_params                                fixture duration         None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "artifact = PytestArtifactLogExtractor(path = a[2])\n",
    "cat, categories = artifact.log_to_df()\n",
    "\n",
    "display(cat)\n",
    "display(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2924319023.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[406], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Faz o teste -> gera graficos com tempo e taxa de falhas por tipo de teste\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Faz o teste -> gera graficos com tempo e taxa de falhas por tipo de teste\n",
    "\n",
    "Workflow -> Job -> Passos -> Resultados pytest \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define color mapping\n",
    "colors = {\n",
    "    'failure': 'firebrick',\n",
    "    'cancelled': 'darkgray',\n",
    "    'startup_failure': 'darkorange',\n",
    "    'success':  'darkgreen'\n",
    "}\n",
    "\n",
    "# Filter the DataFrame\n",
    "a = workflow.df[workflow.df['status'] == 'completed']\n",
    "\n",
    "# Get value counts of the 'conclusion' columnimport matplotlib.pyplot as plt\n",
    "\n",
    "# Define color mapping\n",
    "colors = {\n",
    "    'failure': 'firebrick',\n",
    "    'cancelled': 'darkgray',\n",
    "    'startup_failure':'darkorange',\n",
    "    'success':  'darkgreen'\n",
    "\n",
    "}\n",
    "\n",
    "# Filter the DataFrame\n",
    "a = workflow.df[workflow.df['status'] == 'completed']\n",
    "\n",
    "# Get value counts of the 'conclusion' column\n",
    "value_counts = a['conclusion'].value_counts()\n",
    "\n",
    "# Map colors to the categories in value_counts\n",
    "bar_colors = [colors[cat] for cat in value_counts.index]\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))  # 1 row, 2 columns\n",
    "\n",
    "# Plot the bar chart on the first subplot\n",
    "value_counts.plot.bar(color=bar_colors, ax=ax1)\n",
    "ax1.set_xlabel('Conclusion')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Bar Chart: Conclusion Counts')\n",
    "\n",
    "# Plot the pie chart on the second subplot\n",
    "value_counts.plot.pie(colors=bar_colors, autopct='%1.1f%%', ax=ax2)\n",
    "ax2.set_ylabel('')  # Remove the y-label for the pie chart\n",
    "ax2.set_title('Pie Chart: Conclusion Distribution')\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n",
    "value_counts = a['conclusion'].value_counts()\n",
    "\n",
    "# Map colors to the categories in value_counts\n",
    "bar_colors = [colors[cat] for cat in value_counts.index]\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))  # 1 row, 2 columns\n",
    "\n",
    "# Plot the bar chart on the first subplot\n",
    "value_counts.plot.bar(color=bar_colors, ax=ax1)\n",
    "ax1.set_xlabel('Conclusion')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Bar Chart: Conclusion Counts')\n",
    "\n",
    "# Plot the pie chart on the second subplot\n",
    "value_counts.plot.pie(colors=bar_colors, autopct='%1.1f%%', ax=ax2)\n",
    "ax2.set_ylabel('')  # Remove the y-label for the pie chart\n",
    "ax2.set_title('Pie Chart: Conclusion Distribution')\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jobs Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = ActionsJobs(repository=repo_path, workflow=workflow)\n",
    "ids = workflow.df['databaseId'].unique()\n",
    "all_job_dfs = [jobs.get_jobs(id)for id in ids]\n",
    "jobs_df = pd.concat(all_job_dfs)\n",
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_failed_passed_jobs_bars(df):\n",
    "    unique_names = df.groupby(['Test', 'Conclusion']).size().unstack(fill_value=0)\n",
    "    test_to_number = {test: i + 1 for i, test in enumerate(df['Test'].unique())}\n",
    "\n",
    "    # Define colors for 'FAILED' and 'PASSED'\n",
    "    colors = {\n",
    "        'FAILED': 'firebrick',\n",
    "        'PASSED': 'darkgreen'\n",
    "    }\n",
    "\n",
    "    ax = unique_names.plot.bar(color=[colors['FAILED'], colors['PASSED']], figsize=(8, 4))\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('Test')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('FAILED vs PASSED by Test')\n",
    "\n",
    "    # Change the x-tick labels to their respective numbers\n",
    "    ax.set_xticklabels([test_to_number[test] for test in unique_names.index], rotation=0)\n",
    "\n",
    "    # Create a legend for the test numbers and names\n",
    "    test_legend = [f\"{num}. {test}\" for test, num in test_to_number.items()]\n",
    "    plt.figtext(1.05, 0.5, \"\\n\".join(test_legend), va='center', fontsize=10, wrap=True)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "#plot_failed_passed_jobs_bars(jobs_df[jobs_df['Conclusion'] == 'FAILED'])\n",
    "plot_failed_passed_jobs_bars(jobs_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
