{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "from itertools import chain\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArqManipulation:\n",
    "    \"\"\"\n",
    "    A utility class for file operations and data manipulation.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod \n",
    "    def read_parquet_file(parquet_file_name: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Reads a Parquet file and returns a DataFrame.\n",
    "\n",
    "        :param parquet_file_name: Path to the Parquet file.\n",
    "        :return: DataFrame with file contents.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(parquet_file_name):\n",
    "                print(f\"File '{parquet_file_name}' does not exist.\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            return pd.read_parquet(parquet_file_name)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error reading Parquet file '{parquet_file_name}': {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def save_df_to_parquet(df: pd.DataFrame, parquet_file_name: str):\n",
    "        \"\"\"\n",
    "        Saves a DataFrame to a Parquet file.\n",
    "\n",
    "        :param df: Dataframe to save.\n",
    "        :param parquet_file_name: Parqueet saving path.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(parquet_file_name), exist_ok=True)\n",
    "            df.to_parquet(parquet_file_name)\n",
    "            print(f\"DataFrame successfully saved to {parquet_file_name}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error saving DataFrame to Parquet file '{parquet_file_name}': {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_ansi_escape(base_str: str) -> str:\n",
    "        \"\"\"\n",
    "        Removes ANSI escape values from a string.\n",
    "\n",
    "        :param base_str: Unformmated string.\n",
    "        :return: Cleaned string.\n",
    "        \"\"\"\n",
    "        return re.sub(r'\\x1B\\[[0-9;]*[A-Za-z]', '', base_str)\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_stdout_json(base_str: str) -> dict:\n",
    "        \"\"\"\n",
    "        Parses JSON output from GitHub CLI after cleaning ANSI escape sequences.\n",
    "\n",
    "        :param base_str: The raw output string from the GitHub CLI.\n",
    "        :return: Parsed JSON dictionary.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            cleaned = ArqManipulation.clean_ansi_escape(base_str)\n",
    "            str_output = ''.join(cleaned.splitlines())\n",
    "            return json.loads(str_output)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise e\n",
    "\n",
    "    @staticmethod\n",
    "    def json_to_df(parsed_json: dict) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Converts a JSON dictionary to a sorted DataFrame with specific columns.\n",
    "\n",
    "        :param parsed_json: Parsed JSON data.\n",
    "        :return: Pandas DataFrame sorted by the 'createdAt' column.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df_json = pd.DataFrame(parsed_json)\n",
    "            required_columns = ['name', 'createdAt', 'conclusion', 'status', 'databaseId', 'workflowDatabaseId']\n",
    "            \n",
    "            if not all(col in df_json.columns for col in required_columns):\n",
    "                raise KeyError(f\"Missing required columns in JSON data: {set(required_columns) - set(df_json.columns)}\")\n",
    "\n",
    "            df_json['createdAt'] = pd.to_datetime(df_json['createdAt'])\n",
    "            return df_json[required_columns].sort_values(by=\"createdAt\")\n",
    "        except KeyError as e:\n",
    "            raise ValueError(f\"Error processing JSON to DataFrame: {e}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Unexpected error in json_to_df: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionsWorkflow:\n",
    "    \"\"\"\n",
    "    A class to extract GitHub Actions workflows using the GitHub CLI, generating a dataframe with returned data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, repository, query_size):\n",
    "        \"\"\"\n",
    "        Initializes the ActionsWorkflow class.\n",
    "\n",
    "        :param repository: GitHub repository in the format \"owner/repo\".\n",
    "        :param query_size: Number of workflows to retrieve.\n",
    "        \"\"\"\n",
    "        self.repository = repository\n",
    "        self.json_attributes = '--json name,status,conclusion,createdAt,databaseId,workflowDatabaseId'\n",
    "        self.query_size = query_size\n",
    "        self.df = self.__gh_list_query__()\n",
    "\n",
    "    def __gh_list_query__(self):\n",
    "        \"\"\"\n",
    "        Calls the GitHub API via the GitHub CLI (`gh run list`) and retrieves\n",
    "        a specified number of workflows.\n",
    "\n",
    "        :return: A DataFrame containing the parsed workflow data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            list_command = f'gh run --repo {self.repository} list {self.json_attributes} -L {self.query_size}'\n",
    "            \n",
    "            output_json = subprocess.run(\n",
    "                list_command, shell=True, text=True, check=True, capture_output=True\n",
    "            ).stdout\n",
    "\n",
    "            parsed_json = ArqManipulation.parse_stdout_json(output_json)\n",
    "            df = ArqManipulation.json_to_df(parsed_json)\n",
    "\n",
    "            ArqManipulation.save_df_to_parquet(df = df, parquet_file_name=\"./bin/actionsWorflow.parquet\")\n",
    "\n",
    "            return df.set_index('name')\n",
    "\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error executing GitHub CLI command: {e}\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame on error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionsJobs:\n",
    "    \"\"\"\n",
    "    A class to interact with GitHub Actions jobs using the GitHub CLI.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, repository, workflow):\n",
    "        \"\"\"\n",
    "        Initializes the ActionsJobs class.\n",
    "\n",
    "        :param repository: GitHub repository in the format \"owner/repo\".\n",
    "        :param workflow: Workflow associated with the jobs.\n",
    "        \"\"\"\n",
    "        self.repository = repository\n",
    "        self.workflow = workflow  \n",
    "\n",
    "    def __retrieve_jobs__(self, database_id: int):\n",
    "        command = f'gh run --repo {self.repository} view {database_id}'\n",
    "        jobs_data = subprocess.run(command, shell=True, text=True, check=True, capture_output=True).stdout\n",
    "\n",
    "        return jobs_data\n",
    "\n",
    "    def get_jobs(self, database_id: int) -> pd.DataFrame:\n",
    "            \"\"\"\n",
    "            Retrieves job data from the GitHub CLI and processes it.\n",
    "\n",
    "            :param database_id: The ID of the workflow run.\n",
    "            :return: A Pandas DataFrame containing job details.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                jobs_df = ArqManipulation.read_parquet_file(parquet_file_name=\"./bin/actionsJobs.parquet\")\n",
    "\n",
    "                if jobs_df.empty:\n",
    "                    data = self.__retrieve_jobs__(database_id=database_id)\n",
    "                    jobs_df = self.__clean_job_text__(data)\n",
    "\n",
    "                    jobs_df[\"databaseId\"] = int(database_id)\n",
    "\n",
    "                    ArqManipulation.save_df_to_parquet(jobs_df, parquet_file_name=\"./bin/actionsJobs.parquet\")\n",
    "\n",
    "                elif not database_id in jobs_df['databaseId'].values:\n",
    "                    data = self.__retrieve_jobs__(database_id=database_id)\n",
    "                    data_df = self.__clean_job_text__(data)\n",
    "                    data_df[\"databaseId\"] = int(database_id)\n",
    "\n",
    "                    jobs_df = pd.concat([jobs_df, data_df], ignore_index=True)\n",
    "\n",
    "                    ArqManipulation.save_df_to_parquet(jobs_df, parquet_file_name=\"./bin/actionsJobs.parquet\")\n",
    "\n",
    "                return jobs_df\n",
    "\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"Error executing GitHub CLI command: {e}\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "                return pd.DataFrame()\n",
    "        \n",
    "    def __split_string__(self, job_list):\n",
    "        \"\"\"\n",
    "        Splits a job string into structured components.\n",
    "\n",
    "        :param job: The job string to split.\n",
    "        :return: A list of cleaned job attributes.\n",
    "        \"\"\"\n",
    "        jobs = []\n",
    "\n",
    "        for job in job_list:\n",
    "            delimiters = r\" \\| | / build in | \\(ID |\\| in| / cleanup in | /| in \" \n",
    "            splitted_job = re.split(delimiters, job)\n",
    "            splitted_job = [s.strip() for s in splitted_job if s.strip()]\n",
    "            jobs.append(splitted_job)\n",
    "        \n",
    "        jobs.pop(0)\n",
    "\n",
    "        return jobs\n",
    "\n",
    "    def __build_cleaned_df__(self, data):\n",
    "        # Define columns\n",
    "        columns = [\"conclusion\", \"test\", \"buildTime (sec)\", \"jobId\"]\n",
    "        jobs_df = pd.DataFrame(columns=columns)\n",
    "        jobs_df[\"failedAt\"] = None\n",
    "\n",
    "        for job in data:\n",
    "            if any(\"ID\" in item and (\"PASSED\" in item or \"FAILED\" in item) for item in job):\n",
    "                temp_df = pd.DataFrame(self.__split_string__(job), columns=columns)\n",
    "\n",
    "                temp_df['buildTime (sec)'] = temp_df['buildTime (sec)'].apply(str_time_to_int)\n",
    "                jobs_df = pd.concat([jobs_df, temp_df], ignore_index=True)\n",
    "            \n",
    "            elif any(\"FAILED\" in item for item in job):\n",
    "                failed = next(item for item in job if \"FAILED\" in item).split(\"FAILED | \")\n",
    "                if not jobs_df.empty:\n",
    "                    jobs_df.at[jobs_df.index[-1], \"failedAt\"] = failed[1]  \n",
    "\n",
    "        jobs_df[\"jobId\"] = jobs_df[\"jobId\"].str.rstrip(\")\").astype('int')\n",
    "        return jobs_df\n",
    "\n",
    "\n",
    "    def __find_jobs__(self, base_str: str) -> list[str]:\n",
    "        lines = base_str.splitlines()\n",
    "        arr = []  # Stores grouped sections\n",
    "        current_group = []  # Temporary storage for the current section\n",
    "\n",
    "        for line in lines:\n",
    "            if line.isupper() or not line.strip():  # New section (uppercase or empty line)\n",
    "                if current_group:  # Avoid adding empty groups\n",
    "                    arr.append(current_group)\n",
    "                current_group = [line]  # Start a new group\n",
    "            else:\n",
    "                current_group.append(line)\n",
    "\n",
    "        if current_group:  # Append the last group\n",
    "            arr.append(current_group)\n",
    "\n",
    "        # Filter out groups that do not start with an uppercase title\n",
    "        filtered_arr = [group for group in arr if group and group[0].isupper()]\n",
    "        return filtered_arr\n",
    "\n",
    "    def __clean_job_text__(self, base_str: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Cleans and structures GitHub job data from CLI output.\n",
    "\n",
    "        :param base_str: Raw job text output from the GitHub CLI.\n",
    "        :return: A Pandas DataFrame with structured job data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Remove ANSI escape sequences and unwanted characters\n",
    "            ansi_cleaned = ArqManipulation.clean_ansi_escape(base_str)\n",
    "            cleaned = ansi_cleaned.replace(\"✓\", \"PASSED |\").replace(\"X\", \"FAILED |\")\n",
    "\n",
    "            stripped_list = self.__find_jobs__(cleaned)\n",
    "\n",
    "            if not (x.find('JOBS') or x.find(\"ANNOTATIONS\") for x in stripped_list):\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            jobs_df = self.__build_cleaned_df__(stripped_list)\n",
    "\n",
    "            return jobs_df\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing job text: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    \n",
    "\n",
    "def str_time_to_int(time_str: str) -> int:\n",
    "    \"\"\"\n",
    "    Converts a time string to seconds.\n",
    "    returns: int\n",
    "    \"\"\"\n",
    "    names = ['d', 'h', 'm', 's']\n",
    "    seconds = [86400, 3600, 60, 1]\n",
    "\n",
    "    total_time = 0\n",
    "\n",
    "    for m, t in zip(names,seconds):\n",
    "        if m in time_str:\n",
    "            time_list = time_str.split(m)\n",
    "            total_time +=  int(time_list[0]) * t\n",
    "            time_str = time_list[1]\n",
    "\n",
    "    return total_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionsArtifacts:\n",
    "    \"\"\"\n",
    "    A class to handle downloading, retrieving, and deleting GitHub Actions artifacts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, repository: str):\n",
    "        \"\"\"\n",
    "        Initializes the ActionsArtifacts object.\n",
    "\n",
    "        :param repository: The GitHub repository in the format \"owner/repo\".\n",
    "        \"\"\"\n",
    "        self.repository = repository\n",
    "        self.folder = './artifacts/'  # Default storage dir\n",
    "        self.paths = self.retrieve_downloaded_artifacts() \n",
    "\n",
    "    def download_artifact(self, database_id: str):\n",
    "        \"\"\"\n",
    "        Downloads an artifact from GitHub Actions using the GitHub CLI.\n",
    "\n",
    "        :param database_id: The database ID of the artifact to download.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Ensure the folder exists before downloading\n",
    "            os.makedirs(self.folder, exist_ok=True)\n",
    "\n",
    "            # Construct the command to download the artifact\n",
    "            command = f'gh run --repo {self.repository} download {database_id} --dir {os.path.join(self.folder, str(database_id))}'\n",
    "\n",
    "            # Execute the command\n",
    "            subprocess.run(command, shell=True, text=True, check=True)\n",
    "            print(\"Download Successful\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error during artifact download: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "\n",
    "    def retrieve_downloaded_artifacts(self) -> list[str]:\n",
    "        \"\"\"\n",
    "        Retrieves all downloaded artifacts file paths.\n",
    "\n",
    "        :return: returns Paths of the downloaded artifacts\n",
    "        \"\"\"\n",
    "        paths = []\n",
    "\n",
    "        # Walk through the artifacts folder and collect all file paths\n",
    "        for path, _, files in os.walk(self.folder):\n",
    "            for file in files:\n",
    "                paths.append(os.path.join(path, file))\n",
    "\n",
    "        return paths\n",
    "\n",
    "    def delete_downloaded_artifacts(self):\n",
    "        \"\"\"\n",
    "        Deletes all downloaded artifacts recursively\n",
    "        \"\"\"\n",
    "        try:\n",
    "            shutil.rmtree(self.folder)\n",
    "            if os.path.exists(self.folder):\n",
    "                print(\"Error: Failed to delete artifacts directory.\")\n",
    "            else:\n",
    "                print(\"Artifacts directory deleted successfully.\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"Artifacts directory not found, nothing to delete.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while deleting artifacts: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytestArtifactLogExtractor:\n",
    "    \"\"\"\n",
    "    A class to extract and process test status and timing information from a pytest artifact log.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str):\n",
    "        \"\"\"\n",
    "        Initializes the PytestArtifactLogExtractor object.\n",
    "\n",
    "        :param path: Path to the pytest artifact log file.\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.data = self.__read_file__()\n",
    "\n",
    "    def __read_file__(self):\n",
    "        \"\"\"\n",
    "        Reads the contents of the log file and returns it as a string.\n",
    "\n",
    "        :return: String containing the file content.\n",
    "        \"\"\"\n",
    "        with open(self.path, \"r\") as file: \n",
    "            data = file.read()\n",
    "\n",
    "        return ArqManipulation.clean_ansi_escape(data)\n",
    "\n",
    "    def log_to_df(self):\n",
    "        \"\"\"\n",
    "        Parses the log file to extract test results and performance metrics.\n",
    "\n",
    "        :return: A DataFrame combining test statuses with time metrics.\n",
    "        \"\"\"\n",
    "\n",
    "        df_parquet = ArqManipulation.read_parquet_file(parquet_file_name='pytest.log.parquet')   \n",
    "\n",
    "        databaseId = self.__extract_self_path_info__().get('databaseId').get(0)\n",
    "        databaseId = int(databaseId) if databaseId else None \n",
    "    \n",
    "        if not df_parquet.empty and (databaseId in df_parquet['databaseId']):\n",
    "            return df_parquet\n",
    "\n",
    "        tests, categories, failures = self.__extract_all_categories__()\n",
    "        \n",
    "        # Creating dataframes test status and categories\n",
    "        status_df = pd.DataFrame(tests, columns=[\"status\", \"name\", \"category\", \"arguments\"]).set_index('name')\n",
    "        categories_df = self.__create_df__(categories)\n",
    "        failures_df = pd.DataFrame(failures,columns=['name', 'category', 'arguments', 'error', 'error_details']).set_index('name')\n",
    "\n",
    "        # Labeling the dfs\n",
    "        status_df.index.name = 'pytest_tests_status'\n",
    "        categories_df.index.name = 'pytest_run_times'\n",
    "        failures_df.index.name = 'pytest_failures_errors'\n",
    "\n",
    "        # Applying individual id for each table\n",
    "        status_df['databaseId'] = databaseId\n",
    "        categories_df['databaseId'] = databaseId\n",
    "        failures_df['databaseId'] = databaseId\n",
    "\n",
    "\n",
    "        return status_df, categories_df, failures_df\n",
    "\n",
    "    def __extract_all_categories__(self):\n",
    "        \"\"\"\n",
    "        Converts extracted timing data into DataFrames.\n",
    "\n",
    "        :param values: A list of lists with extracted time metrics.\n",
    "        :type values: list[list]\n",
    "        :return: A list of DataFrames with execution time statistics.\n",
    "        :rtype: list[pandas.DataFrame]\n",
    "        \"\"\"\n",
    "        header = []\n",
    "        # Filtering out irrelevant categories\n",
    "        keywords = ('deselected', 'passed in', 'grand total', 'live log')\n",
    "\n",
    "        values = self.data.splitlines()\n",
    "        for value in values:\n",
    "            if any(k in value for k in keywords):\n",
    "                continue   \n",
    "            elif re.match(r'=+|-+', value): # Divide by headers demarked by '=' or '-' (logging)\n",
    "                value = value.replace(\"=\", \"\")  \n",
    "                value = value.replace(\"-\", \"\")  \n",
    "                header.append([value]) \n",
    "            else:\n",
    "                # Populate each category and break in the case of the pytest-durations tables while ignoring empty values\n",
    "                value = re.split(r\"\\s+\", value) \n",
    "                if list(filter(None, value)):\n",
    "                    header[-1].append(list(filter(None, value)))\n",
    "\n",
    "        headers = [['live_log','live_log','live_log']]\n",
    "        if not 'live log' in self.data:\n",
    "            headers = self.__extract_test_status_names__(self.__get_list_by_name__(header, 'session')[0])\n",
    "            \n",
    "        categories = self.__get_list_by_name__(header, 'duration top')\n",
    "        failures = self.__extract_failures_errors__(self.__get_list_by_name__(header, 'summary')[0])\n",
    "\n",
    "        return headers, categories, failures\n",
    "\n",
    "    def __get_list_by_name__(self, data: list, name: str):\n",
    "        \"\"\"\n",
    "        Find the sublist containing the specified name in the first element.\n",
    "\n",
    "        :param data: A list of sublists to search through.\n",
    "        :type data: list[list]\n",
    "        :param name: The name to search for in the first element of each sublist.\n",
    "        :type name: str\n",
    "        :return: A list of sublists where the first element matches the name.\n",
    "        :rtype: list[list]\n",
    "        \"\"\"\n",
    "        matching_sublists = []\n",
    "        \n",
    "        for sublist in data:\n",
    "            if re.search(name, sublist[0]):  # Converte os itens para string\n",
    "                matching_sublists.append(sublist)\n",
    "        \n",
    "        return matching_sublists\n",
    "\n",
    "    def __extract_test_status_names__(self, data):\n",
    "        \"\"\"\n",
    "        Extracts the status and the tests names out of the pytest log, breaking them down to a list of lists.\n",
    "\n",
    "        :param data: A list of lines containing test results.\n",
    "        :type data: list[str]\n",
    "        :return: list[list[str]]: A list of lists with test names, statuses (PASSED, FAILED, ERROR), and additional details.\n",
    "        \"\"\"\n",
    "\n",
    "        tests = []\n",
    "        keywords = ('PASSED', 'FAILED', 'ERROR')\n",
    "\n",
    "        for line in data:\n",
    "            line = ''.join(line).strip()\n",
    "            \n",
    "            if any(k in line for k in keywords):\n",
    "                line = re.sub(r'\\[.*?\\d%\\]', '', line)\n",
    "                parts = line.split('::', maxsplit=1)\n",
    "\n",
    "                match = re.search(r'(PASSED|FAILED|ERROR)', parts[0])\n",
    "                if match:\n",
    "                    test_name = parts[0][:match.start()].strip()\n",
    "                    status = match.group(0)\n",
    "                else:\n",
    "                    test_name, status = parts[0], None\n",
    "\n",
    "                tmp = [test_name, status]\n",
    "\n",
    "                if len(parts) > 1:\n",
    "                    values = list(filter(None, re.split(r'\\[(.*?)\\]', parts[1])))\n",
    "                    tmp += values\n",
    "                \n",
    "                while len(tmp) < 4:\n",
    "                    tmp.append(None)\n",
    "\n",
    "                tests.append(tmp)\n",
    "        \n",
    "        return tests\n",
    "\n",
    "    def __extract_failures_errors__(self, data):\n",
    "\n",
    "        \"\"\"\n",
    "        Extracts from the pytest log the details of tests with failures or errors cleaning the data to make it ready to a dataframe.\n",
    "\n",
    "        :param data: A list of strings containing test results.\n",
    "        :type data: list[str]\n",
    "        :return: list[list]: A list of lists containing details of tests with failures and/or errors.\n",
    "        \"\"\"\n",
    "\n",
    "        # Regex asks for a string, cleaning it and concatening the list\n",
    "        data_str = ''.join(list(''.join(d) for d in data[1:]))\n",
    "        data_str = list(filter(None, re.split(r'(FAILED|ERROR)', data_str)))\n",
    "\n",
    "        splitted_data = []\n",
    "\n",
    "        # Splitting test from error\n",
    "        for d in data_str:\n",
    "            if d and ('FAILED' or 'ERROR') not in d:\n",
    "                splitted_data.append(list(filter(None, re.split(r'\\[(.*?)\\]-|::|(\\w+):([\\w=*]+)', d))))   \n",
    "\n",
    "        return splitted_data\n",
    "\n",
    "    def __create_df__(self, values):\n",
    "        \"\"\"\n",
    "        Converts extracted timing information into DataFrames.\n",
    "\n",
    "        :param values: A list of lists containing extracted time metrics.\n",
    "        :return: A list of DataFrames with execution time statistics.\n",
    "        \"\"\"\n",
    "        dfs = pd.DataFrame()\n",
    "        \n",
    "        for h in values:\n",
    "            time_df = pd.DataFrame(h[2:], columns=h[1])\n",
    "\n",
    "            # Converting time-related columns to datetime.time format\n",
    "            time_columns = ['avg', 'min', 'total']\n",
    "            for col in time_columns:\n",
    "                if col in time_df.columns:\n",
    "                    time_df[col] = pd.to_timedelta(time_df[col], errors='coerce').dt.total_seconds().round(3)\n",
    "                    \n",
    "            # Assigning a 'durationType' column for metric categorization\n",
    "            time_df['durationType'] = h[0].replace('top', '').replace('test', '')\n",
    "\n",
    "            dfs = pd.concat([time_df, dfs], ignore_index=True)\n",
    "\n",
    "        if 'name' in dfs.columns:\n",
    "            dfs = dfs.set_index('name') \n",
    "\n",
    "        return dfs\n",
    "\n",
    "    def __extract_self_path_info__(self):\n",
    "        \"\"\"\n",
    "        Extracts test and database ID information from the log file path.\n",
    "\n",
    "        :return: A DataFrame containing 'test' and 'databaseId' information.\n",
    "        \"\"\"\n",
    "        # Extract filename without extension\n",
    "        stripped = self.path.split('/')[-1].split('.')\n",
    "        stripped.pop()  # Remove the file extension\n",
    "\n",
    "        # Ensure there are exactly three elements (fill missing ones with None)\n",
    "        while len(stripped) < 3:\n",
    "            stripped.append(None)  # Fill missing values with NaN\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame([stripped], columns=['test', 'region', 'databaseId'])\n",
    "\n",
    "        return df\n",
    "\n",
    "    def __merge_artifact_dfs__(self, times_df, status_df):\n",
    "        \"\"\"\n",
    "        Merges test execution time data with test status information.\n",
    "\n",
    "        :param times_df: A list of DataFrames containing time-related data.\n",
    "        :param status_df: A DataFrame containing test statuses.\n",
    "        :return: A combined DataFrame containing execution metrics and test results.\n",
    "        \"\"\"\n",
    "        databaseId_df = self.__extract_self_path_info__()  \n",
    "        order = ['category', 'durationType', 'databaseId', 'status', 'num', 'avg', 'min', 'total']\n",
    "        dfs = []\n",
    "\n",
    "        for h in times_df:\n",
    "            joined_df = h.join(status_df)  # Merging time metrics with test statuses\n",
    "\n",
    "            # Adding database ID to each row\n",
    "            for col in databaseId_df.columns.values:\n",
    "                joined_df[col] = databaseId_df[col].values[0]  \n",
    "\n",
    "            # Reordering columns\n",
    "            joined_df = joined_df[order]  \n",
    "            dfs.append(joined_df)\n",
    "\n",
    "        return pd.concat(dfs)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Main\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying and creating each dataframe and their respective classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully saved to ./bin/actionsWorflow.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>createdAt</th>\n",
       "      <th>conclusion</th>\n",
       "      <th>status</th>\n",
       "      <th>databaseId</th>\n",
       "      <th>workflowDatabaseId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pull Request Essential Tests</th>\n",
       "      <td>2025-02-11 14:42:01+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13265481705</td>\n",
       "      <td>132962917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Extra Tests</th>\n",
       "      <td>2025-02-11 14:42:01+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13265481700</td>\n",
       "      <td>142271933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Extra Tests</th>\n",
       "      <td>2025-02-11 17:37:25+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269014124</td>\n",
       "      <td>142271933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Essential Tests</th>\n",
       "      <td>2025-02-11 17:37:25+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269014120</td>\n",
       "      <td>132962917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Essential Tests</th>\n",
       "      <td>2025-02-11 17:39:58+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269057739</td>\n",
       "      <td>132962917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Extra Tests</th>\n",
       "      <td>2025-02-11 17:39:58+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269057738</td>\n",
       "      <td>142271933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Extra Tests</th>\n",
       "      <td>2025-02-11 17:45:26+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269149128</td>\n",
       "      <td>142271933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Essential Tests</th>\n",
       "      <td>2025-02-11 17:45:26+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269149127</td>\n",
       "      <td>132962917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Essential Tests</th>\n",
       "      <td>2025-02-11 17:52:13+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269265728</td>\n",
       "      <td>132962917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pull Request Extra Tests</th>\n",
       "      <td>2025-02-11 17:52:13+00:00</td>\n",
       "      <td>success</td>\n",
       "      <td>completed</td>\n",
       "      <td>13269265723</td>\n",
       "      <td>142271933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             createdAt conclusion     status  \\\n",
       "name                                                                           \n",
       "Pull Request Essential Tests 2025-02-11 14:42:01+00:00    success  completed   \n",
       "Pull Request Extra Tests     2025-02-11 14:42:01+00:00    success  completed   \n",
       "Pull Request Extra Tests     2025-02-11 17:37:25+00:00    success  completed   \n",
       "Pull Request Essential Tests 2025-02-11 17:37:25+00:00    success  completed   \n",
       "Pull Request Essential Tests 2025-02-11 17:39:58+00:00    success  completed   \n",
       "Pull Request Extra Tests     2025-02-11 17:39:58+00:00    success  completed   \n",
       "Pull Request Extra Tests     2025-02-11 17:45:26+00:00    success  completed   \n",
       "Pull Request Essential Tests 2025-02-11 17:45:26+00:00    success  completed   \n",
       "Pull Request Essential Tests 2025-02-11 17:52:13+00:00    success  completed   \n",
       "Pull Request Extra Tests     2025-02-11 17:52:13+00:00    success  completed   \n",
       "\n",
       "                               databaseId  workflowDatabaseId  \n",
       "name                                                           \n",
       "Pull Request Essential Tests  13265481705           132962917  \n",
       "Pull Request Extra Tests      13265481700           142271933  \n",
       "Pull Request Extra Tests      13269014124           142271933  \n",
       "Pull Request Essential Tests  13269014120           132962917  \n",
       "Pull Request Essential Tests  13269057739           132962917  \n",
       "Pull Request Extra Tests      13269057738           142271933  \n",
       "Pull Request Extra Tests      13269149128           142271933  \n",
       "Pull Request Essential Tests  13269149127           132962917  \n",
       "Pull Request Essential Tests  13269265728           132962917  \n",
       "Pull Request Extra Tests      13269265723           142271933  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_path = 'MagaluCloud/s3-specs'\n",
    "query_size = 10\n",
    "\n",
    "workflow = ActionsWorkflow(repository=repo_path, query_size=query_size)\n",
    "workflow.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conclusion</th>\n",
       "      <th>test</th>\n",
       "      <th>buildTime (sec)</th>\n",
       "      <th>jobId</th>\n",
       "      <th>failedAt</th>\n",
       "      <th>databaseId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (cold_storage, cold_storage, ../para...</td>\n",
       "      <td>85</td>\n",
       "      <td>37044161130</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (basic, basic, ../params.example.yam...</td>\n",
       "      <td>96</td>\n",
       "      <td>37044161606</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (presign, presign, ../params.example...</td>\n",
       "      <td>69</td>\n",
       "      <td>37044161918</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>tests-success</td>\n",
       "      <td>0</td>\n",
       "      <td>37044262983</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup-tests</td>\n",
       "      <td>102</td>\n",
       "      <td>37044273275</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-ne1.y...</td>\n",
       "      <td>222</td>\n",
       "      <td>37031740446</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-se1.y...</td>\n",
       "      <td>10945</td>\n",
       "      <td>37031741305</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (bucket_versioning, ../params...</td>\n",
       "      <td>101</td>\n",
       "      <td>37031741997</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (acl, ../params/br-ne1.yaml, ...</td>\n",
       "      <td>323</td>\n",
       "      <td>37031742597</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (policy, ../params/br-ne1.yam...</td>\n",
       "      <td>156</td>\n",
       "      <td>37031743174</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup_tests</td>\n",
       "      <td>105</td>\n",
       "      <td>37044113674</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-se1.y...</td>\n",
       "      <td>2168</td>\n",
       "      <td>37043704535</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-ne1.y...</td>\n",
       "      <td>246</td>\n",
       "      <td>37043705230</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (acl, ../params/br-ne1.yaml, ...</td>\n",
       "      <td>398</td>\n",
       "      <td>37043705967</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (bucket_versioning, ../params...</td>\n",
       "      <td>118</td>\n",
       "      <td>37043706472</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (policy, ../params/br-ne1.yam...</td>\n",
       "      <td>165</td>\n",
       "      <td>37043706867</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup_tests</td>\n",
       "      <td>113</td>\n",
       "      <td>37045803570</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (basic, basic, ../params.example.yam...</td>\n",
       "      <td>87</td>\n",
       "      <td>37031740475</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (presign, presign, ../params.example...</td>\n",
       "      <td>73</td>\n",
       "      <td>37031741335</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (cold_storage, cold_storage, ../para...</td>\n",
       "      <td>83</td>\n",
       "      <td>37031742054</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>tests-success</td>\n",
       "      <td>0</td>\n",
       "      <td>37031853981</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup-tests</td>\n",
       "      <td>660</td>\n",
       "      <td>37031865199</td>\n",
       "      <td>None</td>\n",
       "      <td>13265481705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (basic, basic, ../params.example.yam...</td>\n",
       "      <td>91</td>\n",
       "      <td>37043704527</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (cold_storage, cold_storage, ../para...</td>\n",
       "      <td>76</td>\n",
       "      <td>37043705219</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (presign, presign, ../params.example...</td>\n",
       "      <td>67</td>\n",
       "      <td>37043705993</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>tests-success</td>\n",
       "      <td>0</td>\n",
       "      <td>37043801778</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup-tests</td>\n",
       "      <td>135</td>\n",
       "      <td>37043810257</td>\n",
       "      <td>None</td>\n",
       "      <td>13269014120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (presign, presign, ../params.example...</td>\n",
       "      <td>69</td>\n",
       "      <td>37043851890</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (basic, basic, ../params.example.yam...</td>\n",
       "      <td>92</td>\n",
       "      <td>37043852293</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (cold_storage, cold_storage, ../para...</td>\n",
       "      <td>76</td>\n",
       "      <td>37043852681</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>tests-success</td>\n",
       "      <td>0</td>\n",
       "      <td>37043951393</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup-tests</td>\n",
       "      <td>100</td>\n",
       "      <td>37043960162</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (bucket_versioning, ../params...</td>\n",
       "      <td>109</td>\n",
       "      <td>37043851761</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-ne1.y...</td>\n",
       "      <td>248</td>\n",
       "      <td>37043852208</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-se1.y...</td>\n",
       "      <td>2174</td>\n",
       "      <td>37043852553</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (acl, ../params/br-ne1.yaml, ...</td>\n",
       "      <td>362</td>\n",
       "      <td>37043852871</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (policy, ../params/br-ne1.yam...</td>\n",
       "      <td>168</td>\n",
       "      <td>37043853176</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup_tests</td>\n",
       "      <td>106</td>\n",
       "      <td>37045950987</td>\n",
       "      <td>None</td>\n",
       "      <td>13269057738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (acl, ../params/br-ne1.yaml, ...</td>\n",
       "      <td>395</td>\n",
       "      <td>37044161190</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (policy, ../params/br-ne1.yam...</td>\n",
       "      <td>189</td>\n",
       "      <td>37044161643</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (bucket_versioning, ../params...</td>\n",
       "      <td>122</td>\n",
       "      <td>37044161988</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-ne1.y...</td>\n",
       "      <td>281</td>\n",
       "      <td>37044162281</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-se1.y...</td>\n",
       "      <td>2336</td>\n",
       "      <td>37044162628</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup_tests</td>\n",
       "      <td>103</td>\n",
       "      <td>37046417463</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (basic, basic, ../params.example.yam...</td>\n",
       "      <td>90</td>\n",
       "      <td>37044549750</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (presign, presign, ../params.example...</td>\n",
       "      <td>74</td>\n",
       "      <td>37044550292</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (cold_storage, cold_storage, ../para...</td>\n",
       "      <td>75</td>\n",
       "      <td>37044550738</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>tests-success</td>\n",
       "      <td>0</td>\n",
       "      <td>37044639767</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup-tests</td>\n",
       "      <td>107</td>\n",
       "      <td>37044648883</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-ne1.y...</td>\n",
       "      <td>300</td>\n",
       "      <td>37044549759</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-se1.y...</td>\n",
       "      <td>2205</td>\n",
       "      <td>37044550263</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (acl, ../params/br-ne1.yaml, ...</td>\n",
       "      <td>466</td>\n",
       "      <td>37044550660</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (bucket_versioning, ../params...</td>\n",
       "      <td>119</td>\n",
       "      <td>37044550932</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (policy, ../params/br-ne1.yam...</td>\n",
       "      <td>181</td>\n",
       "      <td>37044551314</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup_tests</td>\n",
       "      <td>101</td>\n",
       "      <td>37046670818</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conclusion                                               test  \\\n",
       "0      PASSED  run_tests (cold_storage, cold_storage, ../para...   \n",
       "1      PASSED  run_tests (basic, basic, ../params.example.yam...   \n",
       "2      PASSED  run_tests (presign, presign, ../params.example...   \n",
       "3      PASSED                                      tests-success   \n",
       "4      PASSED                                      cleanup-tests   \n",
       "5      PASSED  extra_tests_debug (locking, ../params/br-ne1.y...   \n",
       "6      PASSED  extra_tests_debug (locking, ../params/br-se1.y...   \n",
       "7      PASSED  extra_tests_dist (bucket_versioning, ../params...   \n",
       "8      PASSED  extra_tests_dist (acl, ../params/br-ne1.yaml, ...   \n",
       "9      PASSED  extra_tests_dist (policy, ../params/br-ne1.yam...   \n",
       "10     PASSED                                      cleanup_tests   \n",
       "11     PASSED  extra_tests_debug (locking, ../params/br-se1.y...   \n",
       "12     PASSED  extra_tests_debug (locking, ../params/br-ne1.y...   \n",
       "13     PASSED  extra_tests_dist (acl, ../params/br-ne1.yaml, ...   \n",
       "14     PASSED  extra_tests_dist (bucket_versioning, ../params...   \n",
       "15     PASSED  extra_tests_dist (policy, ../params/br-ne1.yam...   \n",
       "16     PASSED                                      cleanup_tests   \n",
       "17     PASSED  run_tests (basic, basic, ../params.example.yam...   \n",
       "18     PASSED  run_tests (presign, presign, ../params.example...   \n",
       "19     PASSED  run_tests (cold_storage, cold_storage, ../para...   \n",
       "20     PASSED                                      tests-success   \n",
       "21     PASSED                                      cleanup-tests   \n",
       "22     PASSED  run_tests (basic, basic, ../params.example.yam...   \n",
       "23     PASSED  run_tests (cold_storage, cold_storage, ../para...   \n",
       "24     PASSED  run_tests (presign, presign, ../params.example...   \n",
       "25     PASSED                                      tests-success   \n",
       "26     PASSED                                      cleanup-tests   \n",
       "27     PASSED  run_tests (presign, presign, ../params.example...   \n",
       "28     PASSED  run_tests (basic, basic, ../params.example.yam...   \n",
       "29     PASSED  run_tests (cold_storage, cold_storage, ../para...   \n",
       "30     PASSED                                      tests-success   \n",
       "31     PASSED                                      cleanup-tests   \n",
       "32     PASSED  extra_tests_dist (bucket_versioning, ../params...   \n",
       "33     PASSED  extra_tests_debug (locking, ../params/br-ne1.y...   \n",
       "34     PASSED  extra_tests_debug (locking, ../params/br-se1.y...   \n",
       "35     PASSED  extra_tests_dist (acl, ../params/br-ne1.yaml, ...   \n",
       "36     PASSED  extra_tests_dist (policy, ../params/br-ne1.yam...   \n",
       "37     PASSED                                      cleanup_tests   \n",
       "38     PASSED  extra_tests_dist (acl, ../params/br-ne1.yaml, ...   \n",
       "39     PASSED  extra_tests_dist (policy, ../params/br-ne1.yam...   \n",
       "40     PASSED  extra_tests_dist (bucket_versioning, ../params...   \n",
       "41     PASSED  extra_tests_debug (locking, ../params/br-ne1.y...   \n",
       "42     PASSED  extra_tests_debug (locking, ../params/br-se1.y...   \n",
       "43     PASSED                                      cleanup_tests   \n",
       "44     PASSED  run_tests (basic, basic, ../params.example.yam...   \n",
       "45     PASSED  run_tests (presign, presign, ../params.example...   \n",
       "46     PASSED  run_tests (cold_storage, cold_storage, ../para...   \n",
       "47     PASSED                                      tests-success   \n",
       "48     PASSED                                      cleanup-tests   \n",
       "49     PASSED  extra_tests_debug (locking, ../params/br-ne1.y...   \n",
       "50     PASSED  extra_tests_debug (locking, ../params/br-se1.y...   \n",
       "51     PASSED  extra_tests_dist (acl, ../params/br-ne1.yaml, ...   \n",
       "52     PASSED  extra_tests_dist (bucket_versioning, ../params...   \n",
       "53     PASSED  extra_tests_dist (policy, ../params/br-ne1.yam...   \n",
       "54     PASSED                                      cleanup_tests   \n",
       "\n",
       "    buildTime (sec)        jobId failedAt   databaseId  \n",
       "0                85  37044161130     None  13269149127  \n",
       "1                96  37044161606     None  13269149127  \n",
       "2                69  37044161918     None  13269149127  \n",
       "3                 0  37044262983     None  13269149127  \n",
       "4               102  37044273275     None  13269149127  \n",
       "5               222  37031740446     None  13265481700  \n",
       "6             10945  37031741305     None  13265481700  \n",
       "7               101  37031741997     None  13265481700  \n",
       "8               323  37031742597     None  13265481700  \n",
       "9               156  37031743174     None  13265481700  \n",
       "10              105  37044113674     None  13265481700  \n",
       "11             2168  37043704535     None  13269014124  \n",
       "12              246  37043705230     None  13269014124  \n",
       "13              398  37043705967     None  13269014124  \n",
       "14              118  37043706472     None  13269014124  \n",
       "15              165  37043706867     None  13269014124  \n",
       "16              113  37045803570     None  13269014124  \n",
       "17               87  37031740475     None  13265481705  \n",
       "18               73  37031741335     None  13265481705  \n",
       "19               83  37031742054     None  13265481705  \n",
       "20                0  37031853981     None  13265481705  \n",
       "21              660  37031865199     None  13265481705  \n",
       "22               91  37043704527     None  13269014120  \n",
       "23               76  37043705219     None  13269014120  \n",
       "24               67  37043705993     None  13269014120  \n",
       "25                0  37043801778     None  13269014120  \n",
       "26              135  37043810257     None  13269014120  \n",
       "27               69  37043851890     None  13269057739  \n",
       "28               92  37043852293     None  13269057739  \n",
       "29               76  37043852681     None  13269057739  \n",
       "30                0  37043951393     None  13269057739  \n",
       "31              100  37043960162     None  13269057739  \n",
       "32              109  37043851761     None  13269057738  \n",
       "33              248  37043852208     None  13269057738  \n",
       "34             2174  37043852553     None  13269057738  \n",
       "35              362  37043852871     None  13269057738  \n",
       "36              168  37043853176     None  13269057738  \n",
       "37              106  37045950987     None  13269057738  \n",
       "38              395  37044161190     None  13269149128  \n",
       "39              189  37044161643     None  13269149128  \n",
       "40              122  37044161988     None  13269149128  \n",
       "41              281  37044162281     None  13269149128  \n",
       "42             2336  37044162628     None  13269149128  \n",
       "43              103  37046417463     None  13269149128  \n",
       "44               90  37044549750     None  13269265728  \n",
       "45               74  37044550292     None  13269265728  \n",
       "46               75  37044550738     None  13269265728  \n",
       "47                0  37044639767     None  13269265728  \n",
       "48              107  37044648883     None  13269265728  \n",
       "49              300  37044549759     None  13269265723  \n",
       "50             2205  37044550263     None  13269265723  \n",
       "51              466  37044550660     None  13269265723  \n",
       "52              119  37044550932     None  13269265723  \n",
       "53              181  37044551314     None  13269265723  \n",
       "54              101  37046670818     None  13269265723  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = ActionsJobs(repo_path, workflow)\n",
    "jobs.get_jobs(13269014124)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./artifacts/local_artifact.br_se1.123456.log',\n",
       " './artifacts/13160019050/output_artifact_not_cli_and_locking_se1.13160019050/pytest_output_not_cli_and_locking_se1.13160019050.log',\n",
       " './artifacts/13160019050/output_artifact_not_cli_and_locking_ne1.13160019050/pytest_output_not_cli_and_locking_ne1.13160019050.log',\n",
       " './artifacts/13269014124/output_artifact_policy_br.ne1.13269014124.13269014124/pytest_output_policy_br_ne1.13269014124.log',\n",
       " './artifacts/13269014124/output_artifact_locking_br.ne1.13269014124.13269014124/pytest_output_locking_br.ne1.13269014124.log',\n",
       " './artifacts/13269014124/output_artifact_bucket_versioning_br.ne1.13269014124.13269014124/pytest_output_bucket_versioning.br_ne1.13269014124.log',\n",
       " './artifacts/13269014124/output_artifact_locking_br.se1.13269014124.13269014124/pytest_output_locking_br_se1.13269014124.log',\n",
       " './artifacts/13269014124/output_artifact_acl_br.ne1.13269014124.13269014124/pytest_output_acl.br_ne1.13269014124.log']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifacts = ActionsArtifacts(repository=repo_path)\n",
    "#a = artifacts.download_artifact(13269014124)\n",
    "a = artifacts.retrieve_downloaded_artifacts()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>category</th>\n",
       "      <th>arguments</th>\n",
       "      <th>databaseId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pytest_tests_status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FAILED</th>\n",
       "      <td></td>\n",
       "      <td>test_upload_multiple_objects</td>\n",
       "      <td>num=100-5-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASSED</th>\n",
       "      <td></td>\n",
       "      <td>test_upload_multiple_objects</td>\n",
       "      <td>num=100-3-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAILED</th>\n",
       "      <td></td>\n",
       "      <td>test_upload_multiple_objects</td>\n",
       "      <td>num=100-9-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASSED</th>\n",
       "      <td></td>\n",
       "      <td>test_upload_multiple_objects</td>\n",
       "      <td>num=100-1-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASSED</th>\n",
       "      <td></td>\n",
       "      <td>test_upload_multiple_objects</td>\n",
       "      <td>num=100-7-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASSED</th>\n",
       "      <td></td>\n",
       "      <td>test_upload_multiple_objects</td>\n",
       "      <td>num=100-6-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASSED</th>\n",
       "      <td></td>\n",
       "      <td>test_upload_multiple_objects</td>\n",
       "      <td>num=100-4-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASSED</th>\n",
       "      <td></td>\n",
       "      <td>test_download_multiple_objects</td>\n",
       "      <td>num=100-1-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASSED</th>\n",
       "      <td></td>\n",
       "      <td>test_upload_multiple_objects</td>\n",
       "      <td>num=100-10-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASSED</th>\n",
       "      <td></td>\n",
       "      <td>test_download_multiple_objects</td>\n",
       "      <td>num=100-5-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAILED</th>\n",
       "      <td></td>\n",
       "      <td>test_download_multiple_objects</td>\n",
       "      <td>num=100-3-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASSED</th>\n",
       "      <td></td>\n",
       "      <td>test_download_multiple_objects</td>\n",
       "      <td>num=100-9-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASSED</th>\n",
       "      <td></td>\n",
       "      <td>test_download_multiple_objects</td>\n",
       "      <td>num=100-7-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASSED</th>\n",
       "      <td></td>\n",
       "      <td>test_upload_multiple_objects</td>\n",
       "      <td>num=100-8-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASSED</th>\n",
       "      <td></td>\n",
       "      <td>test_upload_multiple_objects</td>\n",
       "      <td>num=100-2-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASSED</th>\n",
       "      <td></td>\n",
       "      <td>test_download_multiple_objects</td>\n",
       "      <td>num=100-2-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASSED</th>\n",
       "      <td></td>\n",
       "      <td>test_download_multiple_objects</td>\n",
       "      <td>num=100-10-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAILED</th>\n",
       "      <td></td>\n",
       "      <td>test_download_multiple_objects</td>\n",
       "      <td>num=100-4-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASSED</th>\n",
       "      <td></td>\n",
       "      <td>test_download_multiple_objects</td>\n",
       "      <td>num=100-8-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASSED</th>\n",
       "      <td></td>\n",
       "      <td>test_download_multiple_objects</td>\n",
       "      <td>num=100-6-10</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    status                        category      arguments  \\\n",
       "pytest_tests_status                                                         \n",
       "FAILED                        test_upload_multiple_objects   num=100-5-10   \n",
       "PASSED                        test_upload_multiple_objects   num=100-3-10   \n",
       "FAILED                        test_upload_multiple_objects   num=100-9-10   \n",
       "PASSED                        test_upload_multiple_objects   num=100-1-10   \n",
       "PASSED                        test_upload_multiple_objects   num=100-7-10   \n",
       "PASSED                        test_upload_multiple_objects   num=100-6-10   \n",
       "PASSED                        test_upload_multiple_objects   num=100-4-10   \n",
       "PASSED                      test_download_multiple_objects   num=100-1-10   \n",
       "PASSED                        test_upload_multiple_objects  num=100-10-10   \n",
       "PASSED                      test_download_multiple_objects   num=100-5-10   \n",
       "FAILED                      test_download_multiple_objects   num=100-3-10   \n",
       "PASSED                      test_download_multiple_objects   num=100-9-10   \n",
       "PASSED                      test_download_multiple_objects   num=100-7-10   \n",
       "PASSED                        test_upload_multiple_objects   num=100-8-10   \n",
       "PASSED                        test_upload_multiple_objects   num=100-2-10   \n",
       "PASSED                      test_download_multiple_objects   num=100-2-10   \n",
       "PASSED                      test_download_multiple_objects  num=100-10-10   \n",
       "FAILED                      test_download_multiple_objects   num=100-4-10   \n",
       "PASSED                      test_download_multiple_objects   num=100-8-10   \n",
       "PASSED                      test_download_multiple_objects   num=100-6-10   \n",
       "\n",
       "                     databaseId  \n",
       "pytest_tests_status              \n",
       "FAILED                   123456  \n",
       "PASSED                   123456  \n",
       "FAILED                   123456  \n",
       "PASSED                   123456  \n",
       "PASSED                   123456  \n",
       "PASSED                   123456  \n",
       "PASSED                   123456  \n",
       "PASSED                   123456  \n",
       "PASSED                   123456  \n",
       "PASSED                   123456  \n",
       "FAILED                   123456  \n",
       "PASSED                   123456  \n",
       "PASSED                   123456  \n",
       "PASSED                   123456  \n",
       "PASSED                   123456  \n",
       "PASSED                   123456  \n",
       "PASSED                   123456  \n",
       "FAILED                   123456  \n",
       "PASSED                   123456  \n",
       "PASSED                   123456  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>num</th>\n",
       "      <th>avg</th>\n",
       "      <th>min</th>\n",
       "      <th>durationType</th>\n",
       "      <th>databaseId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pytest_run_times</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_download_multiple_objects</th>\n",
       "      <td>40.495</td>\n",
       "      <td>10</td>\n",
       "      <td>3.311</td>\n",
       "      <td>2.036</td>\n",
       "      <td>teardown duration</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_upload_multiple_objects</th>\n",
       "      <td>28.457</td>\n",
       "      <td>10</td>\n",
       "      <td>2.639</td>\n",
       "      <td>1.722</td>\n",
       "      <td>teardown duration</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_download_multiple_objects</th>\n",
       "      <td>66.248</td>\n",
       "      <td>10</td>\n",
       "      <td>6.636</td>\n",
       "      <td>3.790</td>\n",
       "      <td>setup duration</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_upload_multiple_objects</th>\n",
       "      <td>8.536</td>\n",
       "      <td>10</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.541</td>\n",
       "      <td>setup duration</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_download_multiple_objects</th>\n",
       "      <td>65.466</td>\n",
       "      <td>10</td>\n",
       "      <td>6.557</td>\n",
       "      <td>5.550</td>\n",
       "      <td>call duration</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_upload_multiple_objects</th>\n",
       "      <td>43.853</td>\n",
       "      <td>10</td>\n",
       "      <td>4.015</td>\n",
       "      <td>1.980</td>\n",
       "      <td>call duration</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixture_upload_multiple_objects</th>\n",
       "      <td>57.072</td>\n",
       "      <td>10</td>\n",
       "      <td>5.959</td>\n",
       "      <td>3.087</td>\n",
       "      <td>fixture duration</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixture_bucket_with_name</th>\n",
       "      <td>15.654</td>\n",
       "      <td>20</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.478</td>\n",
       "      <td>fixture duration</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3_client</th>\n",
       "      <td>2.011</td>\n",
       "      <td>20</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.057</td>\n",
       "      <td>fixture duration</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_params</th>\n",
       "      <td>0.030</td>\n",
       "      <td>20</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>fixture duration</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  total num    avg    min  \\\n",
       "pytest_run_times                                            \n",
       "test_download_multiple_objects   40.495  10  3.311  2.036   \n",
       "test_upload_multiple_objects     28.457  10  2.639  1.722   \n",
       "test_download_multiple_objects   66.248  10  6.636  3.790   \n",
       "test_upload_multiple_objects      8.536  10  0.841  0.541   \n",
       "test_download_multiple_objects   65.466  10  6.557  5.550   \n",
       "test_upload_multiple_objects     43.853  10  4.015  1.980   \n",
       "fixture_upload_multiple_objects  57.072  10  5.959  3.087   \n",
       "fixture_bucket_with_name         15.654  20  0.844  0.478   \n",
       "s3_client                         2.011  20  0.086  0.057   \n",
       "test_params                       0.030  20  0.002  0.001   \n",
       "\n",
       "                                          durationType  databaseId  \n",
       "pytest_run_times                                                    \n",
       "test_download_multiple_objects     teardown duration        123456  \n",
       "test_upload_multiple_objects       teardown duration        123456  \n",
       "test_download_multiple_objects        setup duration        123456  \n",
       "test_upload_multiple_objects          setup duration        123456  \n",
       "test_download_multiple_objects         call duration        123456  \n",
       "test_upload_multiple_objects           call duration        123456  \n",
       "fixture_upload_multiple_objects     fixture duration        123456  \n",
       "fixture_bucket_with_name            fixture duration        123456  \n",
       "s3_client                           fixture duration        123456  \n",
       "test_params                         fixture duration        123456  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>arguments</th>\n",
       "      <th>error</th>\n",
       "      <th>error_details</th>\n",
       "      <th>databaseId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pytest_failures_errors</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>docs/multiple_objects_test.py</th>\n",
       "      <td>test_upload_multiple_objects</td>\n",
       "      <td>num=100-5-10</td>\n",
       "      <td>AssertionError</td>\n",
       "      <td>Expectsuploads100tobeequaltoobjectsinthebucket...</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>docs/multiple_objects_test.py</th>\n",
       "      <td>test_upload_multiple_objects</td>\n",
       "      <td>num=100-9-10</td>\n",
       "      <td>AssertionError</td>\n",
       "      <td>Expectsuploads100tobeequaltoobjectsinthebucket...</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>docs/multiple_objects_test.py</th>\n",
       "      <td>test_download_multiple_objects</td>\n",
       "      <td>num=100-3-10</td>\n",
       "      <td>AssertionError</td>\n",
       "      <td>Expectsdownloads99tobeequaltouploads100assert9...</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>docs/multiple_objects_test.py</th>\n",
       "      <td>test_download_multiple_objects</td>\n",
       "      <td>num=100-4-10</td>\n",
       "      <td>AssertionError</td>\n",
       "      <td>Expectsdownloads99tobeequaltouploads100assert9...</td>\n",
       "      <td>123456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     category     arguments  \\\n",
       "pytest_failures_errors                                                        \n",
       "docs/multiple_objects_test.py    test_upload_multiple_objects  num=100-5-10   \n",
       "docs/multiple_objects_test.py    test_upload_multiple_objects  num=100-9-10   \n",
       "docs/multiple_objects_test.py  test_download_multiple_objects  num=100-3-10   \n",
       "docs/multiple_objects_test.py  test_download_multiple_objects  num=100-4-10   \n",
       "\n",
       "                                        error  \\\n",
       "pytest_failures_errors                          \n",
       "docs/multiple_objects_test.py  AssertionError   \n",
       "docs/multiple_objects_test.py  AssertionError   \n",
       "docs/multiple_objects_test.py  AssertionError   \n",
       "docs/multiple_objects_test.py  AssertionError   \n",
       "\n",
       "                                                                   error_details  \\\n",
       "pytest_failures_errors                                                             \n",
       "docs/multiple_objects_test.py  Expectsuploads100tobeequaltoobjectsinthebucket...   \n",
       "docs/multiple_objects_test.py  Expectsuploads100tobeequaltoobjectsinthebucket...   \n",
       "docs/multiple_objects_test.py  Expectsdownloads99tobeequaltouploads100assert9...   \n",
       "docs/multiple_objects_test.py  Expectsdownloads99tobeequaltouploads100assert9...   \n",
       "\n",
       "                               databaseId  \n",
       "pytest_failures_errors                     \n",
       "docs/multiple_objects_test.py      123456  \n",
       "docs/multiple_objects_test.py      123456  \n",
       "docs/multiple_objects_test.py      123456  \n",
       "docs/multiple_objects_test.py      123456  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "artifact = PytestArtifactLogExtractor(path = a[0])\n",
    "pytest_tests_status\t, pytest_run_times, pytest_failures_errors = artifact.log_to_df()\n",
    "\n",
    "# Trocar databaseId por jobId\n",
    "display(pytest_tests_status)\n",
    "display(pytest_run_times)\n",
    "display(pytest_failures_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "test_upload_multiple_objects      2\n",
       "test_download_multiple_objects    2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_passed = pytest_tests_status[pytest_tests_status.index.values != 'PASSED'].set_index('category')\n",
    "total_passed.index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_passed</th>\n",
       "      <th>num_failed</th>\n",
       "      <th>total_runs</th>\n",
       "      <th>min_test_time</th>\n",
       "      <th>avg_test_time</th>\n",
       "      <th>total_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_upload_multiple_objects</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>4.243</td>\n",
       "      <td>7.495</td>\n",
       "      <td>80.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_download_multiple_objects</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>11.376</td>\n",
       "      <td>16.504</td>\n",
       "      <td>172.209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                num_passed  num_failed  total_runs  \\\n",
       "test_upload_multiple_objects             2           8          10   \n",
       "test_download_multiple_objects           2           8          10   \n",
       "\n",
       "                                min_test_time  avg_test_time  total_duration  \n",
       "test_upload_multiple_objects            4.243          7.495          80.846  \n",
       "test_download_multiple_objects         11.376         16.504         172.209  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_times = pd.Series(dict(map(lambda t: (t, sum(pytest_run_times[pytest_run_times.index == t].get('total'))), pytest_tests_status.category.unique())))\n",
    "avg_time_test  = pd.Series(dict(map(lambda t: (t, sum(pytest_run_times[pytest_run_times.index == t].get('avg'))), pytest_tests_status.category.unique())))\n",
    "min_test_time  = pd.Series(dict(map(lambda t: (t, sum(pytest_run_times[pytest_run_times.index == t].get('min'))), pytest_tests_status.category.unique())))\n",
    "total_nums = pytest_tests_status['category'].value_counts()\n",
    "total_passed = pytest_tests_status[pytest_tests_status.index.values != 'PASSED'].set_index('category').index.value_counts()\n",
    "time_count_df = pd.concat([total_passed, total_nums - total_passed, total_nums, min_test_time, avg_time_test, total_times], axis=1)\n",
    "time_count_df.columns = ['num_passed', 'num_failed', 'total_runs', 'min_test_time', 'avg_test_time', 'total_duration']\n",
    "\n",
    "report_df = pd.DataFrame()\n",
    "report_df['name'] = pytest_tests_status['category'].unique()\n",
    "report_df = report_df.set_index('name')\n",
    "\n",
    "report_df = pd.concat([report_df, time_count_df], axis=1)\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>error_details</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_upload_multiple_objects</th>\n",
       "      <td>AssertionError</td>\n",
       "      <td>Expectsuploads100tobeequaltoobjectsinthebucket...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_upload_multiple_objects</th>\n",
       "      <td>AssertionError</td>\n",
       "      <td>Expectsuploads100tobeequaltoobjectsinthebucket...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_download_multiple_objects</th>\n",
       "      <td>AssertionError</td>\n",
       "      <td>Expectsdownloads99tobeequaltouploads100assert9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_download_multiple_objects</th>\n",
       "      <td>AssertionError</td>\n",
       "      <td>Expectsdownloads99tobeequaltouploads100assert9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         error  \\\n",
       "category                                         \n",
       "test_upload_multiple_objects    AssertionError   \n",
       "test_upload_multiple_objects    AssertionError   \n",
       "test_download_multiple_objects  AssertionError   \n",
       "test_download_multiple_objects  AssertionError   \n",
       "\n",
       "                                                                    error_details  \n",
       "category                                                                           \n",
       "test_upload_multiple_objects    Expectsuploads100tobeequaltoobjectsinthebucket...  \n",
       "test_upload_multiple_objects    Expectsuploads100tobeequaltoobjectsinthebucket...  \n",
       "test_download_multiple_objects  Expectsdownloads99tobeequaltouploads100assert9...  \n",
       "test_download_multiple_objects  Expectsdownloads99tobeequaltouploads100assert9...  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_details_df = pytest_failures_errors.set_index('category').drop(columns=['arguments', 'databaseId'])\n",
    "failed_details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.time(0, 0, 40, 494736)"
      ]
     },
     "execution_count": 1802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Pedir o id do workflow que se quer um relatorio ou varios ids\n",
    "# 2. Colocar todos os jobs do workflow dentro de um dataframe\n",
    "# 3. Para cada job gerar os 3 dataframes necessarios\n",
    "# 4.\n",
    "\n",
    "# Data de criação do workflow e seu Id\n",
    "# JobId | Nome | Tempo | Falhas/Acertos | Erros (sem detalhes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status  category                        databaseId\n",
      "        test_download_multiple_objects  123456        10\n",
      "        test_upload_multiple_objects    123456        10\n",
      "Name: count, dtype: int64 category\n",
      "test_upload_multiple_objects      2\n",
      "test_download_multiple_objects    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "total = c.value_counts()\n",
    "failed = c[c.index == 'FAILED'].category.value_counts()\n",
    "\n",
    "print(total, failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2924319023.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[406], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Faz o teste -> gera graficos com tempo e taxa de falhas por tipo de teste\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Faz o teste -> gera graficos com tempo e taxa de falhas por tipo de teste\n",
    "\n",
    "Workflow -> Job -> Passos -> Resultados pytest \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define color mapping\n",
    "colors = {\n",
    "    'failure': 'firebrick',\n",
    "    'cancelled': 'darkgray',\n",
    "    'startup_failure': 'darkorange',\n",
    "    'success':  'darkgreen'\n",
    "}\n",
    "\n",
    "# Filter the DataFrame\n",
    "a = workflow.df[workflow.df['status'] == 'completed']\n",
    "\n",
    "# Get value counts of the 'conclusion' columnimport matplotlib.pyplot as plt\n",
    "\n",
    "# Define color mapping\n",
    "colors = {\n",
    "    'failure': 'firebrick',\n",
    "    'cancelled': 'darkgray',\n",
    "    'startup_failure':'darkorange',\n",
    "    'success':  'darkgreen'\n",
    "\n",
    "}\n",
    "\n",
    "# Filter the DataFrame\n",
    "a = workflow.df[workflow.df['status'] == 'completed']\n",
    "\n",
    "# Get value counts of the 'conclusion' column\n",
    "value_counts = a['conclusion'].value_counts()\n",
    "\n",
    "# Map colors to the categories in value_counts\n",
    "bar_colors = [colors[cat] for cat in value_counts.index]\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))  # 1 row, 2 columns\n",
    "\n",
    "# Plot the bar chart on the first subplot\n",
    "value_counts.plot.bar(color=bar_colors, ax=ax1)\n",
    "ax1.set_xlabel('Conclusion')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Bar Chart: Conclusion Counts')\n",
    "\n",
    "# Plot the pie chart on the second subplot\n",
    "value_counts.plot.pie(colors=bar_colors, autopct='%1.1f%%', ax=ax2)\n",
    "ax2.set_ylabel('')  # Remove the y-label for the pie chart\n",
    "ax2.set_title('Pie Chart: Conclusion Distribution')\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n",
    "value_counts = a['conclusion'].value_counts()\n",
    "\n",
    "# Map colors to the categories in value_counts\n",
    "bar_colors = [colors[cat] for cat in value_counts.index]\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))  # 1 row, 2 columns\n",
    "\n",
    "# Plot the bar chart on the first subplot\n",
    "value_counts.plot.bar(color=bar_colors, ax=ax1)\n",
    "ax1.set_xlabel('Conclusion')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Bar Chart: Conclusion Counts')\n",
    "\n",
    "# Plot the pie chart on the second subplot\n",
    "value_counts.plot.pie(colors=bar_colors, autopct='%1.1f%%', ax=ax2)\n",
    "ax2.set_ylabel('')  # Remove the y-label for the pie chart\n",
    "ax2.set_title('Pie Chart: Conclusion Distribution')\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jobs Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully saved to ./bin/actionsJobs.parquet\n",
      "DataFrame successfully saved to ./bin/actionsJobs.parquet\n",
      "DataFrame successfully saved to ./bin/actionsJobs.parquet\n",
      "DataFrame successfully saved to ./bin/actionsJobs.parquet\n",
      "DataFrame successfully saved to ./bin/actionsJobs.parquet\n",
      "DataFrame successfully saved to ./bin/actionsJobs.parquet\n",
      "DataFrame successfully saved to ./bin/actionsJobs.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conclusion</th>\n",
       "      <th>test</th>\n",
       "      <th>buildTime (sec)</th>\n",
       "      <th>jobId</th>\n",
       "      <th>failedAt</th>\n",
       "      <th>databaseId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (cold_storage, cold_storage, ../para...</td>\n",
       "      <td>85</td>\n",
       "      <td>37044161130</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (basic, basic, ../params.example.yam...</td>\n",
       "      <td>96</td>\n",
       "      <td>37044161606</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>run_tests (presign, presign, ../params.example...</td>\n",
       "      <td>69</td>\n",
       "      <td>37044161918</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>tests-success</td>\n",
       "      <td>0</td>\n",
       "      <td>37044262983</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup-tests</td>\n",
       "      <td>102</td>\n",
       "      <td>37044273275</td>\n",
       "      <td>None</td>\n",
       "      <td>13269149127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_debug (locking, ../params/br-se1.y...</td>\n",
       "      <td>2205</td>\n",
       "      <td>37044550263</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (acl, ../params/br-ne1.yaml, ...</td>\n",
       "      <td>466</td>\n",
       "      <td>37044550660</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (bucket_versioning, ../params...</td>\n",
       "      <td>119</td>\n",
       "      <td>37044550932</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>extra_tests_dist (policy, ../params/br-ne1.yam...</td>\n",
       "      <td>181</td>\n",
       "      <td>37044551314</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>PASSED</td>\n",
       "      <td>cleanup_tests</td>\n",
       "      <td>101</td>\n",
       "      <td>37046670818</td>\n",
       "      <td>None</td>\n",
       "      <td>13269265723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   conclusion                                               test  \\\n",
       "0      PASSED  run_tests (cold_storage, cold_storage, ../para...   \n",
       "1      PASSED  run_tests (basic, basic, ../params.example.yam...   \n",
       "2      PASSED  run_tests (presign, presign, ../params.example...   \n",
       "3      PASSED                                      tests-success   \n",
       "4      PASSED                                      cleanup-tests   \n",
       "..        ...                                                ...   \n",
       "50     PASSED  extra_tests_debug (locking, ../params/br-se1.y...   \n",
       "51     PASSED  extra_tests_dist (acl, ../params/br-ne1.yaml, ...   \n",
       "52     PASSED  extra_tests_dist (bucket_versioning, ../params...   \n",
       "53     PASSED  extra_tests_dist (policy, ../params/br-ne1.yam...   \n",
       "54     PASSED                                      cleanup_tests   \n",
       "\n",
       "   buildTime (sec)        jobId failedAt   databaseId  \n",
       "0               85  37044161130     None  13269149127  \n",
       "1               96  37044161606     None  13269149127  \n",
       "2               69  37044161918     None  13269149127  \n",
       "3                0  37044262983     None  13269149127  \n",
       "4              102  37044273275     None  13269149127  \n",
       "..             ...          ...      ...          ...  \n",
       "50            2205  37044550263     None  13269265723  \n",
       "51             466  37044550660     None  13269265723  \n",
       "52             119  37044550932     None  13269265723  \n",
       "53             181  37044551314     None  13269265723  \n",
       "54             101  37046670818     None  13269265723  \n",
       "\n",
       "[355 rows x 6 columns]"
      ]
     },
     "execution_count": 1703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = ActionsJobs(repository=repo_path, workflow=workflow)\n",
    "ids = workflow.df['databaseId'].unique()\n",
    "all_job_dfs = [jobs.get_jobs(id)for id in ids]\n",
    "jobs_df = pd.concat(all_job_dfs)\n",
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Conclusion'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Conclusion'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1706], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m plot_failed_passed_jobs_bars(jobs_df[\u001b[43mjobs_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mConclusion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFAILED\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     33\u001b[0m plot_failed_passed_jobs_bars(jobs_df)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Conclusion'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_failed_passed_jobs_bars(df):\n",
    "    unique_names = df.groupby(['Test', 'Conclusion']).size().unstack(fill_value=0)\n",
    "    test_to_number = {test: i + 1 for i, test in enumerate(df['Test'].unique())}\n",
    "\n",
    "    # Define colors for 'FAILED' and 'PASSED'\n",
    "    colors = {\n",
    "        'FAILED': 'firebrick',\n",
    "        'PASSED': 'darkgreen'\n",
    "    }\n",
    "\n",
    "    ax = unique_names.plot.bar(color=[colors['FAILED'], colors['PASSED']], figsize=(8, 4))\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('Test')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('FAILED vs PASSED by Test')\n",
    "\n",
    "    # Change the x-tick labels to their respective numbers\n",
    "    ax.set_xticklabels([test_to_number[test] for test in unique_names.index], rotation=0)\n",
    "\n",
    "    # Create a legend for the test numbers and names\n",
    "    test_legend = [f\"{num}. {test}\" for test, num in test_to_number.items()]\n",
    "    plt.figtext(1.05, 0.5, \"\\n\".join(test_legend), va='center', fontsize=10, wrap=True)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "#plot_failed_passed_jobs_bars(jobs_df[jobs_df['Conclusion'] == 'FAILED'])\n",
    "plot_failed_passed_jobs_bars(jobs_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
